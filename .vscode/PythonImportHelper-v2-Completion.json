[
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Awaitable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "AsyncGenerator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Generator",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "collections.abc",
        "description": "collections.abc",
        "isExtraImport": true,
        "detail": "collections.abc",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "asdict",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "field",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "IO",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalClient",
        "importPath": "azure.search.documents.agent.aio",
        "description": "azure.search.documents.agent.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.aio",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentMessage",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentMessageTextContent",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalRequest",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalResponse",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentSearchIndexActivityRecord",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentSearchIndexReference",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParams",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentMessage",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentMessageTextContent",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentModelQueryPlanningActivityRecord",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalResponse",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentSearchIndexActivityArguments",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentSearchIndexActivityRecord",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentSearchIndexReference",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentMessage",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRetrievalResponse",
        "importPath": "azure.search.documents.agent.models",
        "description": "azure.search.documents.agent.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.agent.models",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents.aio",
        "description": "azure.search.documents.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.aio",
        "documentation": {}
    },
    {
        "label": "QueryCaptionResult",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "QueryType",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorizedQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "VectorizedQuery",
        "importPath": "azure.search.documents.models",
        "description": "azure.search.documents.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.models",
        "documentation": {}
    },
    {
        "label": "openai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai",
        "description": "openai",
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncStream",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncStream",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "APIError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "RateLimitError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "AsyncOpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "BadRequestError",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "openai.types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "openai.types",
        "description": "openai.types",
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "CompletionUsage",
        "importPath": "openai.types",
        "description": "openai.types",
        "isExtraImport": true,
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "CompletionUsage",
        "importPath": "openai.types",
        "description": "openai.types",
        "isExtraImport": true,
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "CreateEmbeddingResponse",
        "importPath": "openai.types",
        "description": "openai.types",
        "isExtraImport": true,
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "Embedding",
        "importPath": "openai.types",
        "description": "openai.types",
        "isExtraImport": true,
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "CompletionUsage",
        "importPath": "openai.types",
        "description": "openai.types",
        "isExtraImport": true,
        "detail": "openai.types",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionChunk",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessageParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionReasoningEffort",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionToolParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionChunk",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessageParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionToolParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessageParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessageParam",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionChunk",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletion",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessage",
        "importPath": "openai.types.chat",
        "description": "openai.types.chat",
        "isExtraImport": true,
        "detail": "openai.types.chat",
        "documentation": {}
    },
    {
        "label": "PromptManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptyManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptyManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptyManager",
        "importPath": "approaches.promptmanager",
        "description": "approaches.promptmanager",
        "isExtraImport": true,
        "detail": "approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "importPath": "prepdocslib.blobmanager",
        "description": "prepdocslib.blobmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "prepdocslib.embeddings",
        "description": "prepdocslib.embeddings",
        "isExtraImport": true,
        "detail": "prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Approach",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "ExtraInfo",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "ThoughtStep",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "Approach",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "ExtraInfo",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "ThoughtStep",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "Approach",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "approaches.approach",
        "description": "approaches.approach",
        "isExtraImport": true,
        "detail": "approaches.approach",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "prompty",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "prompty",
        "description": "prompty",
        "detail": "prompty",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "ContainerProxy",
        "importPath": "azure.cosmos.aio",
        "description": "azure.cosmos.aio",
        "isExtraImport": true,
        "detail": "azure.cosmos.aio",
        "documentation": {}
    },
    {
        "label": "CosmosClient",
        "importPath": "azure.cosmos.aio",
        "description": "azure.cosmos.aio",
        "isExtraImport": true,
        "detail": "azure.cosmos.aio",
        "documentation": {}
    },
    {
        "label": "CosmosClient",
        "importPath": "azure.cosmos.aio",
        "description": "azure.cosmos.aio",
        "isExtraImport": true,
        "detail": "azure.cosmos.aio",
        "documentation": {}
    },
    {
        "label": "ContainerProxy",
        "importPath": "azure.cosmos.aio",
        "description": "azure.cosmos.aio",
        "isExtraImport": true,
        "detail": "azure.cosmos.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "ManagedIdentityCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "ManagedIdentityCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "ManagedIdentityCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "ManagedIdentityCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "ManagedIdentityCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity.aio",
        "description": "azure.identity.aio",
        "isExtraImport": true,
        "detail": "azure.identity.aio",
        "documentation": {}
    },
    {
        "label": "quart",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "quart",
        "description": "quart",
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "current_app",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "make_response",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "Blueprint",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "Quart",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "abort",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "current_app",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "make_response",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "send_file",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "abort",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "current_app",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "quart",
        "description": "quart",
        "isExtraImport": true,
        "detail": "quart",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_HISTORY_COSMOS_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_CONTAINER",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_VERSION",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CREDENTIAL",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AGENT_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AGENTIC_RETRIEVAL_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_ASK_APPROACH",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AUTH_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_APPROACH",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_HISTORY_BROWSER_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_HISTORY_COSMOS_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CREDENTIAL",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_DEFAULT_REASONING_EFFORT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_GLOBAL_BLOB_MANAGER",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_INGESTER",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_LANGUAGE_PICKER_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_MULTIMODAL_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_OPENAI_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_QUERY_REWRITING_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEARCH_TEXT_EMBEDDINGS",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEND_IMAGE_SOURCES",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEND_TEXT_SOURCES",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_REASONING_EFFORT_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SEARCH_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SEMANTIC_RANKER_DEPLOYED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_INPUT_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_OUTPUT_AZURE_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_OUTPUT_BROWSER_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_ID",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_LOCATION",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_TOKEN",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_VOICE",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_STREAMING_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_USER_BLOB_MANAGER",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_USER_UPLOAD_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_VECTOR_SEARCH_ENABLED",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AUTH_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SEARCH_CLIENT",
        "importPath": "config",
        "description": "config",
        "isExtraImport": true,
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "authenticated",
        "importPath": "decorators",
        "description": "decorators",
        "isExtraImport": true,
        "detail": "decorators",
        "documentation": {}
    },
    {
        "label": "authenticated",
        "importPath": "decorators",
        "description": "decorators",
        "isExtraImport": true,
        "detail": "decorators",
        "documentation": {}
    },
    {
        "label": "authenticated_path",
        "importPath": "decorators",
        "description": "decorators",
        "isExtraImport": true,
        "detail": "decorators",
        "documentation": {}
    },
    {
        "label": "error_response",
        "importPath": "error",
        "description": "error",
        "isExtraImport": true,
        "detail": "error",
        "documentation": {}
    },
    {
        "label": "error_dict",
        "importPath": "error",
        "description": "error",
        "isExtraImport": true,
        "detail": "error",
        "documentation": {}
    },
    {
        "label": "error_response",
        "importPath": "error",
        "description": "error",
        "isExtraImport": true,
        "detail": "error",
        "documentation": {}
    },
    {
        "label": "error_response",
        "importPath": "error",
        "description": "error",
        "isExtraImport": true,
        "detail": "error",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "aiohttp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "aiohttp",
        "description": "aiohttp",
        "detail": "aiohttp",
        "documentation": {}
    },
    {
        "label": "jwt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jwt",
        "description": "jwt",
        "detail": "jwt",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParametersConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataUserAssignedIdentity",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "ShaperSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "WebApiSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIEmbeddingSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SplitSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizerParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "BinaryQuantizationCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgent",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentAzureOpenAIModel",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRequestLimits",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeSourceReference",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "RescoringOptions",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchableField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSource",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticPrioritizedFields",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompressionRescoreStorageMethod",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchProfile",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParametersConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataUserAssignedIdentity",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "ShaperSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "WebApiSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIEmbeddingSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SplitSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizerParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "BinaryQuantizationCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgent",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentAzureOpenAIModel",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRequestLimits",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeSourceReference",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "RescoringOptions",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchableField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSource",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticPrioritizedFields",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompressionRescoreStorageMethod",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchProfile",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParametersConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataUserAssignedIdentity",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "ShaperSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "WebApiSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIEmbeddingSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SplitSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizerParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "BinaryQuantizationCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgent",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentAzureOpenAIModel",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRequestLimits",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeSourceReference",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "RescoringOptions",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchableField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSource",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticPrioritizedFields",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompressionRescoreStorageMethod",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchProfile",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexingParametersConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataUserAssignedIdentity",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "ShaperSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "WebApiSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIEmbeddingSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "IndexProjectionMode",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "InputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "OutputFieldMappingEntry",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataContainer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceConnection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerDataSourceType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjection",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionSelector",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerIndexProjectionsParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexerSkillset",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SplitSkill",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AIServicesVisionVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIVectorizerParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "BinaryQuantizationCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "HnswParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgent",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentAzureOpenAIModel",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgentRequestLimits",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeSourceReference",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "RescoringOptions",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchableField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSource",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticPrioritizedFields",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SemanticSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchAlgorithmConfiguration",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompression",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchCompressionRescoreStorageMethod",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchProfile",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearchVectorizer",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "KnowledgeAgent",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSource",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexKnowledgeSourceParameters",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "PermissionFilter",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchFieldDataType",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndex",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SearchIndexPermissionFilterOption",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "SimpleField",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "VectorSearch",
        "importPath": "azure.search.documents.indexes.models",
        "description": "azure.search.documents.indexes.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.models",
        "documentation": {}
    },
    {
        "label": "serialization",
        "importPath": "cryptography.hazmat.primitives",
        "description": "cryptography.hazmat.primitives",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives",
        "documentation": {}
    },
    {
        "label": "serialization",
        "importPath": "cryptography.hazmat.primitives",
        "description": "cryptography.hazmat.primitives",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives",
        "documentation": {}
    },
    {
        "label": "rsa",
        "importPath": "cryptography.hazmat.primitives.asymmetric",
        "description": "cryptography.hazmat.primitives.asymmetric",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives.asymmetric",
        "documentation": {}
    },
    {
        "label": "rsa",
        "importPath": "cryptography.hazmat.primitives.asymmetric",
        "description": "cryptography.hazmat.primitives.asymmetric",
        "isExtraImport": true,
        "detail": "cryptography.hazmat.primitives.asymmetric",
        "documentation": {}
    },
    {
        "label": "msal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "msal",
        "description": "msal",
        "detail": "msal",
        "documentation": {}
    },
    {
        "label": "ConfidentialClientApplication",
        "importPath": "msal",
        "description": "msal",
        "isExtraImport": true,
        "detail": "msal",
        "documentation": {}
    },
    {
        "label": "TokenCache",
        "importPath": "msal.token_cache",
        "description": "msal.token_cache",
        "isExtraImport": true,
        "detail": "msal.token_cache",
        "documentation": {}
    },
    {
        "label": "tenacity",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tenacity",
        "description": "tenacity",
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_fixed",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_fixed",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_fixed",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "AsyncRetrying",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "retry_if_exception_type",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "stop_after_attempt",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_fixed",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "wait_random_exponential",
        "importPath": "tenacity",
        "description": "tenacity",
        "isExtraImport": true,
        "detail": "tenacity",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urljoin",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "AsyncTokenCredential",
        "importPath": "azure.core.credentials_async",
        "description": "azure.core.credentials_async",
        "isExtraImport": true,
        "detail": "azure.core.credentials_async",
        "documentation": {}
    },
    {
        "label": "azure.core.exceptions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "ResourceNotFoundError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "ResourceNotFoundError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "ResourceNotFoundError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "ResourceNotFoundError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "ResourceNotFoundError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "HttpResponseError",
        "importPath": "azure.core.exceptions",
        "description": "azure.core.exceptions",
        "isExtraImport": true,
        "detail": "azure.core.exceptions",
        "documentation": {}
    },
    {
        "label": "azure.storage.blob.aio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "ContainerClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "BlobServiceClient",
        "importPath": "azure.storage.blob.aio",
        "description": "azure.storage.blob.aio",
        "isExtraImport": true,
        "detail": "azure.storage.blob.aio",
        "documentation": {}
    },
    {
        "label": "azure.storage.filedatalake.aio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "FileSystemClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeServiceClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "FileSystemClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeServiceClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "FileSystemClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeServiceClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "FileSystemClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeServiceClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeServiceClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeDirectoryClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "DataLakeFileClient",
        "importPath": "azure.storage.filedatalake.aio",
        "description": "azure.storage.filedatalake.aio",
        "isExtraImport": true,
        "detail": "azure.storage.filedatalake.aio",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageChops",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "NativeBlobSoftDeleteDeletionDetectionPolicy",
        "importPath": "azure.search.documents.indexes._generated.models",
        "description": "azure.search.documents.indexes._generated.models",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes._generated.models",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "tiktoken",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tiktoken",
        "description": "tiktoken",
        "detail": "tiktoken",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "TypedDict",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "AzureKeyCredential",
        "importPath": "azure.core.credentials",
        "description": "azure.core.credentials",
        "isExtraImport": true,
        "detail": "azure.core.credentials",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "NamedTemporaryFile",
        "importPath": "tempfile",
        "description": "tempfile",
        "isExtraImport": true,
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "Progress",
        "importPath": "rich.progress",
        "description": "rich.progress",
        "isExtraImport": true,
        "detail": "rich.progress",
        "documentation": {}
    },
    {
        "label": "Progress",
        "importPath": "rich.progress",
        "description": "rich.progress",
        "isExtraImport": true,
        "detail": "rich.progress",
        "documentation": {}
    },
    {
        "label": "Progress",
        "importPath": "rich.progress",
        "description": "rich.progress",
        "isExtraImport": true,
        "detail": "rich.progress",
        "documentation": {}
    },
    {
        "label": "Progress",
        "importPath": "rich.progress",
        "description": "rich.progress",
        "isExtraImport": true,
        "detail": "rich.progress",
        "documentation": {}
    },
    {
        "label": "track",
        "importPath": "rich.progress",
        "description": "rich.progress",
        "isExtraImport": true,
        "detail": "rich.progress",
        "documentation": {}
    },
    {
        "label": "html",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "html",
        "description": "html",
        "detail": "html",
        "documentation": {}
    },
    {
        "label": "pymupdf",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pymupdf",
        "description": "pymupdf",
        "detail": "pymupdf",
        "documentation": {}
    },
    {
        "label": "DocumentIntelligenceClient",
        "importPath": "azure.ai.documentintelligence.aio",
        "description": "azure.ai.documentintelligence.aio",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.aio",
        "documentation": {}
    },
    {
        "label": "DocumentIntelligenceClient",
        "importPath": "azure.ai.documentintelligence.aio",
        "description": "azure.ai.documentintelligence.aio",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.aio",
        "documentation": {}
    },
    {
        "label": "DocumentIntelligenceClient",
        "importPath": "azure.ai.documentintelligence.aio",
        "description": "azure.ai.documentintelligence.aio",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.aio",
        "documentation": {}
    },
    {
        "label": "DocumentIntelligenceClient",
        "importPath": "azure.ai.documentintelligence.aio",
        "description": "azure.ai.documentintelligence.aio",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.aio",
        "documentation": {}
    },
    {
        "label": "DocumentIntelligenceClient",
        "importPath": "azure.ai.documentintelligence.aio",
        "description": "azure.ai.documentintelligence.aio",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.aio",
        "documentation": {}
    },
    {
        "label": "AnalyzeDocumentRequest",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResult",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentFigure",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTable",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeDocumentRequest",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResult",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentFigure",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTable",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeDocumentRequest",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResult",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentFigure",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTable",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeDocumentRequest",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResult",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentFigure",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTable",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeDocumentRequest",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResult",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "BoundingRegion",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentCaption",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentFigure",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentPage",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentSpan",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTable",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "DocumentTableCell",
        "importPath": "azure.ai.documentintelligence.models",
        "description": "azure.ai.documentintelligence.models",
        "isExtraImport": true,
        "detail": "azure.ai.documentintelligence.models",
        "documentation": {}
    },
    {
        "label": "PdfReader",
        "importPath": "pypdf",
        "description": "pypdf",
        "isExtraImport": true,
        "detail": "pypdf",
        "documentation": {}
    },
    {
        "label": "PdfReader",
        "importPath": "pypdf",
        "description": "pypdf",
        "isExtraImport": true,
        "detail": "pypdf",
        "documentation": {}
    },
    {
        "label": "PdfReader",
        "importPath": "pypdf",
        "description": "pypdf",
        "isExtraImport": true,
        "detail": "pypdf",
        "documentation": {}
    },
    {
        "label": "PdfReader",
        "importPath": "pypdf",
        "description": "pypdf",
        "isExtraImport": true,
        "detail": "pypdf",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexerClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexerClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexerClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexerClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "SearchIndexClient",
        "importPath": "azure.search.documents.indexes.aio",
        "description": "azure.search.documents.indexes.aio",
        "isExtraImport": true,
        "detail": "azure.search.documents.indexes.aio",
        "documentation": {}
    },
    {
        "label": "mimetypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "mimetypes",
        "description": "mimetypes",
        "detail": "mimetypes",
        "documentation": {}
    },
    {
        "label": "azure.cognitiveservices.speech",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "ResultReason",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "SpeechConfig",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "SpeechSynthesisOutputFormat",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "SpeechSynthesisResult",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "SpeechSynthesizer",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "ResultReason",
        "importPath": "azure.cognitiveservices.speech",
        "description": "azure.cognitiveservices.speech",
        "isExtraImport": true,
        "detail": "azure.cognitiveservices.speech",
        "documentation": {}
    },
    {
        "label": "configure_azure_monitor",
        "importPath": "azure.monitor.opentelemetry",
        "description": "azure.monitor.opentelemetry",
        "isExtraImport": true,
        "detail": "azure.monitor.opentelemetry",
        "documentation": {}
    },
    {
        "label": "AioHttpClientInstrumentor",
        "importPath": "opentelemetry.instrumentation.aiohttp_client",
        "description": "opentelemetry.instrumentation.aiohttp_client",
        "isExtraImport": true,
        "detail": "opentelemetry.instrumentation.aiohttp_client",
        "documentation": {}
    },
    {
        "label": "OpenTelemetryMiddleware",
        "importPath": "opentelemetry.instrumentation.asgi",
        "description": "opentelemetry.instrumentation.asgi",
        "isExtraImport": true,
        "detail": "opentelemetry.instrumentation.asgi",
        "documentation": {}
    },
    {
        "label": "HTTPXClientInstrumentor",
        "importPath": "opentelemetry.instrumentation.httpx",
        "description": "opentelemetry.instrumentation.httpx",
        "isExtraImport": true,
        "detail": "opentelemetry.instrumentation.httpx",
        "documentation": {}
    },
    {
        "label": "OpenAIInstrumentor",
        "importPath": "opentelemetry.instrumentation.openai",
        "description": "opentelemetry.instrumentation.openai",
        "isExtraImport": true,
        "detail": "opentelemetry.instrumentation.openai",
        "documentation": {}
    },
    {
        "label": "cors",
        "importPath": "quart_cors",
        "description": "quart_cors",
        "isExtraImport": true,
        "detail": "quart_cors",
        "documentation": {}
    },
    {
        "label": "ChatReadRetrieveReadApproach",
        "importPath": "approaches.chatreadretrieveread",
        "description": "approaches.chatreadretrieveread",
        "isExtraImport": true,
        "detail": "approaches.chatreadretrieveread",
        "documentation": {}
    },
    {
        "label": "ChatReadRetrieveReadApproach",
        "importPath": "approaches.chatreadretrieveread",
        "description": "approaches.chatreadretrieveread",
        "isExtraImport": true,
        "detail": "approaches.chatreadretrieveread",
        "documentation": {}
    },
    {
        "label": "ChatReadRetrieveReadApproach",
        "importPath": "approaches.chatreadretrieveread",
        "description": "approaches.chatreadretrieveread",
        "isExtraImport": true,
        "detail": "approaches.chatreadretrieveread",
        "documentation": {}
    },
    {
        "label": "RetrieveThenReadApproach",
        "importPath": "approaches.retrievethenread",
        "description": "approaches.retrievethenread",
        "isExtraImport": true,
        "detail": "approaches.retrievethenread",
        "documentation": {}
    },
    {
        "label": "chat_history_cosmosdb_bp",
        "importPath": "chat_history.cosmosdb",
        "description": "chat_history.cosmosdb",
        "isExtraImport": true,
        "detail": "chat_history.cosmosdb",
        "documentation": {}
    },
    {
        "label": "AuthenticationHelper",
        "importPath": "core.authentication",
        "description": "core.authentication",
        "isExtraImport": true,
        "detail": "core.authentication",
        "documentation": {}
    },
    {
        "label": "AuthError",
        "importPath": "core.authentication",
        "description": "core.authentication",
        "isExtraImport": true,
        "detail": "core.authentication",
        "documentation": {}
    },
    {
        "label": "AuthenticationHelper",
        "importPath": "core.authentication",
        "description": "core.authentication",
        "isExtraImport": true,
        "detail": "core.authentication",
        "documentation": {}
    },
    {
        "label": "AuthenticationHelper",
        "importPath": "core.authentication",
        "description": "core.authentication",
        "isExtraImport": true,
        "detail": "core.authentication",
        "documentation": {}
    },
    {
        "label": "AuthError",
        "importPath": "core.authentication",
        "description": "core.authentication",
        "isExtraImport": true,
        "detail": "core.authentication",
        "documentation": {}
    },
    {
        "label": "create_session_id",
        "importPath": "core.sessionhelper",
        "description": "core.sessionhelper",
        "isExtraImport": true,
        "detail": "core.sessionhelper",
        "documentation": {}
    },
    {
        "label": "prepdocs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "prepdocs",
        "description": "prepdocs",
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_file_processors",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "importPath": "prepdocs",
        "description": "prepdocs",
        "isExtraImport": true,
        "detail": "prepdocs",
        "documentation": {}
    },
    {
        "label": "UploadUserFileStrategy",
        "importPath": "prepdocslib.filestrategy",
        "description": "prepdocslib.filestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "importPath": "prepdocslib.filestrategy",
        "description": "prepdocslib.filestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "importPath": "prepdocslib.filestrategy",
        "description": "prepdocslib.filestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "parse_file",
        "importPath": "prepdocslib.filestrategy",
        "description": "prepdocslib.filestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "prepdocslib.listfilestrategy",
        "description": "prepdocslib.listfilestrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "UvicornWorker",
        "importPath": "uvicorn.workers",
        "description": "uvicorn.workers",
        "isExtraImport": true,
        "detail": "uvicorn.workers",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "multiprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "Process",
        "importPath": "multiprocessing",
        "description": "multiprocessing",
        "isExtraImport": true,
        "detail": "multiprocessing",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "app",
        "description": "app",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "create_app",
        "importPath": "app",
        "description": "app",
        "isExtraImport": true,
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "load_azd_env",
        "description": "load_azd_env",
        "isExtraImport": true,
        "detail": "load_azd_env",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "Namespace",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "IntegratedVectorizerStrategy",
        "importPath": "prepdocslib.integratedvectorizerstrategy",
        "description": "prepdocslib.integratedvectorizerstrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "importPath": "prepdocslib.servicesetup",
        "description": "prepdocslib.servicesetup",
        "isExtraImport": true,
        "detail": "prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "importPath": "prepdocslib.strategy",
        "description": "prepdocslib.strategy",
        "isExtraImport": true,
        "detail": "prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "importPath": "prepdocslib.strategy",
        "description": "prepdocslib.strategy",
        "isExtraImport": true,
        "detail": "prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "importPath": "prepdocslib.strategy",
        "description": "prepdocslib.strategy",
        "isExtraImport": true,
        "detail": "prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "importPath": "prepdocslib.strategy",
        "description": "prepdocslib.strategy",
        "isExtraImport": true,
        "detail": "prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "importPath": "prepdocslib.strategy",
        "description": "prepdocslib.strategy",
        "isExtraImport": true,
        "detail": "prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "CloudIngestionStrategy",
        "importPath": "prepdocslib.cloudingestionstrategy",
        "description": "prepdocslib.cloudingestionstrategy",
        "isExtraImport": true,
        "detail": "prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "azure.functions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.functions",
        "description": "azure.functions",
        "detail": "azure.functions",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "importPath": "prepdocslib.fileprocessor",
        "description": "prepdocslib.fileprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "importPath": "prepdocslib.fileprocessor",
        "description": "prepdocslib.fileprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "importPath": "prepdocslib.fileprocessor",
        "description": "prepdocslib.fileprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "importPath": "prepdocslib.fileprocessor",
        "description": "prepdocslib.fileprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "importPath": "prepdocslib.fileprocessor",
        "description": "prepdocslib.fileprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "prepdocslib.page",
        "description": "prepdocslib.page",
        "isExtraImport": true,
        "detail": "prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "process_page_image",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "build_figure_markup",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "process_page_image",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "importPath": "prepdocslib.figureprocessor",
        "description": "prepdocslib.figureprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "process_text",
        "importPath": "prepdocslib.textprocessor",
        "description": "prepdocslib.textprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "combine_text_with_figures",
        "importPath": "prepdocslib.textprocessor",
        "description": "prepdocslib.textprocessor",
        "isExtraImport": true,
        "detail": "prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "get_bearer_token_provider",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "AzureDeveloperCliCredential",
        "importPath": "azure.identity",
        "description": "azure.identity",
        "isExtraImport": true,
        "detail": "azure.identity",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "dotenv_azd",
        "description": "dotenv_azd",
        "isExtraImport": true,
        "detail": "dotenv_azd",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "dotenv_azd",
        "description": "dotenv_azd",
        "isExtraImport": true,
        "detail": "dotenv_azd",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "importPath": "dotenv_azd",
        "description": "dotenv_azd",
        "isExtraImport": true,
        "detail": "dotenv_azd",
        "documentation": {}
    },
    {
        "label": "run_evaluate_from_config",
        "importPath": "evaltools.eval.evaluate",
        "description": "evaltools.eval.evaluate",
        "isExtraImport": true,
        "detail": "evaltools.eval.evaluate",
        "documentation": {}
    },
    {
        "label": "register_metric",
        "importPath": "evaltools.eval.evaluate_metrics",
        "description": "evaltools.eval.evaluate_metrics",
        "isExtraImport": true,
        "detail": "evaltools.eval.evaluate_metrics",
        "documentation": {}
    },
    {
        "label": "BaseMetric",
        "importPath": "evaltools.eval.evaluate_metrics.base_metric",
        "description": "evaltools.eval.evaluate_metrics.base_metric",
        "isExtraImport": true,
        "detail": "evaltools.eval.evaluate_metrics.base_metric",
        "documentation": {}
    },
    {
        "label": "SearchClient",
        "importPath": "azure.search.documents",
        "description": "azure.search.documents",
        "isExtraImport": true,
        "detail": "azure.search.documents",
        "documentation": {}
    },
    {
        "label": "Document",
        "importPath": "langchain_core.documents",
        "description": "langchain_core.documents",
        "isExtraImport": true,
        "detail": "langchain_core.documents",
        "documentation": {}
    },
    {
        "label": "AzureChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "AzureOpenAIEmbeddings",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "LangchainEmbeddingsWrapper",
        "importPath": "ragas.embeddings",
        "description": "ragas.embeddings",
        "isExtraImport": true,
        "detail": "ragas.embeddings",
        "documentation": {}
    },
    {
        "label": "LangchainLLMWrapper",
        "importPath": "ragas.llms",
        "description": "ragas.llms",
        "isExtraImport": true,
        "detail": "ragas.llms",
        "documentation": {}
    },
    {
        "label": "TestsetGenerator",
        "importPath": "ragas.testset",
        "description": "ragas.testset",
        "isExtraImport": true,
        "detail": "ragas.testset",
        "documentation": {}
    },
    {
        "label": "KnowledgeGraph",
        "importPath": "ragas.testset.graph",
        "description": "ragas.testset.graph",
        "isExtraImport": true,
        "detail": "ragas.testset.graph",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "ragas.testset.graph",
        "description": "ragas.testset.graph",
        "isExtraImport": true,
        "detail": "ragas.testset.graph",
        "documentation": {}
    },
    {
        "label": "NodeType",
        "importPath": "ragas.testset.graph",
        "description": "ragas.testset.graph",
        "isExtraImport": true,
        "detail": "ragas.testset.graph",
        "documentation": {}
    },
    {
        "label": "apply_transforms",
        "importPath": "ragas.testset.transforms",
        "description": "ragas.testset.transforms",
        "isExtraImport": true,
        "detail": "ragas.testset.transforms",
        "documentation": {}
    },
    {
        "label": "default_transforms",
        "importPath": "ragas.testset.transforms",
        "description": "ragas.testset.transforms",
        "isExtraImport": true,
        "detail": "ragas.testset.transforms",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "ContentSafetyEvaluator",
        "importPath": "azure.ai.evaluation",
        "description": "azure.ai.evaluation",
        "isExtraImport": true,
        "detail": "azure.ai.evaluation",
        "documentation": {}
    },
    {
        "label": "AdversarialScenario",
        "importPath": "azure.ai.evaluation.simulator",
        "description": "azure.ai.evaluation.simulator",
        "isExtraImport": true,
        "detail": "azure.ai.evaluation.simulator",
        "documentation": {}
    },
    {
        "label": "AdversarialSimulator",
        "importPath": "azure.ai.evaluation.simulator",
        "description": "azure.ai.evaluation.simulator",
        "isExtraImport": true,
        "detail": "azure.ai.evaluation.simulator",
        "documentation": {}
    },
    {
        "label": "SupportedLanguages",
        "importPath": "azure.ai.evaluation.simulator",
        "description": "azure.ai.evaluation.simulator",
        "isExtraImport": true,
        "detail": "azure.ai.evaluation.simulator",
        "documentation": {}
    },
    {
        "label": "APIError",
        "importPath": "kiota_abstractions.api_error",
        "description": "kiota_abstractions.api_error",
        "isExtraImport": true,
        "detail": "kiota_abstractions.api_error",
        "documentation": {}
    },
    {
        "label": "APIError",
        "importPath": "kiota_abstractions.api_error",
        "description": "kiota_abstractions.api_error",
        "isExtraImport": true,
        "detail": "kiota_abstractions.api_error",
        "documentation": {}
    },
    {
        "label": "APIError",
        "importPath": "kiota_abstractions.api_error",
        "description": "kiota_abstractions.api_error",
        "isExtraImport": true,
        "detail": "kiota_abstractions.api_error",
        "documentation": {}
    },
    {
        "label": "GraphServiceClient",
        "importPath": "msgraph",
        "description": "msgraph",
        "isExtraImport": true,
        "detail": "msgraph",
        "documentation": {}
    },
    {
        "label": "GraphServiceClient",
        "importPath": "msgraph",
        "description": "msgraph",
        "isExtraImport": true,
        "detail": "msgraph",
        "documentation": {}
    },
    {
        "label": "GraphServiceClient",
        "importPath": "msgraph",
        "description": "msgraph",
        "isExtraImport": true,
        "detail": "msgraph",
        "documentation": {}
    },
    {
        "label": "GraphServiceClient",
        "importPath": "msgraph",
        "description": "msgraph",
        "isExtraImport": true,
        "detail": "msgraph",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "RequestConfiguration",
        "importPath": "kiota_abstractions.base_request_configuration",
        "description": "kiota_abstractions.base_request_configuration",
        "isExtraImport": true,
        "detail": "kiota_abstractions.base_request_configuration",
        "documentation": {}
    },
    {
        "label": "AddPasswordPostRequestBody",
        "importPath": "msgraph.generated.applications.item.add_password.add_password_post_request_body",
        "description": "msgraph.generated.applications.item.add_password.add_password_post_request_body",
        "isExtraImport": true,
        "detail": "msgraph.generated.applications.item.add_password.add_password_post_request_body",
        "documentation": {}
    },
    {
        "label": "ApiApplication",
        "importPath": "msgraph.generated.models.api_application",
        "description": "msgraph.generated.models.api_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.api_application",
        "documentation": {}
    },
    {
        "label": "Application",
        "importPath": "msgraph.generated.models.application",
        "description": "msgraph.generated.models.application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.application",
        "documentation": {}
    },
    {
        "label": "Application",
        "importPath": "msgraph.generated.models.application",
        "description": "msgraph.generated.models.application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.application",
        "documentation": {}
    },
    {
        "label": "Application",
        "importPath": "msgraph.generated.models.application",
        "description": "msgraph.generated.models.application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.application",
        "documentation": {}
    },
    {
        "label": "ImplicitGrantSettings",
        "importPath": "msgraph.generated.models.implicit_grant_settings",
        "description": "msgraph.generated.models.implicit_grant_settings",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.implicit_grant_settings",
        "documentation": {}
    },
    {
        "label": "OAuth2PermissionGrant",
        "importPath": "msgraph.generated.models.o_auth2_permission_grant",
        "description": "msgraph.generated.models.o_auth2_permission_grant",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.o_auth2_permission_grant",
        "documentation": {}
    },
    {
        "label": "PasswordCredential",
        "importPath": "msgraph.generated.models.password_credential",
        "description": "msgraph.generated.models.password_credential",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.password_credential",
        "documentation": {}
    },
    {
        "label": "PasswordCredential",
        "importPath": "msgraph.generated.models.password_credential",
        "description": "msgraph.generated.models.password_credential",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.password_credential",
        "documentation": {}
    },
    {
        "label": "PermissionScope",
        "importPath": "msgraph.generated.models.permission_scope",
        "description": "msgraph.generated.models.permission_scope",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.permission_scope",
        "documentation": {}
    },
    {
        "label": "RequiredResourceAccess",
        "importPath": "msgraph.generated.models.required_resource_access",
        "description": "msgraph.generated.models.required_resource_access",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.required_resource_access",
        "documentation": {}
    },
    {
        "label": "ResourceAccess",
        "importPath": "msgraph.generated.models.resource_access",
        "description": "msgraph.generated.models.resource_access",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.resource_access",
        "documentation": {}
    },
    {
        "label": "ServicePrincipal",
        "importPath": "msgraph.generated.models.service_principal",
        "description": "msgraph.generated.models.service_principal",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.service_principal",
        "documentation": {}
    },
    {
        "label": "ServicePrincipal",
        "importPath": "msgraph.generated.models.service_principal",
        "description": "msgraph.generated.models.service_principal",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.service_principal",
        "documentation": {}
    },
    {
        "label": "SpaApplication",
        "importPath": "msgraph.generated.models.spa_application",
        "description": "msgraph.generated.models.spa_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.spa_application",
        "documentation": {}
    },
    {
        "label": "SpaApplication",
        "importPath": "msgraph.generated.models.spa_application",
        "description": "msgraph.generated.models.spa_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.spa_application",
        "documentation": {}
    },
    {
        "label": "WebApplication",
        "importPath": "msgraph.generated.models.web_application",
        "description": "msgraph.generated.models.web_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.web_application",
        "documentation": {}
    },
    {
        "label": "WebApplication",
        "importPath": "msgraph.generated.models.web_application",
        "description": "msgraph.generated.models.web_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.web_application",
        "documentation": {}
    },
    {
        "label": "Oauth2PermissionGrantsRequestBuilder",
        "importPath": "msgraph.generated.oauth2_permission_grants.oauth2_permission_grants_request_builder",
        "description": "msgraph.generated.oauth2_permission_grants.oauth2_permission_grants_request_builder",
        "isExtraImport": true,
        "detail": "msgraph.generated.oauth2_permission_grants.oauth2_permission_grants_request_builder",
        "documentation": {}
    },
    {
        "label": "get_application",
        "importPath": "auth_common",
        "description": "auth_common",
        "isExtraImport": true,
        "detail": "auth_common",
        "documentation": {}
    },
    {
        "label": "test_authentication_enabled",
        "importPath": "auth_common",
        "description": "auth_common",
        "isExtraImport": true,
        "detail": "auth_common",
        "documentation": {}
    },
    {
        "label": "get_application",
        "importPath": "auth_common",
        "description": "auth_common",
        "isExtraImport": true,
        "detail": "auth_common",
        "documentation": {}
    },
    {
        "label": "test_authentication_enabled",
        "importPath": "auth_common",
        "description": "auth_common",
        "isExtraImport": true,
        "detail": "auth_common",
        "documentation": {}
    },
    {
        "label": "PublicClientApplication",
        "importPath": "msgraph.generated.models.public_client_application",
        "description": "msgraph.generated.models.public_client_application",
        "isExtraImport": true,
        "detail": "msgraph.generated.models.public_client_application",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "mock",
        "importPath": "unittest",
        "description": "unittest",
        "isExtraImport": true,
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "azure.storage.filedatalake",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure.storage.filedatalake",
        "description": "azure.storage.filedatalake",
        "detail": "azure.storage.filedatalake",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "pytest_asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest_asyncio",
        "description": "pytest_asyncio",
        "detail": "pytest_asyncio",
        "documentation": {}
    },
    {
        "label": "ChatCompletionMessage",
        "importPath": "openai.types.chat.chat_completion",
        "description": "openai.types.chat.chat_completion",
        "isExtraImport": true,
        "detail": "openai.types.chat.chat_completion",
        "documentation": {}
    },
    {
        "label": "Choice",
        "importPath": "openai.types.chat.chat_completion",
        "description": "openai.types.chat.chat_completion",
        "isExtraImport": true,
        "detail": "openai.types.chat.chat_completion",
        "documentation": {}
    },
    {
        "label": "Choice",
        "importPath": "openai.types.chat.chat_completion",
        "description": "openai.types.chat.chat_completion",
        "isExtraImport": true,
        "detail": "openai.types.chat.chat_completion",
        "documentation": {}
    },
    {
        "label": "Usage",
        "importPath": "openai.types.create_embedding_response",
        "description": "openai.types.create_embedding_response",
        "isExtraImport": true,
        "detail": "openai.types.create_embedding_response",
        "documentation": {}
    },
    {
        "label": "Usage",
        "importPath": "openai.types.create_embedding_response",
        "description": "openai.types.create_embedding_response",
        "isExtraImport": true,
        "detail": "openai.types.create_embedding_response",
        "documentation": {}
    },
    {
        "label": "Usage",
        "importPath": "openai.types.create_embedding_response",
        "description": "openai.types.create_embedding_response",
        "isExtraImport": true,
        "detail": "openai.types.create_embedding_response",
        "documentation": {}
    },
    {
        "label": "Usage",
        "importPath": "openai.types.create_embedding_response",
        "description": "openai.types.create_embedding_response",
        "isExtraImport": true,
        "detail": "openai.types.create_embedding_response",
        "documentation": {}
    },
    {
        "label": "core",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "core",
        "description": "core",
        "detail": "core",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "closing",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "uvicorn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uvicorn",
        "description": "uvicorn",
        "detail": "uvicorn",
        "documentation": {}
    },
    {
        "label": "Axe",
        "importPath": "axe_playwright_python.sync_playwright",
        "description": "axe_playwright_python.sync_playwright",
        "isExtraImport": true,
        "detail": "axe_playwright_python.sync_playwright",
        "documentation": {}
    },
    {
        "label": "Page",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "Route",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "expect",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "AioHttpTransportResponse",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "AsyncHttpTransport",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "HttpRequest",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "AioHttpTransportResponse",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "AsyncHttpTransport",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "HttpRequest",
        "importPath": "azure.core.pipeline.transport",
        "description": "azure.core.pipeline.transport",
        "isExtraImport": true,
        "detail": "azure.core.pipeline.transport",
        "documentation": {}
    },
    {
        "label": "BlobProperties",
        "importPath": "azure.storage.blob",
        "description": "azure.storage.blob",
        "isExtraImport": true,
        "detail": "azure.storage.blob",
        "documentation": {}
    },
    {
        "label": "builtins",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "builtins",
        "description": "builtins",
        "detail": "builtins",
        "documentation": {}
    },
    {
        "label": "AdlsGen2Setup",
        "importPath": "scripts.adlsgen2setup",
        "description": "scripts.adlsgen2setup",
        "isExtraImport": true,
        "detail": "scripts.adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "quart.testing.app",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "quart.testing.app",
        "description": "quart.testing.app",
        "detail": "quart.testing.app",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "httpx",
        "description": "httpx",
        "isExtraImport": true,
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "httpx",
        "description": "httpx",
        "isExtraImport": true,
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "httpx",
        "description": "httpx",
        "isExtraImport": true,
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "Response",
        "importPath": "httpx",
        "description": "httpx",
        "isExtraImport": true,
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "SimpleNamespace",
        "importPath": "types",
        "description": "types",
        "isExtraImport": true,
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "auth_init",
        "importPath": "scripts",
        "description": "scripts",
        "isExtraImport": true,
        "detail": "scripts",
        "documentation": {}
    },
    {
        "label": "add_client_secret",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "client_app",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "create_application",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "create_or_update_application_with_secret",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "grant_application_admin_consent",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "server_app_initial",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "server_app_permission_setup",
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "isExtraImport": true,
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "AsyncMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "AsyncMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "MagicMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "Mock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "AsyncMock",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "CosmosDBMigrator",
        "importPath": "scripts.cosmosdb_migration",
        "description": "scripts.cosmosdb_migration",
        "isExtraImport": true,
        "detail": "scripts.cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "migrate_cosmosdb_data",
        "importPath": "scripts.cosmosdb_migration",
        "description": "scripts.cosmosdb_migration",
        "isExtraImport": true,
        "detail": "scripts.cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "to the correct module",
        "importPath": "prepdocslib.csvparser import CsvParser  # Adjust",
        "description": "prepdocslib.csvparser import CsvParser  # Adjust",
        "isExtraImport": true,
        "detail": "prepdocslib.csvparser import CsvParser  # Adjust",
        "documentation": {}
    },
    {
        "label": "function_app",
        "importPath": "document_extractor",
        "description": "document_extractor",
        "isExtraImport": true,
        "detail": "document_extractor",
        "documentation": {}
    },
    {
        "label": "function_app",
        "importPath": "figure_processor",
        "description": "figure_processor",
        "isExtraImport": true,
        "detail": "figure_processor",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "importPath": "prepdocslib.textparser",
        "description": "prepdocslib.textparser",
        "isExtraImport": true,
        "detail": "prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "importPath": "prepdocslib.textparser",
        "description": "prepdocslib.textparser",
        "isExtraImport": true,
        "detail": "prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "importPath": "prepdocslib.textparser",
        "description": "prepdocslib.textparser",
        "isExtraImport": true,
        "detail": "prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "importPath": "prepdocslib.textparser",
        "description": "prepdocslib.textparser",
        "isExtraImport": true,
        "detail": "prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "ENCODING_MODEL",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "importPath": "prepdocslib.textsplitter",
        "description": "prepdocslib.textsplitter",
        "isExtraImport": true,
        "detail": "prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_BYTES",
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "isExtraImport": true,
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "function_app",
        "importPath": "text_processor",
        "description": "text_processor",
        "isExtraImport": true,
        "detail": "text_processor",
        "documentation": {}
    },
    {
        "label": "LocalHTMLParser",
        "importPath": "prepdocslib.htmlparser",
        "description": "prepdocslib.htmlparser",
        "isExtraImport": true,
        "detail": "prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "JsonParser",
        "importPath": "prepdocslib.jsonparser",
        "description": "prepdocslib.jsonparser",
        "isExtraImport": true,
        "detail": "prepdocslib.jsonparser",
        "documentation": {}
    },
    {
        "label": "azure",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "azure",
        "description": "azure",
        "detail": "azure",
        "documentation": {}
    },
    {
        "label": "ManageAcl",
        "importPath": "scripts.manageacl",
        "description": "scripts.manageacl",
        "isExtraImport": true,
        "detail": "scripts.manageacl",
        "documentation": {}
    },
    {
        "label": "ContentUnderstandingDescriber",
        "importPath": "prepdocslib.mediadescriber",
        "description": "prepdocslib.mediadescriber",
        "isExtraImport": true,
        "detail": "prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "MultimodalModelDescriber",
        "importPath": "prepdocslib.mediadescriber",
        "description": "prepdocslib.mediadescriber",
        "isExtraImport": true,
        "detail": "prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "FileStorage",
        "importPath": "werkzeug.datastructures",
        "description": "werkzeug.datastructures",
        "isExtraImport": true,
        "detail": "werkzeug.datastructures",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "importPath": "prepdocslib.pdfparser",
        "description": "prepdocslib.pdfparser",
        "isExtraImport": true,
        "detail": "prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "LocalPdfParser",
        "importPath": "prepdocslib.pdfparser",
        "description": "prepdocslib.pdfparser",
        "isExtraImport": true,
        "detail": "prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "importPath": "prepdocslib.pdfparser",
        "description": "prepdocslib.pdfparser",
        "isExtraImport": true,
        "detail": "prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "Section",
        "importPath": "prepdocslib.searchmanager",
        "description": "prepdocslib.searchmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "importPath": "prepdocslib.searchmanager",
        "description": "prepdocslib.searchmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "Section",
        "importPath": "prepdocslib.searchmanager",
        "description": "prepdocslib.searchmanager",
        "isExtraImport": true,
        "detail": "prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "FileStorage",
        "importPath": "quart.datastructures",
        "description": "quart.datastructures",
        "isExtraImport": true,
        "detail": "quart.datastructures",
        "documentation": {}
    },
    {
        "label": "HttpUser",
        "importPath": "locust",
        "description": "locust",
        "isExtraImport": true,
        "detail": "locust",
        "documentation": {}
    },
    {
        "label": "between",
        "importPath": "locust",
        "description": "locust",
        "isExtraImport": true,
        "detail": "locust",
        "documentation": {}
    },
    {
        "label": "task",
        "importPath": "locust",
        "description": "locust",
        "isExtraImport": true,
        "detail": "locust",
        "documentation": {}
    },
    {
        "label": "Document",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class Document:\n    id: Optional[str] = None\n    content: Optional[str] = None\n    category: Optional[str] = None\n    sourcepage: Optional[str] = None\n    sourcefile: Optional[str] = None\n    oids: Optional[list[str]] = None\n    groups: Optional[list[str]] = None\n    captions: Optional[list[QueryCaptionResult]] = None\n    score: Optional[float] = None",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "ThoughtStep",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class ThoughtStep:\n    title: str\n    description: Optional[Any]\n    props: Optional[dict[str, Any]] = None\n    def update_token_usage(self, usage: CompletionUsage) -> None:\n        if self.props:\n            self.props[\"token_usage\"] = TokenUsageProps.from_completion_usage(usage)\n@dataclass\nclass DataPoints:\n    text: Optional[list[str]] = None",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "DataPoints",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class DataPoints:\n    text: Optional[list[str]] = None\n    images: Optional[list] = None\n    citations: Optional[list[str]] = None\n@dataclass\nclass ExtraInfo:\n    data_points: DataPoints\n    thoughts: list[ThoughtStep] = field(default_factory=list)\n    followup_questions: Optional[list[Any]] = None\n@dataclass",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "ExtraInfo",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class ExtraInfo:\n    data_points: DataPoints\n    thoughts: list[ThoughtStep] = field(default_factory=list)\n    followup_questions: Optional[list[Any]] = None\n@dataclass\nclass TokenUsageProps:\n    prompt_tokens: int\n    completion_tokens: int\n    reasoning_tokens: Optional[int]\n    total_tokens: int",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "TokenUsageProps",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class TokenUsageProps:\n    prompt_tokens: int\n    completion_tokens: int\n    reasoning_tokens: Optional[int]\n    total_tokens: int\n    @classmethod\n    def from_completion_usage(cls, usage: CompletionUsage) -> \"TokenUsageProps\":\n        return cls(\n            prompt_tokens=usage.prompt_tokens,\n            completion_tokens=usage.completion_tokens,",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "GPTReasoningModelSupport",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class GPTReasoningModelSupport:\n    streaming: bool\n    minimal_effort: bool\nclass Approach(ABC):\n    # List of GPT reasoning models support\n    GPT_REASONING_MODELS = {\n        \"o1\": GPTReasoningModelSupport(streaming=False, minimal_effort=False),\n        \"o3\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),\n        \"o3-mini\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),\n        \"o4-mini\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "Approach",
        "kind": 6,
        "importPath": "app.backend.approaches.approach",
        "description": "app.backend.approaches.approach",
        "peekOfCode": "class Approach(ABC):\n    # List of GPT reasoning models support\n    GPT_REASONING_MODELS = {\n        \"o1\": GPTReasoningModelSupport(streaming=False, minimal_effort=False),\n        \"o3\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),\n        \"o3-mini\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),\n        \"o4-mini\": GPTReasoningModelSupport(streaming=True, minimal_effort=False),\n        \"gpt-5\": GPTReasoningModelSupport(streaming=True, minimal_effort=True),\n        \"gpt-5-nano\": GPTReasoningModelSupport(streaming=True, minimal_effort=True),\n        \"gpt-5-mini\": GPTReasoningModelSupport(streaming=True, minimal_effort=True),",
        "detail": "app.backend.approaches.approach",
        "documentation": {}
    },
    {
        "label": "ChatReadRetrieveReadApproach",
        "kind": 6,
        "importPath": "app.backend.approaches.chatreadretrieveread",
        "description": "app.backend.approaches.chatreadretrieveread",
        "peekOfCode": "class ChatReadRetrieveReadApproach(Approach):\n    \"\"\"\n    A multi-step approach that first uses OpenAI to turn the user's question into a search query,\n    then uses Azure AI Search to retrieve relevant documents, and then sends the conversation history,\n    original user question, and search results to OpenAI to generate a response.\n    \"\"\"\n    NO_RESPONSE = \"0\"\n    def __init__(\n        self,\n        *,",
        "detail": "app.backend.approaches.chatreadretrieveread",
        "documentation": {}
    },
    {
        "label": "PromptManager",
        "kind": 6,
        "importPath": "app.backend.approaches.promptmanager",
        "description": "app.backend.approaches.promptmanager",
        "peekOfCode": "class PromptManager:\n    def load_prompt(self, path: str):\n        raise NotImplementedError\n    def load_tools(self, path: str):\n        raise NotImplementedError\n    def render_prompt(self, prompt, data) -> list[ChatCompletionMessageParam]:\n        raise NotImplementedError\nclass PromptyManager(PromptManager):\n    PROMPTS_DIRECTORY = pathlib.Path(__file__).parent / \"prompts\"\n    def load_prompt(self, path: str):",
        "detail": "app.backend.approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "PromptyManager",
        "kind": 6,
        "importPath": "app.backend.approaches.promptmanager",
        "description": "app.backend.approaches.promptmanager",
        "peekOfCode": "class PromptyManager(PromptManager):\n    PROMPTS_DIRECTORY = pathlib.Path(__file__).parent / \"prompts\"\n    def load_prompt(self, path: str):\n        return prompty.load(self.PROMPTS_DIRECTORY / path)\n    def load_tools(self, path: str):\n        return json.loads(open(self.PROMPTS_DIRECTORY / path).read())\n    def render_prompt(self, prompt, data) -> list[ChatCompletionMessageParam]:\n        return prompty.prepare(prompt, data)",
        "detail": "app.backend.approaches.promptmanager",
        "documentation": {}
    },
    {
        "label": "RetrieveThenReadApproach",
        "kind": 6,
        "importPath": "app.backend.approaches.retrievethenread",
        "description": "app.backend.approaches.retrievethenread",
        "peekOfCode": "class RetrieveThenReadApproach(Approach):\n    \"\"\"\n    Simple retrieve-then-read implementation, using the AI Search and OpenAI APIs directly. It first retrieves\n    top documents from search, then constructs a prompt with them, and then uses OpenAI to generate an completion\n    (answer) with that prompt.\n    \"\"\"\n    def __init__(\n        self,\n        *,\n        search_client: SearchClient,",
        "detail": "app.backend.approaches.retrievethenread",
        "documentation": {}
    },
    {
        "label": "chat_history_cosmosdb_bp",
        "kind": 5,
        "importPath": "app.backend.chat_history.cosmosdb",
        "description": "app.backend.chat_history.cosmosdb",
        "peekOfCode": "chat_history_cosmosdb_bp = Blueprint(\"chat_history_cosmos\", __name__, static_folder=\"static\")\n@chat_history_cosmosdb_bp.post(\"/chat_history\")\n@authenticated\nasync def post_chat_history(auth_claims: dict[str, Any]):\n    if not current_app.config[CONFIG_CHAT_HISTORY_COSMOS_ENABLED]:\n        return jsonify({\"error\": \"Chat history not enabled\"}), 400\n    container: ContainerProxy = current_app.config[CONFIG_COSMOS_HISTORY_CONTAINER]\n    if not container:\n        return jsonify({\"error\": \"Chat history not enabled\"}), 400\n    entra_oid = auth_claims.get(\"oid\")",
        "detail": "app.backend.chat_history.cosmosdb",
        "documentation": {}
    },
    {
        "label": "AuthError",
        "kind": 6,
        "importPath": "app.backend.core.authentication",
        "description": "app.backend.core.authentication",
        "peekOfCode": "class AuthError(Exception):\n    def __init__(self, error, status_code):\n        self.error = error\n        self.status_code = status_code\n    def __str__(self) -> str:\n        return self.error or \"\"\nclass AuthenticationHelper:\n    scope: str = \"https://search.azure.com/.default\"\n    def __init__(\n        self,",
        "detail": "app.backend.core.authentication",
        "documentation": {}
    },
    {
        "label": "AuthenticationHelper",
        "kind": 6,
        "importPath": "app.backend.core.authentication",
        "description": "app.backend.core.authentication",
        "peekOfCode": "class AuthenticationHelper:\n    scope: str = \"https://search.azure.com/.default\"\n    def __init__(\n        self,\n        search_index: Optional[SearchIndex],\n        use_authentication: bool,\n        server_app_id: Optional[str],\n        server_app_secret: Optional[str],\n        client_app_id: Optional[str],\n        tenant_id: Optional[str],",
        "detail": "app.backend.core.authentication",
        "documentation": {}
    },
    {
        "label": "create_session_id",
        "kind": 2,
        "importPath": "app.backend.core.sessionhelper",
        "description": "app.backend.core.sessionhelper",
        "peekOfCode": "def create_session_id(\n    config_chat_history_cosmos_enabled: bool, config_chat_history_browser_enabled: bool\n) -> Optional[str]:\n    if config_chat_history_cosmos_enabled:\n        return str(uuid.uuid4())\n    if config_chat_history_browser_enabled:\n        return str(uuid.uuid4())\n    return None",
        "detail": "app.backend.core.sessionhelper",
        "documentation": {}
    },
    {
        "label": "BlobProperties",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.blobmanager",
        "description": "app.backend.prepdocslib.blobmanager",
        "peekOfCode": "class BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":",
        "detail": "app.backend.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BaseBlobManager",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.blobmanager",
        "description": "app.backend.prepdocslib.blobmanager",
        "peekOfCode": "class BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":\n            return f\"{os.path.basename(filename)}#page={page+1}\"\n        else:\n            return os.path.basename(filename)",
        "detail": "app.backend.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.blobmanager",
        "description": "app.backend.prepdocslib.blobmanager",
        "peekOfCode": "class AdlsBlobManager(BaseBlobManager):\n    \"\"\"\n    Manager for Azure Data Lake Storage blob operations, particularly for user-specific file operations.\n    Documents are stored directly in the user's directory for backwards compatibility.\n    Images are stored in a separate images subdirectory for better organization.\n    \"\"\"\n    def __init__(self, endpoint: str, container: str, credential: AsyncTokenCredential):\n        \"\"\"\n        Initializes the AdlsBlobManager with the necessary parameters.\n        Args:",
        "detail": "app.backend.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.blobmanager",
        "description": "app.backend.prepdocslib.blobmanager",
        "peekOfCode": "class BlobManager(BaseBlobManager):\n    \"\"\"\n    Class to manage uploading and deleting blobs containing citation information from a blob storage account\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        container: str,\n        credential: AsyncTokenCredential | str,\n        image_container: Optional[str] = None,",
        "detail": "app.backend.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.blobmanager",
        "description": "app.backend.prepdocslib.blobmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:",
        "detail": "app.backend.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "SkillConfig",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.cloudingestionstrategy",
        "description": "app.backend.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.backend.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CloudIngestionStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.cloudingestionstrategy",
        "description": "app.backend.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,\n        *,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,\n        search_field_name_embedding: str,",
        "detail": "app.backend.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.cloudingestionstrategy",
        "description": "app.backend.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nDEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str",
        "detail": "app.backend.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SKILL_TIMEOUT",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.cloudingestionstrategy",
        "description": "app.backend.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover",
        "detail": "app.backend.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_BATCH_SIZE",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.cloudingestionstrategy",
        "description": "app.backend.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"",
        "detail": "app.backend.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CsvParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.csvparser",
        "description": "app.backend.prepdocslib.csvparser",
        "peekOfCode": "class CsvParser(Parser):\n    \"\"\"\n    Concrete parser that can parse CSV into Page objects. Each row becomes a Page object.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        # Check if content is in bytes (binary file) and decode to string\n        content_str: str\n        if isinstance(content, (bytes, bytearray)):\n            content_str = content.decode(\"utf-8\")\n        elif hasattr(content, \"read\"):  # Handle BufferedReader",
        "detail": "app.backend.prepdocslib.csvparser",
        "documentation": {}
    },
    {
        "label": "EmbeddingBatch",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.embeddings",
        "description": "app.backend.prepdocslib.embeddings",
        "peekOfCode": "class EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {",
        "detail": "app.backend.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ExtraArgs",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.embeddings",
        "description": "app.backend.prepdocslib.embeddings",
        "peekOfCode": "class ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {",
        "detail": "app.backend.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.embeddings",
        "description": "app.backend.prepdocslib.embeddings",
        "peekOfCode": "class OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {\n        \"text-embedding-ada-002\": False,\n        \"text-embedding-3-small\": True,",
        "detail": "app.backend.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.embeddings",
        "description": "app.backend.prepdocslib.embeddings",
        "peekOfCode": "class ImageEmbeddings:\n    \"\"\"\n    Class for using image embeddings from Azure AI Vision\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-image-api\n    \"\"\"\n    def __init__(self, endpoint: str, token_provider: Callable[[], Awaitable[str]]):\n        self.token_provider = token_provider\n        self.endpoint = endpoint\n    async def create_embedding_for_image(self, image_bytes: bytes) -> list[float]:\n        endpoint = urljoin(self.endpoint, \"computervision/retrieval:vectorizeImage\")",
        "detail": "app.backend.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.embeddings",
        "description": "app.backend.prepdocslib.embeddings",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"",
        "detail": "app.backend.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.figureprocessor",
        "description": "app.backend.prepdocslib.figureprocessor",
        "peekOfCode": "class MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,",
        "detail": "app.backend.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.figureprocessor",
        "description": "app.backend.prepdocslib.figureprocessor",
        "peekOfCode": "class FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,\n        credential: AsyncTokenCredential | AzureKeyCredential | None = None,\n        strategy: MediaDescriptionStrategy = MediaDescriptionStrategy.NONE,\n        openai_client: Any | None = None,\n        openai_model: str | None = None,\n        openai_deployment: str | None = None,",
        "detail": "app.backend.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "build_figure_markup",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.figureprocessor",
        "description": "app.backend.prepdocslib.figureprocessor",
        "peekOfCode": "def build_figure_markup(image: \"ImageOnPage\", description: Optional[str] = None) -> str:\n    \"\"\"Create consistent HTML markup for a figure description on demand.\"\"\"\n    caption_parts = [image.figure_id]\n    if image.title:\n        caption_parts.append(image.title)\n    caption = \" \".join(part for part in caption_parts if part)\n    if description:\n        return f\"<figure><figcaption>{caption}<br>{description}</figcaption></figure>\"\n    return f\"<figure><figcaption>{caption}</figcaption></figure>\"\nasync def process_page_image(",
        "detail": "app.backend.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.figureprocessor",
        "description": "app.backend.prepdocslib.figureprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.backend.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.fileprocessor",
        "description": "app.backend.prepdocslib.fileprocessor",
        "peekOfCode": "class FileProcessor:\n    parser: Parser\n    splitter: TextSplitter",
        "detail": "app.backend.prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.filestrategy",
        "description": "app.backend.prepdocslib.filestrategy",
        "peekOfCode": "class FileStrategy(Strategy):\n    \"\"\"\n    Strategy for ingesting documents into a search service from files stored either locally or in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],",
        "detail": "app.backend.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "UploadUserFileStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.filestrategy",
        "description": "app.backend.prepdocslib.filestrategy",
        "peekOfCode": "class UploadUserFileStrategy:\n    \"\"\"\n    Strategy for ingesting a file that has already been uploaded to a ADLS2 storage account\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],\n        blob_manager: AdlsBlobManager,\n        search_field_name_embedding: Optional[str] = None,",
        "detail": "app.backend.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.filestrategy",
        "description": "app.backend.prepdocslib.filestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def parse_file(\n    file: File,\n    file_processors: dict[str, FileProcessor],\n    category: Optional[str] = None,\n    blob_manager: Optional[BaseBlobManager] = None,\n    image_embeddings_client: Optional[ImageEmbeddings] = None,\n    figure_processor: Optional[FigureProcessor] = None,\n    user_oid: Optional[str] = None,\n) -> list[Section]:",
        "detail": "app.backend.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "LocalHTMLParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.htmlparser",
        "description": "app.backend.prepdocslib.htmlparser",
        "peekOfCode": "class LocalHTMLParser(Parser):\n    \"\"\"Parses HTML text into Page objects.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        \"\"\"Parses the given content.\n        To learn more, please visit https://pypi.org/project/beautifulsoup4/\n        Args:\n            content (IO): The content to parse.\n        Returns:\n            Page: The parsed html Page.\n        \"\"\"",
        "detail": "app.backend.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.htmlparser",
        "description": "app.backend.prepdocslib.htmlparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.backend.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.htmlparser",
        "description": "app.backend.prepdocslib.htmlparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)",
        "detail": "app.backend.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "IntegratedVectorizerStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "description": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "class IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,",
        "detail": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "description": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,",
        "detail": "app.backend.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "JsonParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.jsonparser",
        "description": "app.backend.prepdocslib.jsonparser",
        "peekOfCode": "class JsonParser(Parser):\n    \"\"\"\n    Concrete parser that can parse JSON into Page objects. A top-level object becomes a single Page, while a top-level array becomes multiple Page objects.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        offset = 0\n        data = json.loads(content.read())\n        if isinstance(data, list):\n            for i, obj in enumerate(data):\n                offset += 1  # For opening bracket or comma before object",
        "detail": "app.backend.prepdocslib.jsonparser",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.listfilestrategy",
        "description": "app.backend.prepdocslib.listfilestrategy",
        "peekOfCode": "class File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url\n    def filename(self) -> str:",
        "detail": "app.backend.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ListFileStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.listfilestrategy",
        "description": "app.backend.prepdocslib.listfilestrategy",
        "peekOfCode": "class ListFileStrategy(ABC):\n    \"\"\"\n    Abstract strategy for listing files that are located somewhere. For example, on a local computer or remotely in a storage account\n    \"\"\"\n    async def list(self) -> AsyncGenerator[File, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.backend.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.listfilestrategy",
        "description": "app.backend.prepdocslib.listfilestrategy",
        "peekOfCode": "class LocalListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a local filesystem\n    \"\"\"\n    def __init__(self, path_pattern: str, enable_global_documents: bool = False):\n        self.path_pattern = path_pattern\n        self.enable_global_documents = enable_global_documents\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        async for p in self._list_paths(self.path_pattern):\n            yield p",
        "detail": "app.backend.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.listfilestrategy",
        "description": "app.backend.prepdocslib.listfilestrategy",
        "peekOfCode": "class ADLSGen2ListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        data_lake_storage_account: str,\n        data_lake_filesystem: str,\n        data_lake_path: str,\n        credential: AsyncTokenCredential | str,",
        "detail": "app.backend.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.listfilestrategy",
        "description": "app.backend.prepdocslib.listfilestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url",
        "detail": "app.backend.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "MediaDescriber",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.mediadescriber",
        "description": "app.backend.prepdocslib.mediadescriber",
        "peekOfCode": "class MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",",
        "detail": "app.backend.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ContentUnderstandingDescriber",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.mediadescriber",
        "description": "app.backend.prepdocslib.mediadescriber",
        "peekOfCode": "class ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",\n        \"scenario\": \"image\",\n        \"config\": {\"returnDetails\": False},\n        \"fieldSchema\": {",
        "detail": "app.backend.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "MultimodalModelDescriber",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.mediadescriber",
        "description": "app.backend.prepdocslib.mediadescriber",
        "peekOfCode": "class MultimodalModelDescriber(MediaDescriber):\n    def __init__(self, openai_client: AsyncOpenAI, model: str, deployment: Optional[str] = None):\n        self.openai_client = openai_client\n        self.model = model\n        self.deployment = deployment\n    async def describe_image(self, image_bytes: bytes) -> str:\n        def before_retry_sleep(retry_state):\n            logger.info(\"Rate limited on the OpenAI chat completions API, sleeping before retrying...\")\n        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n        image_datauri = f\"data:image/png;base64,{image_base64}\"",
        "detail": "app.backend.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.mediadescriber",
        "description": "app.backend.prepdocslib.mediadescriber",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",",
        "detail": "app.backend.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.page",
        "description": "app.backend.prepdocslib.page",
        "peekOfCode": "class ImageOnPage:\n    bytes: bytes\n    bbox: tuple[float, float, float, float]  # Pixels\n    filename: str\n    figure_id: str\n    page_num: int  # 0-indexed\n    placeholder: str  # HTML placeholder in page text, e.g. '<figure id=\"fig_...\"></figure>'\n    mime_type: str = \"image/png\"  # Set by parser; default assumes PNG rendering\n    url: Optional[str] = None\n    title: str = \"\"",
        "detail": "app.backend.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.page",
        "description": "app.backend.prepdocslib.page",
        "peekOfCode": "class Page:\n    \"\"\"\n    A single page from a document\n    Attributes:\n        page_num (int): Page number (0-indexed)\n        offset (int): If the text of the entire Document was concatenated into a single string, the index of the first character on the page. For example, if page 1 had the text \"hello\" and page 2 had the text \"world\", the offset of page 2 is 5 (\"hellow\")\n        text (str): The text of the page\n    \"\"\"\n    page_num: int\n    offset: int",
        "detail": "app.backend.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.page",
        "description": "app.backend.prepdocslib.page",
        "peekOfCode": "class Chunk:\n    \"\"\"Semantic chunk emitted by the splitter (may originate wholly within one page\n    or be the result of a cross-page merge / trailing fragment carry-forward).\n    Attributes:\n        page_num (int): Logical source page number (0-indexed) for the originating\n            portion of content. For merged content spanning pages we keep the earliest\n            contributing page number for stable attribution.\n        text (str): Textual content of the chunk.\n        images (list[ImageOnPage]): Images associated with this chunk, if any.\n    \"\"\"",
        "detail": "app.backend.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.parser",
        "description": "app.backend.prepdocslib.parser",
        "peekOfCode": "class Parser(ABC):\n    \"\"\"\n    Abstract parser that parses content into Page objects\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        if False:\n            yield  # pragma: no cover - this is necessary for mypy to type check",
        "detail": "app.backend.prepdocslib.parser",
        "documentation": {}
    },
    {
        "label": "LocalPdfParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.pdfparser",
        "description": "app.backend.prepdocslib.pdfparser",
        "peekOfCode": "class LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages\n        offset = 0",
        "detail": "app.backend.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.pdfparser",
        "description": "app.backend.prepdocslib.pdfparser",
        "peekOfCode": "class DocumentAnalysisParser(Parser):\n    \"\"\"\n    Concrete parser backed by Azure AI Document Intelligence that can parse many document formats into pages\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/document-intelligence/overview\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        model_id: str = \"prebuilt-layout\",",
        "detail": "app.backend.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.pdfparser",
        "description": "app.backend.prepdocslib.pdfparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages",
        "detail": "app.backend.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "Section",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.searchmanager",
        "description": "app.backend.prepdocslib.searchmanager",
        "peekOfCode": "class Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field\nclass SearchManager:",
        "detail": "app.backend.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.searchmanager",
        "description": "app.backend.prepdocslib.searchmanager",
        "peekOfCode": "class SearchManager:\n    \"\"\"\n    Class to manage a search service. It can create indexes, and update or remove sections stored in these indexes\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        search_analyzer_name: Optional[str] = None,\n        use_acls: bool = False,",
        "detail": "app.backend.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.searchmanager",
        "description": "app.backend.prepdocslib.searchmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field",
        "detail": "app.backend.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "class OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).\n    LOCAL:        A locally hosted OpenAI-compatible endpoint (no key required).\n    \"\"\"\n    OPENAI = \"openai\"\n    AZURE = \"azure\"\n    AZURE_CUSTOM = \"azure_custom\"",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_search_info(\n    search_service: str,\n    index_name: str,\n    azure_credential: AsyncTokenCredential,\n    use_agentic_retrieval: Optional[bool] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    agent_name: Optional[str] = None,\n    agent_max_output_tokens: Optional[int] = None,\n    azure_openai_searchagent_deployment: Optional[str] = None,\n    azure_openai_searchagent_model: Optional[str] = None,",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_openai_client(\n    openai_host: OpenAIHost,\n    azure_credential: AsyncTokenCredential,\n    azure_openai_api_key: Optional[str] = None,\n    azure_openai_service: Optional[str] = None,\n    azure_openai_custom_url: Optional[str] = None,\n    openai_api_key: Optional[str] = None,\n    openai_organization: Optional[str] = None,\n) -> tuple[AsyncOpenAI, Optional[str]]:\n    openai_client: AsyncOpenAI",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_image_embeddings_service(\n    azure_credential: AsyncTokenCredential,\n    vision_endpoint: Optional[str],\n    use_multimodal: bool,\n) -> ImageEmbeddings | None:\n    image_embeddings_service: Optional[ImageEmbeddings] = None\n    if use_multimodal:\n        if vision_endpoint is None:\n            raise ValueError(\"An Azure AI Vision endpoint must be provided to use multimodal features.\")\n        image_embeddings_service = ImageEmbeddings(",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_embeddings_service(\n    openai_host: OpenAIHost,\n    open_ai_client: AsyncOpenAI,\n    emb_model_name: str,\n    emb_model_dimensions: int,\n    azure_openai_deployment: Optional[str] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    disable_batch: bool = False,\n) -> OpenAIEmbeddings:\n    if openai_host in [OpenAIHost.AZURE, OpenAIHost.AZURE_CUSTOM]:",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_blob_manager(\n    azure_credential: AsyncTokenCredential | str,\n    storage_account: str,\n    storage_container: str,\n    storage_resource_group: Optional[str] = None,\n    subscription_id: Optional[str] = None,\n    storage_key: Optional[str] = None,\n    image_storage_container: Optional[str] = None,\n) -> BlobManager:\n    \"\"\"Create a BlobManager instance for document or figure storage.",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def setup_figure_processor(\n    *,\n    credential: AsyncTokenCredential | None,\n    use_multimodal: bool,\n    use_content_understanding: bool,\n    content_understanding_endpoint: str | None,\n    openai_client: object | None,\n    openai_model: str | None,\n    openai_deployment: str | None,\n) -> FigureProcessor | None:",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def build_file_processors(\n    *,\n    azure_credential: AsyncTokenCredential,\n    document_intelligence_service: str | None,\n    document_intelligence_key: str | None = None,\n    use_local_pdf_parser: bool = False,\n    use_local_html_parser: bool = False,\n    process_figures: bool = False,\n) -> dict[str, FileProcessor]:\n    sentence_text_splitter = SentenceTextSplitter()",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "def select_processor_for_filename(file_name: str, file_processors: dict[str, FileProcessor]) -> FileProcessor:\n    \"\"\"Select the appropriate file processor for a given filename.\n    Args:\n        file_name: Name of the file to process\n        file_processors: Dictionary mapping file extensions to FileProcessor instances\n    Returns:\n        FileProcessor instance for the file\n    Raises:\n        ValueError: If the file extension is not supported\n    \"\"\"",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.servicesetup",
        "description": "app.backend.prepdocslib.servicesetup",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).",
        "detail": "app.backend.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.strategy",
        "description": "app.backend.prepdocslib.strategy",
        "peekOfCode": "class SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        index_name: str,",
        "detail": "app.backend.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.strategy",
        "description": "app.backend.prepdocslib.strategy",
        "peekOfCode": "class DocumentAction(Enum):\n    Add = 0\n    Remove = 1\n    RemoveAll = 2\nclass Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError",
        "detail": "app.backend.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.strategy",
        "description": "app.backend.prepdocslib.strategy",
        "peekOfCode": "class Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError\n    async def run(self):\n        raise NotImplementedError",
        "detail": "app.backend.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.strategy",
        "description": "app.backend.prepdocslib.strategy",
        "peekOfCode": "USER_AGENT = \"azure-search-chat-demo/1.0.0\"\nclass SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,",
        "detail": "app.backend.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.textparser",
        "description": "app.backend.prepdocslib.textparser",
        "peekOfCode": "class TextParser(Parser):\n    \"\"\"Parses simple text into a Page object.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        data = content.read()\n        decoded_data = data.decode(\"utf-8\")\n        text = cleanup_data(decoded_data)\n        yield Page(0, 0, text=text)",
        "detail": "app.backend.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.textparser",
        "description": "app.backend.prepdocslib.textparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.backend.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "combine_text_with_figures",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.textprocessor",
        "description": "app.backend.prepdocslib.textprocessor",
        "peekOfCode": "def combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)\n        elif image.placeholder not in page.text:",
        "detail": "app.backend.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "process_text",
        "kind": 2,
        "importPath": "app.backend.prepdocslib.textprocessor",
        "description": "app.backend.prepdocslib.textprocessor",
        "peekOfCode": "def process_text(\n    pages: list[\"Page\"],\n    file: \"File\",\n    splitter: \"TextSplitter\",\n    category: str | None = None,\n) -> list[\"Section\"]:\n    \"\"\"Process document text and figures into searchable sections.\n    Combines text with figure descriptions, splits into chunks, and\n    associates figures with their containing sections.\n    \"\"\"",
        "detail": "app.backend.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textprocessor",
        "description": "app.backend.prepdocslib.textprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)",
        "detail": "app.backend.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "TextSplitter",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "class TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\nENCODING_MODEL = \"text-embedding-ada-002\"",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "_ChunkBuilder",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "class _ChunkBuilder:\n    \"\"\"Accumulates sentence-like spans for a single page until size limits are reached.\n    Responsibilities:\n    - Track appended text fragments and their approximate token length.\n    - Decide if a new span can be added without exceeding character or token thresholds.\n    - Flush accumulated content into an output list as a `Chunk`.\n    - Allow a figure block to be force-appended (even if it overflows) so that headings + figure stay together.\n    Notes:\n    - Character limit is soft (exact enforcement + later normalization); token limit is hard.\n    - Token counts are computed by the caller and passed to `add`; this class stays agnostic of the encoder.",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "class SentenceTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks. This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_tokens_per_section: int = 500):\n        self.sentence_endings = STANDARD_SENTENCE_ENDINGS + CJK_SENTENCE_ENDINGS\n        self.word_breaks = STANDARD_WORD_BREAKS + CJK_WORD_BREAKS\n        self.max_section_length = DEFAULT_SECTION_LENGTH\n        self.sentence_search_limit = 100\n        self.max_tokens_per_section = max_tokens_per_section",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "kind": 6,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "class SimpleTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks based on a max object length. It is not aware of the content of the page.\n    This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_object_length: int = 1000):\n        self.max_object_length = max_object_length\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        all_text = \"\".join(page.text for page in pages)\n        if len(all_text.strip()) == 0:",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "ENCODING_MODEL",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "ENCODING_MODEL = \"text-embedding-ada-002\"\nSTANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "CJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n# See CL05 and CL06, based on JIS X 4051:2004\n# https://www.w3.org/TR/jlreq/#cl-04\nCJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "CJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "bpe",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OVERLAP_PERCENT",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SECTION_LENGTH",
        "kind": 5,
        "importPath": "app.backend.prepdocslib.textsplitter",
        "description": "app.backend.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.\n    - Otherwise concatenate directly.",
        "detail": "app.backend.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "JSONEncoder",
        "kind": 6,
        "importPath": "app.backend.app",
        "description": "app.backend.app",
        "peekOfCode": "class JSONEncoder(json.JSONEncoder):\n    def default(self, o):\n        if dataclasses.is_dataclass(o) and not isinstance(o, type):\n            return dataclasses.asdict(o)\n        return super().default(o)\nasync def format_as_ndjson(r: AsyncGenerator[dict, None]) -> AsyncGenerator[str, None]:\n    try:\n        async for event in r:\n            yield json.dumps(event, ensure_ascii=False, cls=JSONEncoder) + \"\\n\"\n    except Exception as error:",
        "detail": "app.backend.app",
        "documentation": {}
    },
    {
        "label": "auth_setup",
        "kind": 2,
        "importPath": "app.backend.app",
        "description": "app.backend.app",
        "peekOfCode": "def auth_setup():\n    auth_helper = current_app.config[CONFIG_AUTH_CLIENT]\n    return jsonify(auth_helper.get_auth_setup_for_client())\n@bp.route(\"/config\", methods=[\"GET\"])\ndef config():\n    return jsonify(\n        {\n            \"showMultimodalOptions\": current_app.config[CONFIG_MULTIMODAL_ENABLED],\n            \"showSemanticRankerOption\": current_app.config[CONFIG_SEMANTIC_RANKER_DEPLOYED],\n            \"showQueryRewritingOption\": current_app.config[CONFIG_QUERY_REWRITING_ENABLED],",
        "detail": "app.backend.app",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 2,
        "importPath": "app.backend.app",
        "description": "app.backend.app",
        "peekOfCode": "def config():\n    return jsonify(\n        {\n            \"showMultimodalOptions\": current_app.config[CONFIG_MULTIMODAL_ENABLED],\n            \"showSemanticRankerOption\": current_app.config[CONFIG_SEMANTIC_RANKER_DEPLOYED],\n            \"showQueryRewritingOption\": current_app.config[CONFIG_QUERY_REWRITING_ENABLED],\n            \"showReasoningEffortOption\": current_app.config[CONFIG_REASONING_EFFORT_ENABLED],\n            \"streamingEnabled\": current_app.config[CONFIG_STREAMING_ENABLED],\n            \"defaultReasoningEffort\": current_app.config[CONFIG_DEFAULT_REASONING_EFFORT],\n            \"showVectorOption\": current_app.config[CONFIG_VECTOR_SEARCH_ENABLED],",
        "detail": "app.backend.app",
        "documentation": {}
    },
    {
        "label": "create_app",
        "kind": 2,
        "importPath": "app.backend.app",
        "description": "app.backend.app",
        "peekOfCode": "def create_app():\n    app = Quart(__name__)\n    app.register_blueprint(bp)\n    app.register_blueprint(chat_history_cosmosdb_bp)\n    if os.getenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\"):\n        app.logger.info(\"APPLICATIONINSIGHTS_CONNECTION_STRING is set, enabling Azure Monitor\")\n        configure_azure_monitor(\n            instrumentation_options={\n                \"django\": {\"enabled\": False},\n                \"psycopg2\": {\"enabled\": False},",
        "detail": "app.backend.app",
        "documentation": {}
    },
    {
        "label": "bp",
        "kind": 5,
        "importPath": "app.backend.app",
        "description": "app.backend.app",
        "peekOfCode": "bp = Blueprint(\"routes\", __name__, static_folder=\"static\")\n# Fix Windows registry issue with mimetypes\nmimetypes.add_type(\"application/javascript\", \".js\")\nmimetypes.add_type(\"text/css\", \".css\")\n@bp.route(\"/\")\nasync def index():\n    return await bp.send_static_file(\"index.html\")\n# Empty page is recommended for login redirect to work.\n# See https://github.com/AzureAD/microsoft-authentication-library-for-js/blob/dev/lib/msal-browser/docs/initialization.md#redirecturi-considerations for more information\n@bp.route(\"/redirect\")",
        "detail": "app.backend.app",
        "documentation": {}
    },
    {
        "label": "CONFIG_OPENAI_TOKEN",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_OPENAI_TOKEN = \"openai_token\"\nCONFIG_CREDENTIAL = \"azure_credential\"\nCONFIG_ASK_APPROACH = \"ask_approach\"\nCONFIG_CHAT_APPROACH = \"chat_approach\"\nCONFIG_GLOBAL_BLOB_MANAGER = \"global_blob_manager\"\nCONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CREDENTIAL",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_CREDENTIAL = \"azure_credential\"\nCONFIG_ASK_APPROACH = \"ask_approach\"\nCONFIG_CHAT_APPROACH = \"chat_approach\"\nCONFIG_GLOBAL_BLOB_MANAGER = \"global_blob_manager\"\nCONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_ASK_APPROACH",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_ASK_APPROACH = \"ask_approach\"\nCONFIG_CHAT_APPROACH = \"chat_approach\"\nCONFIG_GLOBAL_BLOB_MANAGER = \"global_blob_manager\"\nCONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_APPROACH",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_CHAT_APPROACH = \"chat_approach\"\nCONFIG_GLOBAL_BLOB_MANAGER = \"global_blob_manager\"\nCONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_GLOBAL_BLOB_MANAGER",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_GLOBAL_BLOB_MANAGER = \"global_blob_manager\"\nCONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_USER_BLOB_MANAGER",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_USER_BLOB_MANAGER = \"user_blob_manager\"\nCONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_USER_UPLOAD_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_USER_UPLOAD_ENABLED = \"user_upload_enabled\"\nCONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AUTH_CLIENT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_AUTH_CLIENT = \"auth_client\"\nCONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SEMANTIC_RANKER_DEPLOYED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SEMANTIC_RANKER_DEPLOYED = \"semantic_ranker_deployed\"\nCONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_QUERY_REWRITING_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_QUERY_REWRITING_ENABLED = \"query_rewriting_enabled\"\nCONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_REASONING_EFFORT_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_REASONING_EFFORT_ENABLED = \"reasoning_effort_enabled\"\nCONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_DEFAULT_REASONING_EFFORT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_DEFAULT_REASONING_EFFORT = \"default_reasoning_effort\"\nCONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_VECTOR_SEARCH_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_VECTOR_SEARCH_ENABLED = \"vector_search_enabled\"\nCONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SEARCH_CLIENT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SEARCH_CLIENT = \"search_client\"\nCONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_OPENAI_CLIENT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_OPENAI_CLIENT = \"openai_client\"\nCONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AGENT_CLIENT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_AGENT_CLIENT = \"agent_client\"\nCONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_INGESTER",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_INGESTER = \"ingester\"\nCONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_LANGUAGE_PICKER_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_LANGUAGE_PICKER_ENABLED = \"language_picker_enabled\"\nCONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_INPUT_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_INPUT_ENABLED = \"speech_input_enabled\"\nCONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_OUTPUT_BROWSER_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_OUTPUT_BROWSER_ENABLED = \"speech_output_browser_enabled\"\nCONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_OUTPUT_AZURE_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_OUTPUT_AZURE_ENABLED = \"speech_output_azure_enabled\"\nCONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_ID",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_SERVICE_ID = \"speech_service_id\"\nCONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_LOCATION",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_SERVICE_LOCATION = \"speech_service_location\"\nCONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_TOKEN",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_SERVICE_TOKEN = \"speech_service_token\"\nCONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_SPEECH_SERVICE_VOICE",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_SPEECH_SERVICE_VOICE = \"speech_service_voice\"\nCONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_STREAMING_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_STREAMING_ENABLED = \"streaming_enabled\"\nCONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_HISTORY_BROWSER_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_CHAT_HISTORY_BROWSER_ENABLED = \"chat_history_browser_enabled\"\nCONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_CHAT_HISTORY_COSMOS_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_CHAT_HISTORY_COSMOS_ENABLED = \"chat_history_cosmos_enabled\"\nCONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_AGENTIC_RETRIEVAL_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_AGENTIC_RETRIEVAL_ENABLED = \"agentic_retrieval\"\nCONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_CLIENT",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_COSMOS_HISTORY_CLIENT = \"cosmos_history_client\"\nCONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_CONTAINER",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_COSMOS_HISTORY_CONTAINER = \"cosmos_history_container\"\nCONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_COSMOS_HISTORY_VERSION",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_COSMOS_HISTORY_VERSION = \"cosmos_history_version\"\nCONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_MULTIMODAL_ENABLED",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_MULTIMODAL_ENABLED = \"multimodal_enabled\"\nCONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEARCH_TEXT_EMBEDDINGS",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_RAG_SEARCH_TEXT_EMBEDDINGS = \"rag_search_text_embeddings\"\nCONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_RAG_SEARCH_IMAGE_EMBEDDINGS = \"rag_search_image_embeddings\"\nCONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEND_TEXT_SOURCES",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_RAG_SEND_TEXT_SOURCES = \"rag_send_text_sources\"\nCONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CONFIG_RAG_SEND_IMAGE_SOURCES",
        "kind": 5,
        "importPath": "app.backend.config",
        "description": "app.backend.config",
        "peekOfCode": "CONFIG_RAG_SEND_IMAGE_SOURCES = \"rag_send_image_sources\"",
        "detail": "app.backend.config",
        "documentation": {}
    },
    {
        "label": "CustomUvicornWorker",
        "kind": 6,
        "importPath": "app.backend.custom_uvicorn_worker",
        "description": "app.backend.custom_uvicorn_worker",
        "peekOfCode": "class CustomUvicornWorker(UvicornWorker):\n    CONFIG_KWARGS = {\n        \"log_config\": logconfig_dict,\n    }",
        "detail": "app.backend.custom_uvicorn_worker",
        "documentation": {}
    },
    {
        "label": "logconfig_dict",
        "kind": 5,
        "importPath": "app.backend.custom_uvicorn_worker",
        "description": "app.backend.custom_uvicorn_worker",
        "peekOfCode": "logconfig_dict = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"formatters\": {\n        \"default\": {\n            \"()\": \"uvicorn.logging.DefaultFormatter\",\n            \"format\": \"%(asctime)s - %(levelname)s - %(message)s\",\n        },\n        \"access\": {\n            \"()\": \"uvicorn.logging.AccessFormatter\",",
        "detail": "app.backend.custom_uvicorn_worker",
        "documentation": {}
    },
    {
        "label": "authenticated_path",
        "kind": 2,
        "importPath": "app.backend.decorators",
        "description": "app.backend.decorators",
        "peekOfCode": "def authenticated_path(route_fn: Callable[[str, dict[str, Any]], Any]):\n    \"\"\"\n    Decorator for routes that request a specific file that might require access control enforcement\n    \"\"\"\n    @wraps(route_fn)\n    async def auth_handler(path=\"\"):\n        # If authentication is enabled, validate the user can access the file\n        auth_helper = current_app.config[CONFIG_AUTH_CLIENT]\n        search_client = current_app.config[CONFIG_SEARCH_CLIENT]\n        authorized = False",
        "detail": "app.backend.decorators",
        "documentation": {}
    },
    {
        "label": "authenticated",
        "kind": 2,
        "importPath": "app.backend.decorators",
        "description": "app.backend.decorators",
        "peekOfCode": "def authenticated(route_fn: _C) -> _C:\n    \"\"\"\n    Decorator for routes that might require access control. Unpacks Authorization header information into an auth_claims dictionary\n    \"\"\"\n    @wraps(route_fn)\n    async def auth_handler(*args, **kwargs):\n        auth_helper = current_app.config[CONFIG_AUTH_CLIENT]\n        try:\n            auth_claims = await auth_helper.get_auth_claims_if_enabled(request.headers)\n        except AuthError:",
        "detail": "app.backend.decorators",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "app.backend.decorators",
        "description": "app.backend.decorators",
        "peekOfCode": "_C = TypeVar(\"_C\", bound=Callable[..., Any])\ndef authenticated(route_fn: _C) -> _C:\n    \"\"\"\n    Decorator for routes that might require access control. Unpacks Authorization header information into an auth_claims dictionary\n    \"\"\"\n    @wraps(route_fn)\n    async def auth_handler(*args, **kwargs):\n        auth_helper = current_app.config[CONFIG_AUTH_CLIENT]\n        try:\n            auth_claims = await auth_helper.get_auth_claims_if_enabled(request.headers)",
        "detail": "app.backend.decorators",
        "documentation": {}
    },
    {
        "label": "error_dict",
        "kind": 2,
        "importPath": "app.backend.error",
        "description": "app.backend.error",
        "peekOfCode": "def error_dict(error: Exception) -> dict:\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        return {\"error\": ERROR_MESSAGE_FILTER}\n    if isinstance(error, APIError) and error.code == \"context_length_exceeded\":\n        return {\"error\": ERROR_MESSAGE_LENGTH}\n    return {\"error\": ERROR_MESSAGE.format(error_type=type(error))}\ndef error_response(error: Exception, route: str, status_code: int = 500):\n    logging.exception(\"Exception in %s: %s\", route, error)\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        status_code = 400",
        "detail": "app.backend.error",
        "documentation": {}
    },
    {
        "label": "error_response",
        "kind": 2,
        "importPath": "app.backend.error",
        "description": "app.backend.error",
        "peekOfCode": "def error_response(error: Exception, route: str, status_code: int = 500):\n    logging.exception(\"Exception in %s: %s\", route, error)\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        status_code = 400\n    return jsonify(error_dict(error)), status_code",
        "detail": "app.backend.error",
        "documentation": {}
    },
    {
        "label": "ERROR_MESSAGE",
        "kind": 5,
        "importPath": "app.backend.error",
        "description": "app.backend.error",
        "peekOfCode": "ERROR_MESSAGE = \"\"\"The app encountered an error processing your request.\nIf you are an administrator of the app, check the application logs for a full traceback.\nError type: {error_type}\n\"\"\"\nERROR_MESSAGE_FILTER = \"\"\"Your message contains content that was flagged by the OpenAI content filter.\"\"\"\nERROR_MESSAGE_LENGTH = \"\"\"Your message exceeded the context length limit for this OpenAI model. Please shorten your message or change your settings to retrieve fewer search results.\"\"\"\ndef error_dict(error: Exception) -> dict:\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        return {\"error\": ERROR_MESSAGE_FILTER}\n    if isinstance(error, APIError) and error.code == \"context_length_exceeded\":",
        "detail": "app.backend.error",
        "documentation": {}
    },
    {
        "label": "ERROR_MESSAGE_FILTER",
        "kind": 5,
        "importPath": "app.backend.error",
        "description": "app.backend.error",
        "peekOfCode": "ERROR_MESSAGE_FILTER = \"\"\"Your message contains content that was flagged by the OpenAI content filter.\"\"\"\nERROR_MESSAGE_LENGTH = \"\"\"Your message exceeded the context length limit for this OpenAI model. Please shorten your message or change your settings to retrieve fewer search results.\"\"\"\ndef error_dict(error: Exception) -> dict:\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        return {\"error\": ERROR_MESSAGE_FILTER}\n    if isinstance(error, APIError) and error.code == \"context_length_exceeded\":\n        return {\"error\": ERROR_MESSAGE_LENGTH}\n    return {\"error\": ERROR_MESSAGE.format(error_type=type(error))}\ndef error_response(error: Exception, route: str, status_code: int = 500):\n    logging.exception(\"Exception in %s: %s\", route, error)",
        "detail": "app.backend.error",
        "documentation": {}
    },
    {
        "label": "ERROR_MESSAGE_LENGTH",
        "kind": 5,
        "importPath": "app.backend.error",
        "description": "app.backend.error",
        "peekOfCode": "ERROR_MESSAGE_LENGTH = \"\"\"Your message exceeded the context length limit for this OpenAI model. Please shorten your message or change your settings to retrieve fewer search results.\"\"\"\ndef error_dict(error: Exception) -> dict:\n    if isinstance(error, APIError) and error.code == \"content_filter\":\n        return {\"error\": ERROR_MESSAGE_FILTER}\n    if isinstance(error, APIError) and error.code == \"context_length_exceeded\":\n        return {\"error\": ERROR_MESSAGE_LENGTH}\n    return {\"error\": ERROR_MESSAGE.format(error_type=type(error))}\ndef error_response(error: Exception, route: str, status_code: int = 500):\n    logging.exception(\"Exception in %s: %s\", route, error)\n    if isinstance(error, APIError) and error.code == \"content_filter\":",
        "detail": "app.backend.error",
        "documentation": {}
    },
    {
        "label": "max_requests",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "max_requests = 1000\nmax_requests_jitter = 50\nlog_file = \"-\"\nbind = \"0.0.0.0\"\ntimeout = 230\n# https://learn.microsoft.com/troubleshoot/azure/app-service/web-apps-performance-faqs#why-does-my-request-time-out-after-230-seconds\nnum_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "max_requests_jitter",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "max_requests_jitter = 50\nlog_file = \"-\"\nbind = \"0.0.0.0\"\ntimeout = 230\n# https://learn.microsoft.com/troubleshoot/azure/app-service/web-apps-performance-faqs#why-does-my-request-time-out-after-230-seconds\nnum_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1\nelse:",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "log_file",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "log_file = \"-\"\nbind = \"0.0.0.0\"\ntimeout = 230\n# https://learn.microsoft.com/troubleshoot/azure/app-service/web-apps-performance-faqs#why-does-my-request-time-out-after-230-seconds\nnum_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1\nelse:\n    workers = (num_cpus * 2) + 1",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "bind",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "bind = \"0.0.0.0\"\ntimeout = 230\n# https://learn.microsoft.com/troubleshoot/azure/app-service/web-apps-performance-faqs#why-does-my-request-time-out-after-230-seconds\nnum_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1\nelse:\n    workers = (num_cpus * 2) + 1\nworker_class = \"custom_uvicorn_worker.CustomUvicornWorker\"",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "timeout",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "timeout = 230\n# https://learn.microsoft.com/troubleshoot/azure/app-service/web-apps-performance-faqs#why-does-my-request-time-out-after-230-seconds\nnum_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1\nelse:\n    workers = (num_cpus * 2) + 1\nworker_class = \"custom_uvicorn_worker.CustomUvicornWorker\"",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "num_cpus",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "num_cpus = multiprocessing.cpu_count()\nif os.getenv(\"WEBSITE_SKU\") == \"LinuxFree\":\n    # Free tier reports 2 CPUs but can't handle multiple workers\n    workers = 1\nelse:\n    workers = (num_cpus * 2) + 1\nworker_class = \"custom_uvicorn_worker.CustomUvicornWorker\"",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "worker_class",
        "kind": 5,
        "importPath": "app.backend.gunicorn.conf",
        "description": "app.backend.gunicorn.conf",
        "peekOfCode": "worker_class = \"custom_uvicorn_worker.CustomUvicornWorker\"",
        "detail": "app.backend.gunicorn.conf",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "kind": 2,
        "importPath": "app.backend.load_azd_env",
        "description": "app.backend.load_azd_env",
        "peekOfCode": "def load_azd_env():\n    \"\"\"Get path to current azd env file and load file using python-dotenv\"\"\"\n    result = subprocess.run(\"azd env list -o json\", shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise Exception(\"Error loading azd env\")\n    env_json = json.loads(result.stdout)\n    env_file_path = None\n    for entry in env_json:\n        if entry[\"IsDefault\"]:\n            env_file_path = entry[\"DotEnvPath\"]",
        "detail": "app.backend.load_azd_env",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.load_azd_env",
        "description": "app.backend.load_azd_env",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef load_azd_env():\n    \"\"\"Get path to current azd env file and load file using python-dotenv\"\"\"\n    result = subprocess.run(\"azd env list -o json\", shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise Exception(\"Error loading azd env\")\n    env_json = json.loads(result.stdout)\n    env_file_path = None\n    for entry in env_json:\n        if entry[\"IsDefault\"]:",
        "detail": "app.backend.load_azd_env",
        "documentation": {}
    },
    {
        "label": "RUNNING_ON_AZURE",
        "kind": 5,
        "importPath": "app.backend.main",
        "description": "app.backend.main",
        "peekOfCode": "RUNNING_ON_AZURE = os.getenv(\"WEBSITE_HOSTNAME\") is not None or os.getenv(\"RUNNING_IN_PRODUCTION\") is not None\nif not RUNNING_ON_AZURE:\n    load_azd_env()\napp = create_app()",
        "detail": "app.backend.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app.backend.main",
        "description": "app.backend.main",
        "peekOfCode": "app = create_app()",
        "detail": "app.backend.main",
        "documentation": {}
    },
    {
        "label": "setup_list_file_strategy",
        "kind": 2,
        "importPath": "app.backend.prepdocs",
        "description": "app.backend.prepdocs",
        "peekOfCode": "def setup_list_file_strategy(\n    azure_credential: AsyncTokenCredential,\n    local_files: Optional[str],\n    datalake_storage_account: Optional[str],\n    datalake_filesystem: Optional[str],\n    datalake_path: Optional[str],\n    datalake_key: Optional[str],\n    enable_global_documents: bool = False,\n):\n    list_file_strategy: ListFileStrategy",
        "detail": "app.backend.prepdocs",
        "documentation": {}
    },
    {
        "label": "setup_file_processors",
        "kind": 2,
        "importPath": "app.backend.prepdocs",
        "description": "app.backend.prepdocs",
        "peekOfCode": "def setup_file_processors(\n    azure_credential: AsyncTokenCredential,\n    document_intelligence_service: Optional[str],\n    document_intelligence_key: Optional[str] = None,\n    local_pdf_parser: bool = False,\n    local_html_parser: bool = False,\n    use_content_understanding: bool = False,\n    use_multimodal: bool = False,\n    openai_client: Optional[AsyncOpenAI] = None,\n    openai_model: Optional[str] = None,",
        "detail": "app.backend.prepdocs",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.prepdocs",
        "description": "app.backend.prepdocs",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def check_search_service_connectivity(search_service: str) -> bool:\n    \"\"\"Check if the search service is accessible by hitting the /ping endpoint.\"\"\"\n    ping_url = f\"https://{search_service}.search.windows.net/ping\"\n    try:\n        async with aiohttp.ClientSession() as session:\n            async with session.get(ping_url, timeout=aiohttp.ClientTimeout(total=10)) as response:\n                return response.status == 200\n    except Exception as e:\n        logger.debug(f\"Search service ping failed: {e}\")",
        "detail": "app.backend.prepdocs",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.backend.setup_cloud_ingestion",
        "description": "app.backend.setup_cloud_ingestion",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def setup_cloud_ingestion_strategy(\n    azure_credential: AsyncTokenCredential,\n    document_action: DocumentAction = DocumentAction.Add,\n) -> tuple[CloudIngestionStrategy, AsyncOpenAI, AsyncTokenCredential, BlobManager]:\n    \"\"\"Setup the cloud ingestion strategy with all required services.\"\"\"\n    # Get environment variables\n    search_service = os.environ[\"AZURE_SEARCH_SERVICE\"]\n    index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n    search_user_assigned_identity_resource_id = os.environ[\"AZURE_SEARCH_USER_ASSIGNED_IDENTITY_RESOURCE_ID\"]",
        "detail": "app.backend.setup_cloud_ingestion",
        "documentation": {}
    },
    {
        "label": "BlobProperties",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.blobmanager",
        "description": "app.functions.document_extractor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":",
        "detail": "app.functions.document_extractor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BaseBlobManager",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.blobmanager",
        "description": "app.functions.document_extractor.prepdocslib.blobmanager",
        "peekOfCode": "class BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":\n            return f\"{os.path.basename(filename)}#page={page+1}\"\n        else:\n            return os.path.basename(filename)",
        "detail": "app.functions.document_extractor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.blobmanager",
        "description": "app.functions.document_extractor.prepdocslib.blobmanager",
        "peekOfCode": "class AdlsBlobManager(BaseBlobManager):\n    \"\"\"\n    Manager for Azure Data Lake Storage blob operations, particularly for user-specific file operations.\n    Documents are stored directly in the user's directory for backwards compatibility.\n    Images are stored in a separate images subdirectory for better organization.\n    \"\"\"\n    def __init__(self, endpoint: str, container: str, credential: AsyncTokenCredential):\n        \"\"\"\n        Initializes the AdlsBlobManager with the necessary parameters.\n        Args:",
        "detail": "app.functions.document_extractor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.blobmanager",
        "description": "app.functions.document_extractor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobManager(BaseBlobManager):\n    \"\"\"\n    Class to manage uploading and deleting blobs containing citation information from a blob storage account\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        container: str,\n        credential: AsyncTokenCredential | str,\n        image_container: Optional[str] = None,",
        "detail": "app.functions.document_extractor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.blobmanager",
        "description": "app.functions.document_extractor.prepdocslib.blobmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:",
        "detail": "app.functions.document_extractor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "SkillConfig",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CloudIngestionStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,\n        *,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,\n        search_field_name_embedding: str,",
        "detail": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nDEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str",
        "detail": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SKILL_TIMEOUT",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover",
        "detail": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_BATCH_SIZE",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CsvParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.csvparser",
        "description": "app.functions.document_extractor.prepdocslib.csvparser",
        "peekOfCode": "class CsvParser(Parser):\n    \"\"\"\n    Concrete parser that can parse CSV into Page objects. Each row becomes a Page object.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        # Check if content is in bytes (binary file) and decode to string\n        content_str: str\n        if isinstance(content, (bytes, bytearray)):\n            content_str = content.decode(\"utf-8\")\n        elif hasattr(content, \"read\"):  # Handle BufferedReader",
        "detail": "app.functions.document_extractor.prepdocslib.csvparser",
        "documentation": {}
    },
    {
        "label": "EmbeddingBatch",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.embeddings",
        "description": "app.functions.document_extractor.prepdocslib.embeddings",
        "peekOfCode": "class EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {",
        "detail": "app.functions.document_extractor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ExtraArgs",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.embeddings",
        "description": "app.functions.document_extractor.prepdocslib.embeddings",
        "peekOfCode": "class ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {",
        "detail": "app.functions.document_extractor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.embeddings",
        "description": "app.functions.document_extractor.prepdocslib.embeddings",
        "peekOfCode": "class OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {\n        \"text-embedding-ada-002\": False,\n        \"text-embedding-3-small\": True,",
        "detail": "app.functions.document_extractor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.embeddings",
        "description": "app.functions.document_extractor.prepdocslib.embeddings",
        "peekOfCode": "class ImageEmbeddings:\n    \"\"\"\n    Class for using image embeddings from Azure AI Vision\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-image-api\n    \"\"\"\n    def __init__(self, endpoint: str, token_provider: Callable[[], Awaitable[str]]):\n        self.token_provider = token_provider\n        self.endpoint = endpoint\n    async def create_embedding_for_image(self, image_bytes: bytes) -> list[float]:\n        endpoint = urljoin(self.endpoint, \"computervision/retrieval:vectorizeImage\")",
        "detail": "app.functions.document_extractor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.embeddings",
        "description": "app.functions.document_extractor.prepdocslib.embeddings",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "description": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "peekOfCode": "class MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,",
        "detail": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "description": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "peekOfCode": "class FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,\n        credential: AsyncTokenCredential | AzureKeyCredential | None = None,\n        strategy: MediaDescriptionStrategy = MediaDescriptionStrategy.NONE,\n        openai_client: Any | None = None,\n        openai_model: str | None = None,\n        openai_deployment: str | None = None,",
        "detail": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "build_figure_markup",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "description": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "peekOfCode": "def build_figure_markup(image: \"ImageOnPage\", description: Optional[str] = None) -> str:\n    \"\"\"Create consistent HTML markup for a figure description on demand.\"\"\"\n    caption_parts = [image.figure_id]\n    if image.title:\n        caption_parts.append(image.title)\n    caption = \" \".join(part for part in caption_parts if part)\n    if description:\n        return f\"<figure><figcaption>{caption}<br>{description}</figcaption></figure>\"\n    return f\"<figure><figcaption>{caption}</figcaption></figure>\"\nasync def process_page_image(",
        "detail": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "description": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.document_extractor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.fileprocessor",
        "description": "app.functions.document_extractor.prepdocslib.fileprocessor",
        "peekOfCode": "class FileProcessor:\n    parser: Parser\n    splitter: TextSplitter",
        "detail": "app.functions.document_extractor.prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.filestrategy",
        "description": "app.functions.document_extractor.prepdocslib.filestrategy",
        "peekOfCode": "class FileStrategy(Strategy):\n    \"\"\"\n    Strategy for ingesting documents into a search service from files stored either locally or in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],",
        "detail": "app.functions.document_extractor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "UploadUserFileStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.filestrategy",
        "description": "app.functions.document_extractor.prepdocslib.filestrategy",
        "peekOfCode": "class UploadUserFileStrategy:\n    \"\"\"\n    Strategy for ingesting a file that has already been uploaded to a ADLS2 storage account\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],\n        blob_manager: AdlsBlobManager,\n        search_field_name_embedding: Optional[str] = None,",
        "detail": "app.functions.document_extractor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.filestrategy",
        "description": "app.functions.document_extractor.prepdocslib.filestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def parse_file(\n    file: File,\n    file_processors: dict[str, FileProcessor],\n    category: Optional[str] = None,\n    blob_manager: Optional[BaseBlobManager] = None,\n    image_embeddings_client: Optional[ImageEmbeddings] = None,\n    figure_processor: Optional[FigureProcessor] = None,\n    user_oid: Optional[str] = None,\n) -> list[Section]:",
        "detail": "app.functions.document_extractor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "LocalHTMLParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.htmlparser",
        "description": "app.functions.document_extractor.prepdocslib.htmlparser",
        "peekOfCode": "class LocalHTMLParser(Parser):\n    \"\"\"Parses HTML text into Page objects.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        \"\"\"Parses the given content.\n        To learn more, please visit https://pypi.org/project/beautifulsoup4/\n        Args:\n            content (IO): The content to parse.\n        Returns:\n            Page: The parsed html Page.\n        \"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.htmlparser",
        "description": "app.functions.document_extractor.prepdocslib.htmlparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.document_extractor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.htmlparser",
        "description": "app.functions.document_extractor.prepdocslib.htmlparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)",
        "detail": "app.functions.document_extractor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "IntegratedVectorizerStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "class IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,",
        "detail": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,",
        "detail": "app.functions.document_extractor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "JsonParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.jsonparser",
        "description": "app.functions.document_extractor.prepdocslib.jsonparser",
        "peekOfCode": "class JsonParser(Parser):\n    \"\"\"\n    Concrete parser that can parse JSON into Page objects. A top-level object becomes a single Page, while a top-level array becomes multiple Page objects.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        offset = 0\n        data = json.loads(content.read())\n        if isinstance(data, list):\n            for i, obj in enumerate(data):\n                offset += 1  # For opening bracket or comma before object",
        "detail": "app.functions.document_extractor.prepdocslib.jsonparser",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "description": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "peekOfCode": "class File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url\n    def filename(self) -> str:",
        "detail": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "description": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ListFileStrategy(ABC):\n    \"\"\"\n    Abstract strategy for listing files that are located somewhere. For example, on a local computer or remotely in a storage account\n    \"\"\"\n    async def list(self) -> AsyncGenerator[File, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "description": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "peekOfCode": "class LocalListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a local filesystem\n    \"\"\"\n    def __init__(self, path_pattern: str, enable_global_documents: bool = False):\n        self.path_pattern = path_pattern\n        self.enable_global_documents = enable_global_documents\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        async for p in self._list_paths(self.path_pattern):\n            yield p",
        "detail": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "description": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ADLSGen2ListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        data_lake_storage_account: str,\n        data_lake_filesystem: str,\n        data_lake_path: str,\n        credential: AsyncTokenCredential | str,",
        "detail": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "description": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url",
        "detail": "app.functions.document_extractor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "MediaDescriber",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "description": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "peekOfCode": "class MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",",
        "detail": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ContentUnderstandingDescriber",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "description": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "peekOfCode": "class ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",\n        \"scenario\": \"image\",\n        \"config\": {\"returnDetails\": False},\n        \"fieldSchema\": {",
        "detail": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "MultimodalModelDescriber",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "description": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "peekOfCode": "class MultimodalModelDescriber(MediaDescriber):\n    def __init__(self, openai_client: AsyncOpenAI, model: str, deployment: Optional[str] = None):\n        self.openai_client = openai_client\n        self.model = model\n        self.deployment = deployment\n    async def describe_image(self, image_bytes: bytes) -> str:\n        def before_retry_sleep(retry_state):\n            logger.info(\"Rate limited on the OpenAI chat completions API, sleeping before retrying...\")\n        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n        image_datauri = f\"data:image/png;base64,{image_base64}\"",
        "detail": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "description": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",",
        "detail": "app.functions.document_extractor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.page",
        "description": "app.functions.document_extractor.prepdocslib.page",
        "peekOfCode": "class ImageOnPage:\n    bytes: bytes\n    bbox: tuple[float, float, float, float]  # Pixels\n    filename: str\n    figure_id: str\n    page_num: int  # 0-indexed\n    placeholder: str  # HTML placeholder in page text, e.g. '<figure id=\"fig_...\"></figure>'\n    mime_type: str = \"image/png\"  # Set by parser; default assumes PNG rendering\n    url: Optional[str] = None\n    title: str = \"\"",
        "detail": "app.functions.document_extractor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.page",
        "description": "app.functions.document_extractor.prepdocslib.page",
        "peekOfCode": "class Page:\n    \"\"\"\n    A single page from a document\n    Attributes:\n        page_num (int): Page number (0-indexed)\n        offset (int): If the text of the entire Document was concatenated into a single string, the index of the first character on the page. For example, if page 1 had the text \"hello\" and page 2 had the text \"world\", the offset of page 2 is 5 (\"hellow\")\n        text (str): The text of the page\n    \"\"\"\n    page_num: int\n    offset: int",
        "detail": "app.functions.document_extractor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.page",
        "description": "app.functions.document_extractor.prepdocslib.page",
        "peekOfCode": "class Chunk:\n    \"\"\"Semantic chunk emitted by the splitter (may originate wholly within one page\n    or be the result of a cross-page merge / trailing fragment carry-forward).\n    Attributes:\n        page_num (int): Logical source page number (0-indexed) for the originating\n            portion of content. For merged content spanning pages we keep the earliest\n            contributing page number for stable attribution.\n        text (str): Textual content of the chunk.\n        images (list[ImageOnPage]): Images associated with this chunk, if any.\n    \"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.parser",
        "description": "app.functions.document_extractor.prepdocslib.parser",
        "peekOfCode": "class Parser(ABC):\n    \"\"\"\n    Abstract parser that parses content into Page objects\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        if False:\n            yield  # pragma: no cover - this is necessary for mypy to type check",
        "detail": "app.functions.document_extractor.prepdocslib.parser",
        "documentation": {}
    },
    {
        "label": "LocalPdfParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.pdfparser",
        "description": "app.functions.document_extractor.prepdocslib.pdfparser",
        "peekOfCode": "class LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages\n        offset = 0",
        "detail": "app.functions.document_extractor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.pdfparser",
        "description": "app.functions.document_extractor.prepdocslib.pdfparser",
        "peekOfCode": "class DocumentAnalysisParser(Parser):\n    \"\"\"\n    Concrete parser backed by Azure AI Document Intelligence that can parse many document formats into pages\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/document-intelligence/overview\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        model_id: str = \"prebuilt-layout\",",
        "detail": "app.functions.document_extractor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.pdfparser",
        "description": "app.functions.document_extractor.prepdocslib.pdfparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages",
        "detail": "app.functions.document_extractor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "Section",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.searchmanager",
        "description": "app.functions.document_extractor.prepdocslib.searchmanager",
        "peekOfCode": "class Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field\nclass SearchManager:",
        "detail": "app.functions.document_extractor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.searchmanager",
        "description": "app.functions.document_extractor.prepdocslib.searchmanager",
        "peekOfCode": "class SearchManager:\n    \"\"\"\n    Class to manage a search service. It can create indexes, and update or remove sections stored in these indexes\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        search_analyzer_name: Optional[str] = None,\n        use_acls: bool = False,",
        "detail": "app.functions.document_extractor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.searchmanager",
        "description": "app.functions.document_extractor.prepdocslib.searchmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field",
        "detail": "app.functions.document_extractor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "class OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).\n    LOCAL:        A locally hosted OpenAI-compatible endpoint (no key required).\n    \"\"\"\n    OPENAI = \"openai\"\n    AZURE = \"azure\"\n    AZURE_CUSTOM = \"azure_custom\"",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_search_info(\n    search_service: str,\n    index_name: str,\n    azure_credential: AsyncTokenCredential,\n    use_agentic_retrieval: Optional[bool] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    agent_name: Optional[str] = None,\n    agent_max_output_tokens: Optional[int] = None,\n    azure_openai_searchagent_deployment: Optional[str] = None,\n    azure_openai_searchagent_model: Optional[str] = None,",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_openai_client(\n    openai_host: OpenAIHost,\n    azure_credential: AsyncTokenCredential,\n    azure_openai_api_key: Optional[str] = None,\n    azure_openai_service: Optional[str] = None,\n    azure_openai_custom_url: Optional[str] = None,\n    openai_api_key: Optional[str] = None,\n    openai_organization: Optional[str] = None,\n) -> tuple[AsyncOpenAI, Optional[str]]:\n    openai_client: AsyncOpenAI",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_image_embeddings_service(\n    azure_credential: AsyncTokenCredential,\n    vision_endpoint: Optional[str],\n    use_multimodal: bool,\n) -> ImageEmbeddings | None:\n    image_embeddings_service: Optional[ImageEmbeddings] = None\n    if use_multimodal:\n        if vision_endpoint is None:\n            raise ValueError(\"An Azure AI Vision endpoint must be provided to use multimodal features.\")\n        image_embeddings_service = ImageEmbeddings(",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_embeddings_service(\n    openai_host: OpenAIHost,\n    open_ai_client: AsyncOpenAI,\n    emb_model_name: str,\n    emb_model_dimensions: int,\n    azure_openai_deployment: Optional[str] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    disable_batch: bool = False,\n) -> OpenAIEmbeddings:\n    if openai_host in [OpenAIHost.AZURE, OpenAIHost.AZURE_CUSTOM]:",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_blob_manager(\n    azure_credential: AsyncTokenCredential | str,\n    storage_account: str,\n    storage_container: str,\n    storage_resource_group: Optional[str] = None,\n    subscription_id: Optional[str] = None,\n    storage_key: Optional[str] = None,\n    image_storage_container: Optional[str] = None,\n) -> BlobManager:\n    \"\"\"Create a BlobManager instance for document or figure storage.",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_figure_processor(\n    *,\n    credential: AsyncTokenCredential | None,\n    use_multimodal: bool,\n    use_content_understanding: bool,\n    content_understanding_endpoint: str | None,\n    openai_client: object | None,\n    openai_model: str | None,\n    openai_deployment: str | None,\n) -> FigureProcessor | None:",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def build_file_processors(\n    *,\n    azure_credential: AsyncTokenCredential,\n    document_intelligence_service: str | None,\n    document_intelligence_key: str | None = None,\n    use_local_pdf_parser: bool = False,\n    use_local_html_parser: bool = False,\n    process_figures: bool = False,\n) -> dict[str, FileProcessor]:\n    sentence_text_splitter = SentenceTextSplitter()",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "def select_processor_for_filename(file_name: str, file_processors: dict[str, FileProcessor]) -> FileProcessor:\n    \"\"\"Select the appropriate file processor for a given filename.\n    Args:\n        file_name: Name of the file to process\n        file_processors: Dictionary mapping file extensions to FileProcessor instances\n    Returns:\n        FileProcessor instance for the file\n    Raises:\n        ValueError: If the file extension is not supported\n    \"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.servicesetup",
        "description": "app.functions.document_extractor.prepdocslib.servicesetup",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).",
        "detail": "app.functions.document_extractor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.strategy",
        "description": "app.functions.document_extractor.prepdocslib.strategy",
        "peekOfCode": "class SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        index_name: str,",
        "detail": "app.functions.document_extractor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.strategy",
        "description": "app.functions.document_extractor.prepdocslib.strategy",
        "peekOfCode": "class DocumentAction(Enum):\n    Add = 0\n    Remove = 1\n    RemoveAll = 2\nclass Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError",
        "detail": "app.functions.document_extractor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.strategy",
        "description": "app.functions.document_extractor.prepdocslib.strategy",
        "peekOfCode": "class Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError\n    async def run(self):\n        raise NotImplementedError",
        "detail": "app.functions.document_extractor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.strategy",
        "description": "app.functions.document_extractor.prepdocslib.strategy",
        "peekOfCode": "USER_AGENT = \"azure-search-chat-demo/1.0.0\"\nclass SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,",
        "detail": "app.functions.document_extractor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.textparser",
        "description": "app.functions.document_extractor.prepdocslib.textparser",
        "peekOfCode": "class TextParser(Parser):\n    \"\"\"Parses simple text into a Page object.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        data = content.read()\n        decoded_data = data.decode(\"utf-8\")\n        text = cleanup_data(decoded_data)\n        yield Page(0, 0, text=text)",
        "detail": "app.functions.document_extractor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.textparser",
        "description": "app.functions.document_extractor.prepdocslib.textparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.document_extractor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "combine_text_with_figures",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.textprocessor",
        "description": "app.functions.document_extractor.prepdocslib.textprocessor",
        "peekOfCode": "def combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)\n        elif image.placeholder not in page.text:",
        "detail": "app.functions.document_extractor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "process_text",
        "kind": 2,
        "importPath": "app.functions.document_extractor.prepdocslib.textprocessor",
        "description": "app.functions.document_extractor.prepdocslib.textprocessor",
        "peekOfCode": "def process_text(\n    pages: list[\"Page\"],\n    file: \"File\",\n    splitter: \"TextSplitter\",\n    category: str | None = None,\n) -> list[\"Section\"]:\n    \"\"\"Process document text and figures into searchable sections.\n    Combines text with figure descriptions, splits into chunks, and\n    associates figures with their containing sections.\n    \"\"\"",
        "detail": "app.functions.document_extractor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textprocessor",
        "description": "app.functions.document_extractor.prepdocslib.textprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)",
        "detail": "app.functions.document_extractor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "TextSplitter",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "class TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\nENCODING_MODEL = \"text-embedding-ada-002\"",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "_ChunkBuilder",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "class _ChunkBuilder:\n    \"\"\"Accumulates sentence-like spans for a single page until size limits are reached.\n    Responsibilities:\n    - Track appended text fragments and their approximate token length.\n    - Decide if a new span can be added without exceeding character or token thresholds.\n    - Flush accumulated content into an output list as a `Chunk`.\n    - Allow a figure block to be force-appended (even if it overflows) so that headings + figure stay together.\n    Notes:\n    - Character limit is soft (exact enforcement + later normalization); token limit is hard.\n    - Token counts are computed by the caller and passed to `add`; this class stays agnostic of the encoder.",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "class SentenceTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks. This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_tokens_per_section: int = 500):\n        self.sentence_endings = STANDARD_SENTENCE_ENDINGS + CJK_SENTENCE_ENDINGS\n        self.word_breaks = STANDARD_WORD_BREAKS + CJK_WORD_BREAKS\n        self.max_section_length = DEFAULT_SECTION_LENGTH\n        self.sentence_search_limit = 100\n        self.max_tokens_per_section = max_tokens_per_section",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "kind": 6,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "class SimpleTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks based on a max object length. It is not aware of the content of the page.\n    This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_object_length: int = 1000):\n        self.max_object_length = max_object_length\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        all_text = \"\".join(page.text for page in pages)\n        if len(all_text.strip()) == 0:",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "ENCODING_MODEL",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "ENCODING_MODEL = \"text-embedding-ada-002\"\nSTANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n# See CL05 and CL06, based on JIS X 4051:2004\n# https://www.w3.org/TR/jlreq/#cl-04\nCJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "bpe",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OVERLAP_PERCENT",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SECTION_LENGTH",
        "kind": 5,
        "importPath": "app.functions.document_extractor.prepdocslib.textsplitter",
        "description": "app.functions.document_extractor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.\n    - Otherwise concatenate directly.",
        "detail": "app.functions.document_extractor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "GlobalSettings",
        "kind": 6,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "class GlobalSettings:\n    file_processors: dict[str, FileProcessor]\n    azure_credential: ManagedIdentityCredential\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration\n    use_local_pdf_parser = os.getenv(\"USE_LOCAL_PDF_PARSER\", \"false\").lower() == \"true\"\n    use_local_html_parser = os.getenv(\"USE_LOCAL_HTML_PARSER\", \"false\").lower() == \"true\"\n    use_multimodal = os.getenv(\"USE_MULTIMODAL\", \"false\").lower() == \"true\"",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "configure_global_settings",
        "kind": 2,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "def configure_global_settings():\n    global settings\n    # Environment configuration\n    use_local_pdf_parser = os.getenv(\"USE_LOCAL_PDF_PARSER\", \"false\").lower() == \"true\"\n    use_local_html_parser = os.getenv(\"USE_LOCAL_HTML_PARSER\", \"false\").lower() == \"true\"\n    use_multimodal = os.getenv(\"USE_MULTIMODAL\", \"false\").lower() == \"true\"\n    document_intelligence_service = os.getenv(\"AZURE_DOCUMENTINTELLIGENCE_SERVICE\")\n    # Single shared managed identity credential\n    if AZURE_CLIENT_ID := os.getenv(\"AZURE_CLIENT_ID\"):\n        logger.info(\"Using Managed Identity with client ID: %s\", AZURE_CLIENT_ID)",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "get_document_stream_filedata",
        "kind": 2,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "def get_document_stream_filedata(data: dict[str, Any]) -> tuple[io.BytesIO, str, str]:\n    \"\"\"Return a BytesIO stream for file_data input only (skillset must send file bytes).\"\"\"\n    file_payload = data.get(\"file_data\", {})\n    encoded = file_payload.get(\"data\")\n    if not encoded:\n        raise ValueError(\"file_data payload missing base64 data\")\n    document_bytes = base64.b64decode(encoded)\n    file_name = data.get(\"file_name\") or data.get(\"fileName\") or file_payload.get(\"name\") or \"document\"\n    content_type = data.get(\"contentType\") or file_payload.get(\"contentType\") or \"application/octet-stream\"\n    stream = io.BytesIO(document_bytes)",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "build_document_components",
        "kind": 2,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "def build_document_components(file_name: str, pages: list[Page]) -> dict[str, Any]:\n    page_entries: list[dict[str, Any]] = []\n    figure_entries: list[dict[str, Any]] = []\n    for page in pages:\n        page_text = page.text or \"\"\n        figure_ids_on_page: list[str] = []\n        if page.images:\n            for image in page.images:\n                figure_ids_on_page.append(image.figure_id)\n                figure_entries.append(image.to_skill_payload(file_name))",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)\nlogger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    file_processors: dict[str, FileProcessor]\n    azure_credential: ManagedIdentityCredential\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.document_extractor.function_app",
        "description": "app.functions.document_extractor.function_app",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    file_processors: dict[str, FileProcessor]\n    azure_credential: ManagedIdentityCredential\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration\n    use_local_pdf_parser = os.getenv(\"USE_LOCAL_PDF_PARSER\", \"false\").lower() == \"true\"",
        "detail": "app.functions.document_extractor.function_app",
        "documentation": {}
    },
    {
        "label": "BlobProperties",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.blobmanager",
        "description": "app.functions.figure_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":",
        "detail": "app.functions.figure_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BaseBlobManager",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.blobmanager",
        "description": "app.functions.figure_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":\n            return f\"{os.path.basename(filename)}#page={page+1}\"\n        else:\n            return os.path.basename(filename)",
        "detail": "app.functions.figure_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.blobmanager",
        "description": "app.functions.figure_processor.prepdocslib.blobmanager",
        "peekOfCode": "class AdlsBlobManager(BaseBlobManager):\n    \"\"\"\n    Manager for Azure Data Lake Storage blob operations, particularly for user-specific file operations.\n    Documents are stored directly in the user's directory for backwards compatibility.\n    Images are stored in a separate images subdirectory for better organization.\n    \"\"\"\n    def __init__(self, endpoint: str, container: str, credential: AsyncTokenCredential):\n        \"\"\"\n        Initializes the AdlsBlobManager with the necessary parameters.\n        Args:",
        "detail": "app.functions.figure_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.blobmanager",
        "description": "app.functions.figure_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobManager(BaseBlobManager):\n    \"\"\"\n    Class to manage uploading and deleting blobs containing citation information from a blob storage account\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        container: str,\n        credential: AsyncTokenCredential | str,\n        image_container: Optional[str] = None,",
        "detail": "app.functions.figure_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.blobmanager",
        "description": "app.functions.figure_processor.prepdocslib.blobmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:",
        "detail": "app.functions.figure_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "SkillConfig",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CloudIngestionStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,\n        *,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,\n        search_field_name_embedding: str,",
        "detail": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nDEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str",
        "detail": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SKILL_TIMEOUT",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover",
        "detail": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_BATCH_SIZE",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CsvParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.csvparser",
        "description": "app.functions.figure_processor.prepdocslib.csvparser",
        "peekOfCode": "class CsvParser(Parser):\n    \"\"\"\n    Concrete parser that can parse CSV into Page objects. Each row becomes a Page object.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        # Check if content is in bytes (binary file) and decode to string\n        content_str: str\n        if isinstance(content, (bytes, bytearray)):\n            content_str = content.decode(\"utf-8\")\n        elif hasattr(content, \"read\"):  # Handle BufferedReader",
        "detail": "app.functions.figure_processor.prepdocslib.csvparser",
        "documentation": {}
    },
    {
        "label": "EmbeddingBatch",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.embeddings",
        "description": "app.functions.figure_processor.prepdocslib.embeddings",
        "peekOfCode": "class EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {",
        "detail": "app.functions.figure_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ExtraArgs",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.embeddings",
        "description": "app.functions.figure_processor.prepdocslib.embeddings",
        "peekOfCode": "class ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {",
        "detail": "app.functions.figure_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.embeddings",
        "description": "app.functions.figure_processor.prepdocslib.embeddings",
        "peekOfCode": "class OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {\n        \"text-embedding-ada-002\": False,\n        \"text-embedding-3-small\": True,",
        "detail": "app.functions.figure_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.embeddings",
        "description": "app.functions.figure_processor.prepdocslib.embeddings",
        "peekOfCode": "class ImageEmbeddings:\n    \"\"\"\n    Class for using image embeddings from Azure AI Vision\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-image-api\n    \"\"\"\n    def __init__(self, endpoint: str, token_provider: Callable[[], Awaitable[str]]):\n        self.token_provider = token_provider\n        self.endpoint = endpoint\n    async def create_embedding_for_image(self, image_bytes: bytes) -> list[float]:\n        endpoint = urljoin(self.endpoint, \"computervision/retrieval:vectorizeImage\")",
        "detail": "app.functions.figure_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.embeddings",
        "description": "app.functions.figure_processor.prepdocslib.embeddings",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "description": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "peekOfCode": "class MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,",
        "detail": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "description": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "peekOfCode": "class FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,\n        credential: AsyncTokenCredential | AzureKeyCredential | None = None,\n        strategy: MediaDescriptionStrategy = MediaDescriptionStrategy.NONE,\n        openai_client: Any | None = None,\n        openai_model: str | None = None,\n        openai_deployment: str | None = None,",
        "detail": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "build_figure_markup",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "description": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "peekOfCode": "def build_figure_markup(image: \"ImageOnPage\", description: Optional[str] = None) -> str:\n    \"\"\"Create consistent HTML markup for a figure description on demand.\"\"\"\n    caption_parts = [image.figure_id]\n    if image.title:\n        caption_parts.append(image.title)\n    caption = \" \".join(part for part in caption_parts if part)\n    if description:\n        return f\"<figure><figcaption>{caption}<br>{description}</figcaption></figure>\"\n    return f\"<figure><figcaption>{caption}</figcaption></figure>\"\nasync def process_page_image(",
        "detail": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "description": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.figure_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.fileprocessor",
        "description": "app.functions.figure_processor.prepdocslib.fileprocessor",
        "peekOfCode": "class FileProcessor:\n    parser: Parser\n    splitter: TextSplitter",
        "detail": "app.functions.figure_processor.prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.filestrategy",
        "description": "app.functions.figure_processor.prepdocslib.filestrategy",
        "peekOfCode": "class FileStrategy(Strategy):\n    \"\"\"\n    Strategy for ingesting documents into a search service from files stored either locally or in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],",
        "detail": "app.functions.figure_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "UploadUserFileStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.filestrategy",
        "description": "app.functions.figure_processor.prepdocslib.filestrategy",
        "peekOfCode": "class UploadUserFileStrategy:\n    \"\"\"\n    Strategy for ingesting a file that has already been uploaded to a ADLS2 storage account\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],\n        blob_manager: AdlsBlobManager,\n        search_field_name_embedding: Optional[str] = None,",
        "detail": "app.functions.figure_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.filestrategy",
        "description": "app.functions.figure_processor.prepdocslib.filestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def parse_file(\n    file: File,\n    file_processors: dict[str, FileProcessor],\n    category: Optional[str] = None,\n    blob_manager: Optional[BaseBlobManager] = None,\n    image_embeddings_client: Optional[ImageEmbeddings] = None,\n    figure_processor: Optional[FigureProcessor] = None,\n    user_oid: Optional[str] = None,\n) -> list[Section]:",
        "detail": "app.functions.figure_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "LocalHTMLParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.htmlparser",
        "description": "app.functions.figure_processor.prepdocslib.htmlparser",
        "peekOfCode": "class LocalHTMLParser(Parser):\n    \"\"\"Parses HTML text into Page objects.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        \"\"\"Parses the given content.\n        To learn more, please visit https://pypi.org/project/beautifulsoup4/\n        Args:\n            content (IO): The content to parse.\n        Returns:\n            Page: The parsed html Page.\n        \"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.htmlparser",
        "description": "app.functions.figure_processor.prepdocslib.htmlparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.figure_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.htmlparser",
        "description": "app.functions.figure_processor.prepdocslib.htmlparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)",
        "detail": "app.functions.figure_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "IntegratedVectorizerStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "class IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,",
        "detail": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,",
        "detail": "app.functions.figure_processor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "JsonParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.jsonparser",
        "description": "app.functions.figure_processor.prepdocslib.jsonparser",
        "peekOfCode": "class JsonParser(Parser):\n    \"\"\"\n    Concrete parser that can parse JSON into Page objects. A top-level object becomes a single Page, while a top-level array becomes multiple Page objects.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        offset = 0\n        data = json.loads(content.read())\n        if isinstance(data, list):\n            for i, obj in enumerate(data):\n                offset += 1  # For opening bracket or comma before object",
        "detail": "app.functions.figure_processor.prepdocslib.jsonparser",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url\n    def filename(self) -> str:",
        "detail": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ListFileStrategy(ABC):\n    \"\"\"\n    Abstract strategy for listing files that are located somewhere. For example, on a local computer or remotely in a storage account\n    \"\"\"\n    async def list(self) -> AsyncGenerator[File, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class LocalListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a local filesystem\n    \"\"\"\n    def __init__(self, path_pattern: str, enable_global_documents: bool = False):\n        self.path_pattern = path_pattern\n        self.enable_global_documents = enable_global_documents\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        async for p in self._list_paths(self.path_pattern):\n            yield p",
        "detail": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ADLSGen2ListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        data_lake_storage_account: str,\n        data_lake_filesystem: str,\n        data_lake_path: str,\n        credential: AsyncTokenCredential | str,",
        "detail": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url",
        "detail": "app.functions.figure_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "MediaDescriber",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "description": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",",
        "detail": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ContentUnderstandingDescriber",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "description": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",\n        \"scenario\": \"image\",\n        \"config\": {\"returnDetails\": False},\n        \"fieldSchema\": {",
        "detail": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "MultimodalModelDescriber",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "description": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class MultimodalModelDescriber(MediaDescriber):\n    def __init__(self, openai_client: AsyncOpenAI, model: str, deployment: Optional[str] = None):\n        self.openai_client = openai_client\n        self.model = model\n        self.deployment = deployment\n    async def describe_image(self, image_bytes: bytes) -> str:\n        def before_retry_sleep(retry_state):\n            logger.info(\"Rate limited on the OpenAI chat completions API, sleeping before retrying...\")\n        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n        image_datauri = f\"data:image/png;base64,{image_base64}\"",
        "detail": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "description": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",",
        "detail": "app.functions.figure_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.page",
        "description": "app.functions.figure_processor.prepdocslib.page",
        "peekOfCode": "class ImageOnPage:\n    bytes: bytes\n    bbox: tuple[float, float, float, float]  # Pixels\n    filename: str\n    figure_id: str\n    page_num: int  # 0-indexed\n    placeholder: str  # HTML placeholder in page text, e.g. '<figure id=\"fig_...\"></figure>'\n    mime_type: str = \"image/png\"  # Set by parser; default assumes PNG rendering\n    url: Optional[str] = None\n    title: str = \"\"",
        "detail": "app.functions.figure_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.page",
        "description": "app.functions.figure_processor.prepdocslib.page",
        "peekOfCode": "class Page:\n    \"\"\"\n    A single page from a document\n    Attributes:\n        page_num (int): Page number (0-indexed)\n        offset (int): If the text of the entire Document was concatenated into a single string, the index of the first character on the page. For example, if page 1 had the text \"hello\" and page 2 had the text \"world\", the offset of page 2 is 5 (\"hellow\")\n        text (str): The text of the page\n    \"\"\"\n    page_num: int\n    offset: int",
        "detail": "app.functions.figure_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.page",
        "description": "app.functions.figure_processor.prepdocslib.page",
        "peekOfCode": "class Chunk:\n    \"\"\"Semantic chunk emitted by the splitter (may originate wholly within one page\n    or be the result of a cross-page merge / trailing fragment carry-forward).\n    Attributes:\n        page_num (int): Logical source page number (0-indexed) for the originating\n            portion of content. For merged content spanning pages we keep the earliest\n            contributing page number for stable attribution.\n        text (str): Textual content of the chunk.\n        images (list[ImageOnPage]): Images associated with this chunk, if any.\n    \"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.parser",
        "description": "app.functions.figure_processor.prepdocslib.parser",
        "peekOfCode": "class Parser(ABC):\n    \"\"\"\n    Abstract parser that parses content into Page objects\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        if False:\n            yield  # pragma: no cover - this is necessary for mypy to type check",
        "detail": "app.functions.figure_processor.prepdocslib.parser",
        "documentation": {}
    },
    {
        "label": "LocalPdfParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.pdfparser",
        "description": "app.functions.figure_processor.prepdocslib.pdfparser",
        "peekOfCode": "class LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages\n        offset = 0",
        "detail": "app.functions.figure_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.pdfparser",
        "description": "app.functions.figure_processor.prepdocslib.pdfparser",
        "peekOfCode": "class DocumentAnalysisParser(Parser):\n    \"\"\"\n    Concrete parser backed by Azure AI Document Intelligence that can parse many document formats into pages\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/document-intelligence/overview\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        model_id: str = \"prebuilt-layout\",",
        "detail": "app.functions.figure_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.pdfparser",
        "description": "app.functions.figure_processor.prepdocslib.pdfparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages",
        "detail": "app.functions.figure_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "Section",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.searchmanager",
        "description": "app.functions.figure_processor.prepdocslib.searchmanager",
        "peekOfCode": "class Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field\nclass SearchManager:",
        "detail": "app.functions.figure_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.searchmanager",
        "description": "app.functions.figure_processor.prepdocslib.searchmanager",
        "peekOfCode": "class SearchManager:\n    \"\"\"\n    Class to manage a search service. It can create indexes, and update or remove sections stored in these indexes\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        search_analyzer_name: Optional[str] = None,\n        use_acls: bool = False,",
        "detail": "app.functions.figure_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.searchmanager",
        "description": "app.functions.figure_processor.prepdocslib.searchmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field",
        "detail": "app.functions.figure_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "class OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).\n    LOCAL:        A locally hosted OpenAI-compatible endpoint (no key required).\n    \"\"\"\n    OPENAI = \"openai\"\n    AZURE = \"azure\"\n    AZURE_CUSTOM = \"azure_custom\"",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_search_info(\n    search_service: str,\n    index_name: str,\n    azure_credential: AsyncTokenCredential,\n    use_agentic_retrieval: Optional[bool] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    agent_name: Optional[str] = None,\n    agent_max_output_tokens: Optional[int] = None,\n    azure_openai_searchagent_deployment: Optional[str] = None,\n    azure_openai_searchagent_model: Optional[str] = None,",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_openai_client(\n    openai_host: OpenAIHost,\n    azure_credential: AsyncTokenCredential,\n    azure_openai_api_key: Optional[str] = None,\n    azure_openai_service: Optional[str] = None,\n    azure_openai_custom_url: Optional[str] = None,\n    openai_api_key: Optional[str] = None,\n    openai_organization: Optional[str] = None,\n) -> tuple[AsyncOpenAI, Optional[str]]:\n    openai_client: AsyncOpenAI",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_image_embeddings_service(\n    azure_credential: AsyncTokenCredential,\n    vision_endpoint: Optional[str],\n    use_multimodal: bool,\n) -> ImageEmbeddings | None:\n    image_embeddings_service: Optional[ImageEmbeddings] = None\n    if use_multimodal:\n        if vision_endpoint is None:\n            raise ValueError(\"An Azure AI Vision endpoint must be provided to use multimodal features.\")\n        image_embeddings_service = ImageEmbeddings(",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_embeddings_service(\n    openai_host: OpenAIHost,\n    open_ai_client: AsyncOpenAI,\n    emb_model_name: str,\n    emb_model_dimensions: int,\n    azure_openai_deployment: Optional[str] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    disable_batch: bool = False,\n) -> OpenAIEmbeddings:\n    if openai_host in [OpenAIHost.AZURE, OpenAIHost.AZURE_CUSTOM]:",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_blob_manager(\n    azure_credential: AsyncTokenCredential | str,\n    storage_account: str,\n    storage_container: str,\n    storage_resource_group: Optional[str] = None,\n    subscription_id: Optional[str] = None,\n    storage_key: Optional[str] = None,\n    image_storage_container: Optional[str] = None,\n) -> BlobManager:\n    \"\"\"Create a BlobManager instance for document or figure storage.",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_figure_processor(\n    *,\n    credential: AsyncTokenCredential | None,\n    use_multimodal: bool,\n    use_content_understanding: bool,\n    content_understanding_endpoint: str | None,\n    openai_client: object | None,\n    openai_model: str | None,\n    openai_deployment: str | None,\n) -> FigureProcessor | None:",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def build_file_processors(\n    *,\n    azure_credential: AsyncTokenCredential,\n    document_intelligence_service: str | None,\n    document_intelligence_key: str | None = None,\n    use_local_pdf_parser: bool = False,\n    use_local_html_parser: bool = False,\n    process_figures: bool = False,\n) -> dict[str, FileProcessor]:\n    sentence_text_splitter = SentenceTextSplitter()",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "def select_processor_for_filename(file_name: str, file_processors: dict[str, FileProcessor]) -> FileProcessor:\n    \"\"\"Select the appropriate file processor for a given filename.\n    Args:\n        file_name: Name of the file to process\n        file_processors: Dictionary mapping file extensions to FileProcessor instances\n    Returns:\n        FileProcessor instance for the file\n    Raises:\n        ValueError: If the file extension is not supported\n    \"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.servicesetup",
        "description": "app.functions.figure_processor.prepdocslib.servicesetup",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).",
        "detail": "app.functions.figure_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.strategy",
        "description": "app.functions.figure_processor.prepdocslib.strategy",
        "peekOfCode": "class SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        index_name: str,",
        "detail": "app.functions.figure_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.strategy",
        "description": "app.functions.figure_processor.prepdocslib.strategy",
        "peekOfCode": "class DocumentAction(Enum):\n    Add = 0\n    Remove = 1\n    RemoveAll = 2\nclass Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError",
        "detail": "app.functions.figure_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.strategy",
        "description": "app.functions.figure_processor.prepdocslib.strategy",
        "peekOfCode": "class Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError\n    async def run(self):\n        raise NotImplementedError",
        "detail": "app.functions.figure_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.strategy",
        "description": "app.functions.figure_processor.prepdocslib.strategy",
        "peekOfCode": "USER_AGENT = \"azure-search-chat-demo/1.0.0\"\nclass SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,",
        "detail": "app.functions.figure_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.textparser",
        "description": "app.functions.figure_processor.prepdocslib.textparser",
        "peekOfCode": "class TextParser(Parser):\n    \"\"\"Parses simple text into a Page object.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        data = content.read()\n        decoded_data = data.decode(\"utf-8\")\n        text = cleanup_data(decoded_data)\n        yield Page(0, 0, text=text)",
        "detail": "app.functions.figure_processor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.textparser",
        "description": "app.functions.figure_processor.prepdocslib.textparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.figure_processor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "combine_text_with_figures",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.textprocessor",
        "description": "app.functions.figure_processor.prepdocslib.textprocessor",
        "peekOfCode": "def combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)\n        elif image.placeholder not in page.text:",
        "detail": "app.functions.figure_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "process_text",
        "kind": 2,
        "importPath": "app.functions.figure_processor.prepdocslib.textprocessor",
        "description": "app.functions.figure_processor.prepdocslib.textprocessor",
        "peekOfCode": "def process_text(\n    pages: list[\"Page\"],\n    file: \"File\",\n    splitter: \"TextSplitter\",\n    category: str | None = None,\n) -> list[\"Section\"]:\n    \"\"\"Process document text and figures into searchable sections.\n    Combines text with figure descriptions, splits into chunks, and\n    associates figures with their containing sections.\n    \"\"\"",
        "detail": "app.functions.figure_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textprocessor",
        "description": "app.functions.figure_processor.prepdocslib.textprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)",
        "detail": "app.functions.figure_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "TextSplitter",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "class TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\nENCODING_MODEL = \"text-embedding-ada-002\"",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "_ChunkBuilder",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "class _ChunkBuilder:\n    \"\"\"Accumulates sentence-like spans for a single page until size limits are reached.\n    Responsibilities:\n    - Track appended text fragments and their approximate token length.\n    - Decide if a new span can be added without exceeding character or token thresholds.\n    - Flush accumulated content into an output list as a `Chunk`.\n    - Allow a figure block to be force-appended (even if it overflows) so that headings + figure stay together.\n    Notes:\n    - Character limit is soft (exact enforcement + later normalization); token limit is hard.\n    - Token counts are computed by the caller and passed to `add`; this class stays agnostic of the encoder.",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "class SentenceTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks. This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_tokens_per_section: int = 500):\n        self.sentence_endings = STANDARD_SENTENCE_ENDINGS + CJK_SENTENCE_ENDINGS\n        self.word_breaks = STANDARD_WORD_BREAKS + CJK_WORD_BREAKS\n        self.max_section_length = DEFAULT_SECTION_LENGTH\n        self.sentence_search_limit = 100\n        self.max_tokens_per_section = max_tokens_per_section",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "kind": 6,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "class SimpleTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks based on a max object length. It is not aware of the content of the page.\n    This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_object_length: int = 1000):\n        self.max_object_length = max_object_length\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        all_text = \"\".join(page.text for page in pages)\n        if len(all_text.strip()) == 0:",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "ENCODING_MODEL",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "ENCODING_MODEL = \"text-embedding-ada-002\"\nSTANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n# See CL05 and CL06, based on JIS X 4051:2004\n# https://www.w3.org/TR/jlreq/#cl-04\nCJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "bpe",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OVERLAP_PERCENT",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SECTION_LENGTH",
        "kind": 5,
        "importPath": "app.functions.figure_processor.prepdocslib.textsplitter",
        "description": "app.functions.figure_processor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.\n    - Otherwise concatenate directly.",
        "detail": "app.functions.figure_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "GlobalSettings",
        "kind": 6,
        "importPath": "app.functions.figure_processor.function_app",
        "description": "app.functions.figure_processor.function_app",
        "peekOfCode": "class GlobalSettings:\n    blob_manager: BlobManager\n    figure_processor: FigureProcessor | None\n    image_embeddings: ImageEmbeddings | None\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration\n    # Required variables\n    AZURE_STORAGE_ACCOUNT = os.environ[\"AZURE_STORAGE_ACCOUNT\"]",
        "detail": "app.functions.figure_processor.function_app",
        "documentation": {}
    },
    {
        "label": "configure_global_settings",
        "kind": 2,
        "importPath": "app.functions.figure_processor.function_app",
        "description": "app.functions.figure_processor.function_app",
        "peekOfCode": "def configure_global_settings():\n    global settings\n    # Environment configuration\n    # Required variables\n    AZURE_STORAGE_ACCOUNT = os.environ[\"AZURE_STORAGE_ACCOUNT\"]\n    IMAGE_CONTAINER = os.environ[\"AZURE_IMAGESTORAGE_CONTAINER\"]\n    # Optional feature flags\n    USE_MULTIMODAL = os.getenv(\"USE_MULTIMODAL\", \"false\").lower() == \"true\"\n    USE_MEDIA_DESCRIBER_AZURE_CU = os.getenv(\"USE_MEDIA_DESCRIBER_AZURE_CU\", \"false\").lower() == \"true\"\n    # Conditionally required (based on feature flags)",
        "detail": "app.functions.figure_processor.function_app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app.functions.figure_processor.function_app",
        "description": "app.functions.figure_processor.function_app",
        "peekOfCode": "app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)\nlogger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    blob_manager: BlobManager\n    figure_processor: FigureProcessor | None\n    image_embeddings: ImageEmbeddings | None\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings",
        "detail": "app.functions.figure_processor.function_app",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.figure_processor.function_app",
        "description": "app.functions.figure_processor.function_app",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    blob_manager: BlobManager\n    figure_processor: FigureProcessor | None\n    image_embeddings: ImageEmbeddings | None\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration",
        "detail": "app.functions.figure_processor.function_app",
        "documentation": {}
    },
    {
        "label": "BlobProperties",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.blobmanager",
        "description": "app.functions.text_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":",
        "detail": "app.functions.text_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BaseBlobManager",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.blobmanager",
        "description": "app.functions.text_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:\n        if os.path.splitext(filename)[1].lower() == \".pdf\":\n            return f\"{os.path.basename(filename)}#page={page+1}\"\n        else:\n            return os.path.basename(filename)",
        "detail": "app.functions.text_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "AdlsBlobManager",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.blobmanager",
        "description": "app.functions.text_processor.prepdocslib.blobmanager",
        "peekOfCode": "class AdlsBlobManager(BaseBlobManager):\n    \"\"\"\n    Manager for Azure Data Lake Storage blob operations, particularly for user-specific file operations.\n    Documents are stored directly in the user's directory for backwards compatibility.\n    Images are stored in a separate images subdirectory for better organization.\n    \"\"\"\n    def __init__(self, endpoint: str, container: str, credential: AsyncTokenCredential):\n        \"\"\"\n        Initializes the AdlsBlobManager with the necessary parameters.\n        Args:",
        "detail": "app.functions.text_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "BlobManager",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.blobmanager",
        "description": "app.functions.text_processor.prepdocslib.blobmanager",
        "peekOfCode": "class BlobManager(BaseBlobManager):\n    \"\"\"\n    Class to manage uploading and deleting blobs containing citation information from a blob storage account\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        container: str,\n        credential: AsyncTokenCredential | str,\n        image_container: Optional[str] = None,",
        "detail": "app.functions.text_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.blobmanager",
        "description": "app.functions.text_processor.prepdocslib.blobmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass BlobProperties(TypedDict, total=False):\n    \"\"\"Properties of a blob, with optional fields for content settings\"\"\"\n    content_settings: dict[str, Any]\nclass BaseBlobManager:\n    \"\"\"\n    Base class for Azure Storage operations, providing common file naming and path utilities\n    \"\"\"\n    @classmethod\n    def sourcepage_from_file_page(cls, filename, page=0) -> str:",
        "detail": "app.functions.text_processor.prepdocslib.blobmanager",
        "documentation": {}
    },
    {
        "label": "SkillConfig",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CloudIngestionStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "class CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"\n    def __init__(\n        self,\n        *,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,\n        search_field_name_embedding: str,",
        "detail": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nDEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str",
        "detail": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SKILL_TIMEOUT",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_SKILL_TIMEOUT = timedelta(seconds=230)\nDEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover",
        "detail": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "DEFAULT_BATCH_SIZE",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "description": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "peekOfCode": "DEFAULT_BATCH_SIZE = 1\n@dataclass(slots=True)\nclass SkillConfig:\n    \"\"\"Configuration for a custom Web API skill.\"\"\"\n    name: str\n    description: str\n    uri: str\n    auth_resource_id: str\nclass CloudIngestionStrategy(Strategy):  # pragma: no cover\n    \"\"\"Ingestion strategy that wires Azure Function custom skills into an indexer.\"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.cloudingestionstrategy",
        "documentation": {}
    },
    {
        "label": "CsvParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.csvparser",
        "description": "app.functions.text_processor.prepdocslib.csvparser",
        "peekOfCode": "class CsvParser(Parser):\n    \"\"\"\n    Concrete parser that can parse CSV into Page objects. Each row becomes a Page object.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        # Check if content is in bytes (binary file) and decode to string\n        content_str: str\n        if isinstance(content, (bytes, bytearray)):\n            content_str = content.decode(\"utf-8\")\n        elif hasattr(content, \"read\"):  # Handle BufferedReader",
        "detail": "app.functions.text_processor.prepdocslib.csvparser",
        "documentation": {}
    },
    {
        "label": "EmbeddingBatch",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.embeddings",
        "description": "app.functions.text_processor.prepdocslib.embeddings",
        "peekOfCode": "class EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {",
        "detail": "app.functions.text_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ExtraArgs",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.embeddings",
        "description": "app.functions.text_processor.prepdocslib.embeddings",
        "peekOfCode": "class ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {",
        "detail": "app.functions.text_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.embeddings",
        "description": "app.functions.text_processor.prepdocslib.embeddings",
        "peekOfCode": "class OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"\n    SUPPORTED_BATCH_MODEL = {\n        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n    }\n    SUPPORTED_DIMENSIONS_MODEL = {\n        \"text-embedding-ada-002\": False,\n        \"text-embedding-3-small\": True,",
        "detail": "app.functions.text_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "ImageEmbeddings",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.embeddings",
        "description": "app.functions.text_processor.prepdocslib.embeddings",
        "peekOfCode": "class ImageEmbeddings:\n    \"\"\"\n    Class for using image embeddings from Azure AI Vision\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-image-api\n    \"\"\"\n    def __init__(self, endpoint: str, token_provider: Callable[[], Awaitable[str]]):\n        self.token_provider = token_provider\n        self.endpoint = endpoint\n    async def create_embedding_for_image(self, image_bytes: bytes) -> list[float]:\n        endpoint = urljoin(self.endpoint, \"computervision/retrieval:vectorizeImage\")",
        "detail": "app.functions.text_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.embeddings",
        "description": "app.functions.text_processor.prepdocslib.embeddings",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass EmbeddingBatch:\n    \"\"\"Represents a batch of text that is going to be embedded.\"\"\"\n    def __init__(self, texts: list[str], token_length: int):\n        self.texts = texts\n        self.token_length = token_length\nclass ExtraArgs(TypedDict, total=False):\n    dimensions: int\nclass OpenAIEmbeddings(ABC):\n    \"\"\"Client wrapper that handles batching, retries, and token accounting.\"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.embeddings",
        "documentation": {}
    },
    {
        "label": "MediaDescriptionStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.figureprocessor",
        "description": "app.functions.text_processor.prepdocslib.figureprocessor",
        "peekOfCode": "class MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,",
        "detail": "app.functions.text_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FigureProcessor",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.figureprocessor",
        "description": "app.functions.text_processor.prepdocslib.figureprocessor",
        "peekOfCode": "class FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,\n        *,\n        credential: AsyncTokenCredential | AzureKeyCredential | None = None,\n        strategy: MediaDescriptionStrategy = MediaDescriptionStrategy.NONE,\n        openai_client: Any | None = None,\n        openai_model: str | None = None,\n        openai_deployment: str | None = None,",
        "detail": "app.functions.text_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "build_figure_markup",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.figureprocessor",
        "description": "app.functions.text_processor.prepdocslib.figureprocessor",
        "peekOfCode": "def build_figure_markup(image: \"ImageOnPage\", description: Optional[str] = None) -> str:\n    \"\"\"Create consistent HTML markup for a figure description on demand.\"\"\"\n    caption_parts = [image.figure_id]\n    if image.title:\n        caption_parts.append(image.title)\n    caption = \" \".join(part for part in caption_parts if part)\n    if description:\n        return f\"<figure><figcaption>{caption}<br>{description}</figcaption></figure>\"\n    return f\"<figure><figcaption>{caption}</figcaption></figure>\"\nasync def process_page_image(",
        "detail": "app.functions.text_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.figureprocessor",
        "description": "app.functions.text_processor.prepdocslib.figureprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriptionStrategy(Enum):\n    \"\"\"Supported mechanisms for describing images extracted from documents.\"\"\"\n    NONE = \"none\"\n    OPENAI = \"openai\"\n    CONTENTUNDERSTANDING = \"content_understanding\"\nclass FigureProcessor:\n    \"\"\"Helper that lazily creates a media describer and captions figures on demand.\"\"\"\n    def __init__(\n        self,",
        "detail": "app.functions.text_processor.prepdocslib.figureprocessor",
        "documentation": {}
    },
    {
        "label": "FileProcessor",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.fileprocessor",
        "description": "app.functions.text_processor.prepdocslib.fileprocessor",
        "peekOfCode": "class FileProcessor:\n    parser: Parser\n    splitter: TextSplitter",
        "detail": "app.functions.text_processor.prepdocslib.fileprocessor",
        "documentation": {}
    },
    {
        "label": "FileStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.filestrategy",
        "description": "app.functions.text_processor.prepdocslib.filestrategy",
        "peekOfCode": "class FileStrategy(Strategy):\n    \"\"\"\n    Strategy for ingesting documents into a search service from files stored either locally or in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],",
        "detail": "app.functions.text_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "UploadUserFileStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.filestrategy",
        "description": "app.functions.text_processor.prepdocslib.filestrategy",
        "peekOfCode": "class UploadUserFileStrategy:\n    \"\"\"\n    Strategy for ingesting a file that has already been uploaded to a ADLS2 storage account\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        file_processors: dict[str, FileProcessor],\n        blob_manager: AdlsBlobManager,\n        search_field_name_embedding: Optional[str] = None,",
        "detail": "app.functions.text_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.filestrategy",
        "description": "app.functions.text_processor.prepdocslib.filestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nasync def parse_file(\n    file: File,\n    file_processors: dict[str, FileProcessor],\n    category: Optional[str] = None,\n    blob_manager: Optional[BaseBlobManager] = None,\n    image_embeddings_client: Optional[ImageEmbeddings] = None,\n    figure_processor: Optional[FigureProcessor] = None,\n    user_oid: Optional[str] = None,\n) -> list[Section]:",
        "detail": "app.functions.text_processor.prepdocslib.filestrategy",
        "documentation": {}
    },
    {
        "label": "LocalHTMLParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.htmlparser",
        "description": "app.functions.text_processor.prepdocslib.htmlparser",
        "peekOfCode": "class LocalHTMLParser(Parser):\n    \"\"\"Parses HTML text into Page objects.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        \"\"\"Parses the given content.\n        To learn more, please visit https://pypi.org/project/beautifulsoup4/\n        Args:\n            content (IO): The content to parse.\n        Returns:\n            Page: The parsed html Page.\n        \"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.htmlparser",
        "description": "app.functions.text_processor.prepdocslib.htmlparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.text_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.htmlparser",
        "description": "app.functions.text_processor.prepdocslib.htmlparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)",
        "detail": "app.functions.text_processor.prepdocslib.htmlparser",
        "documentation": {}
    },
    {
        "label": "IntegratedVectorizerStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "class IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,\n        embeddings: OpenAIEmbeddings,",
        "detail": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "description": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass IntegratedVectorizerStrategy(Strategy):  # pragma: no cover\n    \"\"\"\n    Strategy for ingesting and vectorizing documents into a search service from files stored storage account\n    \"\"\"\n    def __init__(\n        self,\n        list_file_strategy: ListFileStrategy,\n        blob_manager: BlobManager,\n        search_info: SearchInfo,",
        "detail": "app.functions.text_processor.prepdocslib.integratedvectorizerstrategy",
        "documentation": {}
    },
    {
        "label": "JsonParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.jsonparser",
        "description": "app.functions.text_processor.prepdocslib.jsonparser",
        "peekOfCode": "class JsonParser(Parser):\n    \"\"\"\n    Concrete parser that can parse JSON into Page objects. A top-level object becomes a single Page, while a top-level array becomes multiple Page objects.\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        offset = 0\n        data = json.loads(content.read())\n        if isinstance(data, list):\n            for i, obj in enumerate(data):\n                offset += 1  # For opening bracket or comma before object",
        "detail": "app.functions.text_processor.prepdocslib.jsonparser",
        "documentation": {}
    },
    {
        "label": "File",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url\n    def filename(self) -> str:",
        "detail": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ListFileStrategy(ABC):\n    \"\"\"\n    Abstract strategy for listing files that are located somewhere. For example, on a local computer or remotely in a storage account\n    \"\"\"\n    async def list(self) -> AsyncGenerator[File, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "LocalListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class LocalListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a local filesystem\n    \"\"\"\n    def __init__(self, path_pattern: str, enable_global_documents: bool = False):\n        self.path_pattern = path_pattern\n        self.enable_global_documents = enable_global_documents\n    async def list_paths(self) -> AsyncGenerator[str, None]:\n        async for p in self._list_paths(self.path_pattern):\n            yield p",
        "detail": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "ADLSGen2ListFileStrategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "class ADLSGen2ListFileStrategy(ListFileStrategy):\n    \"\"\"\n    Concrete strategy for listing files that are located in a data lake storage account\n    \"\"\"\n    def __init__(\n        self,\n        data_lake_storage_account: str,\n        data_lake_filesystem: str,\n        data_lake_path: str,\n        credential: AsyncTokenCredential | str,",
        "detail": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "description": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass File:\n    \"\"\"\n    Represents a file stored either locally or in a data lake storage account\n    This file might contain access control information about which users or groups can access it\n    \"\"\"\n    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n        self.content = content\n        self.acls = acls or {}\n        self.url = url",
        "detail": "app.functions.text_processor.prepdocslib.listfilestrategy",
        "documentation": {}
    },
    {
        "label": "MediaDescriber",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.mediadescriber",
        "description": "app.functions.text_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",",
        "detail": "app.functions.text_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ContentUnderstandingDescriber",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.mediadescriber",
        "description": "app.functions.text_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n        \"baseAnalyzerId\": \"prebuilt-image\",\n        \"scenario\": \"image\",\n        \"config\": {\"returnDetails\": False},\n        \"fieldSchema\": {",
        "detail": "app.functions.text_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "MultimodalModelDescriber",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.mediadescriber",
        "description": "app.functions.text_processor.prepdocslib.mediadescriber",
        "peekOfCode": "class MultimodalModelDescriber(MediaDescriber):\n    def __init__(self, openai_client: AsyncOpenAI, model: str, deployment: Optional[str] = None):\n        self.openai_client = openai_client\n        self.model = model\n        self.deployment = deployment\n    async def describe_image(self, image_bytes: bytes) -> str:\n        def before_retry_sleep(retry_state):\n            logger.info(\"Rate limited on the OpenAI chat completions API, sleeping before retrying...\")\n        image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n        image_datauri = f\"data:image/png;base64,{image_base64}\"",
        "detail": "app.functions.text_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.mediadescriber",
        "description": "app.functions.text_processor.prepdocslib.mediadescriber",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass MediaDescriber(ABC):\n    async def describe_image(self, image_bytes) -> str:\n        raise NotImplementedError  # pragma: no cover\nclass ContentUnderstandingDescriber(MediaDescriber):\n    CU_API_VERSION = \"2024-12-01-preview\"\n    analyzer_schema = {\n        \"analyzerId\": \"image_analyzer\",\n        \"name\": \"Image understanding\",\n        \"description\": \"Extract detailed structured information from images extracted from documents.\",",
        "detail": "app.functions.text_processor.prepdocslib.mediadescriber",
        "documentation": {}
    },
    {
        "label": "ImageOnPage",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.page",
        "description": "app.functions.text_processor.prepdocslib.page",
        "peekOfCode": "class ImageOnPage:\n    bytes: bytes\n    bbox: tuple[float, float, float, float]  # Pixels\n    filename: str\n    figure_id: str\n    page_num: int  # 0-indexed\n    placeholder: str  # HTML placeholder in page text, e.g. '<figure id=\"fig_...\"></figure>'\n    mime_type: str = \"image/png\"  # Set by parser; default assumes PNG rendering\n    url: Optional[str] = None\n    title: str = \"\"",
        "detail": "app.functions.text_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Page",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.page",
        "description": "app.functions.text_processor.prepdocslib.page",
        "peekOfCode": "class Page:\n    \"\"\"\n    A single page from a document\n    Attributes:\n        page_num (int): Page number (0-indexed)\n        offset (int): If the text of the entire Document was concatenated into a single string, the index of the first character on the page. For example, if page 1 had the text \"hello\" and page 2 had the text \"world\", the offset of page 2 is 5 (\"hellow\")\n        text (str): The text of the page\n    \"\"\"\n    page_num: int\n    offset: int",
        "detail": "app.functions.text_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Chunk",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.page",
        "description": "app.functions.text_processor.prepdocslib.page",
        "peekOfCode": "class Chunk:\n    \"\"\"Semantic chunk emitted by the splitter (may originate wholly within one page\n    or be the result of a cross-page merge / trailing fragment carry-forward).\n    Attributes:\n        page_num (int): Logical source page number (0-indexed) for the originating\n            portion of content. For merged content spanning pages we keep the earliest\n            contributing page number for stable attribution.\n        text (str): Textual content of the chunk.\n        images (list[ImageOnPage]): Images associated with this chunk, if any.\n    \"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.page",
        "documentation": {}
    },
    {
        "label": "Parser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.parser",
        "description": "app.functions.text_processor.prepdocslib.parser",
        "peekOfCode": "class Parser(ABC):\n    \"\"\"\n    Abstract parser that parses content into Page objects\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        if False:\n            yield  # pragma: no cover - this is necessary for mypy to type check",
        "detail": "app.functions.text_processor.prepdocslib.parser",
        "documentation": {}
    },
    {
        "label": "LocalPdfParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.pdfparser",
        "description": "app.functions.text_processor.prepdocslib.pdfparser",
        "peekOfCode": "class LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages\n        offset = 0",
        "detail": "app.functions.text_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "DocumentAnalysisParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.pdfparser",
        "description": "app.functions.text_processor.prepdocslib.pdfparser",
        "peekOfCode": "class DocumentAnalysisParser(Parser):\n    \"\"\"\n    Concrete parser backed by Azure AI Document Intelligence that can parse many document formats into pages\n    To learn more, please visit https://learn.microsoft.com/azure/ai-services/document-intelligence/overview\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        model_id: str = \"prebuilt-layout\",",
        "detail": "app.functions.text_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.pdfparser",
        "description": "app.functions.text_processor.prepdocslib.pdfparser",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass LocalPdfParser(Parser):\n    \"\"\"\n    Concrete parser backed by PyPDF that can parse PDFs into pages\n    To learn more, please visit https://pypi.org/project/pypdf/\n    \"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n        reader = PdfReader(content)\n        pages = reader.pages",
        "detail": "app.functions.text_processor.prepdocslib.pdfparser",
        "documentation": {}
    },
    {
        "label": "Section",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.searchmanager",
        "description": "app.functions.text_processor.prepdocslib.searchmanager",
        "peekOfCode": "class Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field\nclass SearchManager:",
        "detail": "app.functions.text_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "SearchManager",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.searchmanager",
        "description": "app.functions.text_processor.prepdocslib.searchmanager",
        "peekOfCode": "class SearchManager:\n    \"\"\"\n    Class to manage a search service. It can create indexes, and update or remove sections stored in these indexes\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        search_info: SearchInfo,\n        search_analyzer_name: Optional[str] = None,\n        use_acls: bool = False,",
        "detail": "app.functions.text_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.searchmanager",
        "description": "app.functions.text_processor.prepdocslib.searchmanager",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass Section:\n    \"\"\"\n    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n    \"\"\"\n    def __init__(self, chunk: Chunk, content: File, category: Optional[str] = None):\n        self.chunk = chunk  # content comes from here\n        self.content = content  # sourcepage and sourcefile come from here\n        self.category = category\n        # this also needs images which will become the images field",
        "detail": "app.functions.text_processor.prepdocslib.searchmanager",
        "documentation": {}
    },
    {
        "label": "OpenAIHost",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "class OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).\n    LOCAL:        A locally hosted OpenAI-compatible endpoint (no key required).\n    \"\"\"\n    OPENAI = \"openai\"\n    AZURE = \"azure\"\n    AZURE_CUSTOM = \"azure_custom\"",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "clean_key_if_exists",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).\n    AZURE_CUSTOM: A fully custom endpoint URL (for Network Isolation / APIM).",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_search_info",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_search_info(\n    search_service: str,\n    index_name: str,\n    azure_credential: AsyncTokenCredential,\n    use_agentic_retrieval: Optional[bool] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    agent_name: Optional[str] = None,\n    agent_max_output_tokens: Optional[int] = None,\n    azure_openai_searchagent_deployment: Optional[str] = None,\n    azure_openai_searchagent_model: Optional[str] = None,",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_openai_client",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_openai_client(\n    openai_host: OpenAIHost,\n    azure_credential: AsyncTokenCredential,\n    azure_openai_api_key: Optional[str] = None,\n    azure_openai_service: Optional[str] = None,\n    azure_openai_custom_url: Optional[str] = None,\n    openai_api_key: Optional[str] = None,\n    openai_organization: Optional[str] = None,\n) -> tuple[AsyncOpenAI, Optional[str]]:\n    openai_client: AsyncOpenAI",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_image_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_image_embeddings_service(\n    azure_credential: AsyncTokenCredential,\n    vision_endpoint: Optional[str],\n    use_multimodal: bool,\n) -> ImageEmbeddings | None:\n    image_embeddings_service: Optional[ImageEmbeddings] = None\n    if use_multimodal:\n        if vision_endpoint is None:\n            raise ValueError(\"An Azure AI Vision endpoint must be provided to use multimodal features.\")\n        image_embeddings_service = ImageEmbeddings(",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_embeddings_service",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_embeddings_service(\n    openai_host: OpenAIHost,\n    open_ai_client: AsyncOpenAI,\n    emb_model_name: str,\n    emb_model_dimensions: int,\n    azure_openai_deployment: Optional[str] = None,\n    azure_openai_endpoint: Optional[str] = None,\n    disable_batch: bool = False,\n) -> OpenAIEmbeddings:\n    if openai_host in [OpenAIHost.AZURE, OpenAIHost.AZURE_CUSTOM]:",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_blob_manager",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_blob_manager(\n    azure_credential: AsyncTokenCredential | str,\n    storage_account: str,\n    storage_container: str,\n    storage_resource_group: Optional[str] = None,\n    subscription_id: Optional[str] = None,\n    storage_key: Optional[str] = None,\n    image_storage_container: Optional[str] = None,\n) -> BlobManager:\n    \"\"\"Create a BlobManager instance for document or figure storage.",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "setup_figure_processor",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def setup_figure_processor(\n    *,\n    credential: AsyncTokenCredential | None,\n    use_multimodal: bool,\n    use_content_understanding: bool,\n    content_understanding_endpoint: str | None,\n    openai_client: object | None,\n    openai_model: str | None,\n    openai_deployment: str | None,\n) -> FigureProcessor | None:",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "build_file_processors",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def build_file_processors(\n    *,\n    azure_credential: AsyncTokenCredential,\n    document_intelligence_service: str | None,\n    document_intelligence_key: str | None = None,\n    use_local_pdf_parser: bool = False,\n    use_local_html_parser: bool = False,\n    process_figures: bool = False,\n) -> dict[str, FileProcessor]:\n    sentence_text_splitter = SentenceTextSplitter()",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "select_processor_for_filename",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "def select_processor_for_filename(file_name: str, file_processors: dict[str, FileProcessor]) -> FileProcessor:\n    \"\"\"Select the appropriate file processor for a given filename.\n    Args:\n        file_name: Name of the file to process\n        file_processors: Dictionary mapping file extensions to FileProcessor instances\n    Returns:\n        FileProcessor instance for the file\n    Raises:\n        ValueError: If the file extension is not supported\n    \"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.servicesetup",
        "description": "app.functions.text_processor.prepdocslib.servicesetup",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef clean_key_if_exists(key: Optional[str]) -> Optional[str]:\n    \"\"\"Remove leading and trailing whitespace from a key if it exists. If the key is empty, return None.\"\"\"\n    if key is not None and key.strip() != \"\":\n        return key.strip()\n    return None\nclass OpenAIHost(str, Enum):\n    \"\"\"Supported OpenAI hosting styles.\n    OPENAI:       Public OpenAI API.\n    AZURE:        Standard Azure OpenAI (service name becomes endpoint).",
        "detail": "app.functions.text_processor.prepdocslib.servicesetup",
        "documentation": {}
    },
    {
        "label": "SearchInfo",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.strategy",
        "description": "app.functions.text_processor.prepdocslib.strategy",
        "peekOfCode": "class SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,\n        index_name: str,",
        "detail": "app.functions.text_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "DocumentAction",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.strategy",
        "description": "app.functions.text_processor.prepdocslib.strategy",
        "peekOfCode": "class DocumentAction(Enum):\n    Add = 0\n    Remove = 1\n    RemoveAll = 2\nclass Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError",
        "detail": "app.functions.text_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "Strategy",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.strategy",
        "description": "app.functions.text_processor.prepdocslib.strategy",
        "peekOfCode": "class Strategy(ABC):\n    \"\"\"\n    Abstract strategy for ingesting documents into a search service. It has a single setup step to perform any required initialization, and then a run step that actually ingests documents into the search service.\n    \"\"\"\n    async def setup(self):\n        raise NotImplementedError\n    async def run(self):\n        raise NotImplementedError",
        "detail": "app.functions.text_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "USER_AGENT",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.strategy",
        "description": "app.functions.text_processor.prepdocslib.strategy",
        "peekOfCode": "USER_AGENT = \"azure-search-chat-demo/1.0.0\"\nclass SearchInfo:\n    \"\"\"\n    Class representing a connection to a search service\n    To learn more, please visit https://learn.microsoft.com/azure/search/search-what-is-azure-search\n    \"\"\"\n    def __init__(\n        self,\n        endpoint: str,\n        credential: AsyncTokenCredential | AzureKeyCredential,",
        "detail": "app.functions.text_processor.prepdocslib.strategy",
        "documentation": {}
    },
    {
        "label": "TextParser",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.textparser",
        "description": "app.functions.text_processor.prepdocslib.textparser",
        "peekOfCode": "class TextParser(Parser):\n    \"\"\"Parses simple text into a Page object.\"\"\"\n    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n        data = content.read()\n        decoded_data = data.decode(\"utf-8\")\n        text = cleanup_data(decoded_data)\n        yield Page(0, 0, text=text)",
        "detail": "app.functions.text_processor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "cleanup_data",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.textparser",
        "description": "app.functions.text_processor.prepdocslib.textparser",
        "peekOfCode": "def cleanup_data(data: str) -> str:\n    \"\"\"Cleans up the given content using regexes\n    Args:\n        data: (str): The data to clean up.\n    Returns:\n        str: The cleaned up data.\n    \"\"\"\n    # match two or more newlines and replace them with one new line\n    output = re.sub(r\"\\n{2,}\", \"\\n\", data)\n    # match two or more spaces that are not newlines and replace them with one space",
        "detail": "app.functions.text_processor.prepdocslib.textparser",
        "documentation": {}
    },
    {
        "label": "combine_text_with_figures",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.textprocessor",
        "description": "app.functions.text_processor.prepdocslib.textprocessor",
        "peekOfCode": "def combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)\n        elif image.placeholder not in page.text:",
        "detail": "app.functions.text_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "process_text",
        "kind": 2,
        "importPath": "app.functions.text_processor.prepdocslib.textprocessor",
        "description": "app.functions.text_processor.prepdocslib.textprocessor",
        "peekOfCode": "def process_text(\n    pages: list[\"Page\"],\n    file: \"File\",\n    splitter: \"TextSplitter\",\n    category: str | None = None,\n) -> list[\"Section\"]:\n    \"\"\"Process document text and figures into searchable sections.\n    Combines text with figure descriptions, splits into chunks, and\n    associates figures with their containing sections.\n    \"\"\"",
        "detail": "app.functions.text_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textprocessor",
        "description": "app.functions.text_processor.prepdocslib.textprocessor",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef combine_text_with_figures(page: \"Page\") -> None:\n    \"\"\"Replace figure placeholders in page text with full description markup.\"\"\"\n    for image in page.images:\n        if image.description and image.placeholder in page.text:\n            figure_markup = build_figure_markup(image, image.description)\n            page.text = page.text.replace(image.placeholder, figure_markup)\n            logger.info(\"Replaced placeholder for figure %s with description markup\", image.figure_id)\n        elif not image.description:\n            logger.debug(\"No description for figure %s; keeping placeholder\", image.figure_id)",
        "detail": "app.functions.text_processor.prepdocslib.textprocessor",
        "documentation": {}
    },
    {
        "label": "TextSplitter",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "class TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield\nENCODING_MODEL = \"text-embedding-ada-002\"",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "_ChunkBuilder",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "class _ChunkBuilder:\n    \"\"\"Accumulates sentence-like spans for a single page until size limits are reached.\n    Responsibilities:\n    - Track appended text fragments and their approximate token length.\n    - Decide if a new span can be added without exceeding character or token thresholds.\n    - Flush accumulated content into an output list as a `Chunk`.\n    - Allow a figure block to be force-appended (even if it overflows) so that headings + figure stay together.\n    Notes:\n    - Character limit is soft (exact enforcement + later normalization); token limit is hard.\n    - Token counts are computed by the caller and passed to `add`; this class stays agnostic of the encoder.",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SentenceTextSplitter",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "class SentenceTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks. This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_tokens_per_section: int = 500):\n        self.sentence_endings = STANDARD_SENTENCE_ENDINGS + CJK_SENTENCE_ENDINGS\n        self.word_breaks = STANDARD_WORD_BREAKS + CJK_WORD_BREAKS\n        self.max_section_length = DEFAULT_SECTION_LENGTH\n        self.sentence_search_limit = 100\n        self.max_tokens_per_section = max_tokens_per_section",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "SimpleTextSplitter",
        "kind": 6,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "class SimpleTextSplitter(TextSplitter):\n    \"\"\"\n    Class that splits pages into smaller chunks based on a max object length. It is not aware of the content of the page.\n    This is required because embedding models may not be able to analyze an entire page at once\n    \"\"\"\n    def __init__(self, max_object_length: int = 1000):\n        self.max_object_length = max_object_length\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        all_text = \"\".join(page.text for page in pages)\n        if len(all_text.strip()) == 0:",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass TextSplitter(ABC):\n    \"\"\"\n    Splits a list of pages into smaller chunks.\n    :param pages: The pages to split\n    :return: A generator of Chunk\n    \"\"\"\n    def split_pages(self, pages: list[Page]) -> Generator[Chunk, None, None]:\n        if False:  # pragma: no cover - this is necessary for mypy to type check\n            yield",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "ENCODING_MODEL",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "ENCODING_MODEL = \"text-embedding-ada-002\"\nSTANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n# See W3C document https://www.w3.org/TR/jlreq/#cl-01\nCJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_WORD_BREAKS",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_WORD_BREAKS = [\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",\n    \"\",",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "STANDARD_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "STANDARD_SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n# See CL05 and CL06, based on JIS X 4051:2004\n# https://www.w3.org/TR/jlreq/#cl-04\nCJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "CJK_SENTENCE_ENDINGS",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "CJK_SENTENCE_ENDINGS = [\"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\nbpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "bpe",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\nDEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_OVERLAP_PERCENT",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\nDEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "DEFAULT_SECTION_LENGTH",
        "kind": 5,
        "importPath": "app.functions.text_processor.prepdocslib.textsplitter",
        "description": "app.functions.text_processor.prepdocslib.textsplitter",
        "peekOfCode": "DEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\ndef _safe_concat(a: str, b: str) -> str:\n    \"\"\"Concatenate two non-empty segments, inserting a space only when both sides\n    end/start with alphanumerics and no natural boundary exists.\n    Rules:\n    - Both input strings are expected to be non-empty\n    - Preserve existing whitespace if either side already provides a boundary.\n    - Do not insert a space after a closing HTML tag marker '>'.\n    - If both boundary characters are alphanumeric, insert a single space.\n    - Otherwise concatenate directly.",
        "detail": "app.functions.text_processor.prepdocslib.textsplitter",
        "documentation": {}
    },
    {
        "label": "GlobalSettings",
        "kind": 6,
        "importPath": "app.functions.text_processor.function_app",
        "description": "app.functions.text_processor.function_app",
        "peekOfCode": "class GlobalSettings:\n    use_vectors: bool\n    use_multimodal: bool\n    embedding_dimensions: int\n    file_processors: dict[str, FileProcessor]\n    embedding_service: OpenAIEmbeddings | None\nsettings: GlobalSettings | None = None\ndef configure_global_settings():\n    global settings\n    # Environment configuration",
        "detail": "app.functions.text_processor.function_app",
        "documentation": {}
    },
    {
        "label": "configure_global_settings",
        "kind": 2,
        "importPath": "app.functions.text_processor.function_app",
        "description": "app.functions.text_processor.function_app",
        "peekOfCode": "def configure_global_settings():\n    global settings\n    # Environment configuration\n    use_vectors = os.getenv(\"USE_VECTORS\", \"true\").lower() == \"true\"\n    use_multimodal = os.getenv(\"USE_MULTIMODAL\", \"false\").lower() == \"true\"\n    embedding_dimensions = int(os.getenv(\"AZURE_OPENAI_EMB_DIMENSIONS\", \"3072\"))\n    # Conditionally required (based on feature flags)\n    openai_host_str = os.getenv(\"OPENAI_HOST\", \"azure\")\n    azure_openai_service = os.getenv(\"AZURE_OPENAI_SERVICE\")\n    azure_openai_custom_url = os.getenv(\"AZURE_OPENAI_CUSTOM_URL\")",
        "detail": "app.functions.text_processor.function_app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "app.functions.text_processor.function_app",
        "description": "app.functions.text_processor.function_app",
        "peekOfCode": "app = func.FunctionApp(http_auth_level=func.AuthLevel.ANONYMOUS)\nlogger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    use_vectors: bool\n    use_multimodal: bool\n    embedding_dimensions: int\n    file_processors: dict[str, FileProcessor]\n    embedding_service: OpenAIEmbeddings | None\nsettings: GlobalSettings | None = None",
        "detail": "app.functions.text_processor.function_app",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "app.functions.text_processor.function_app",
        "description": "app.functions.text_processor.function_app",
        "peekOfCode": "logger = logging.getLogger(__name__)\n@dataclass\nclass GlobalSettings:\n    use_vectors: bool\n    use_multimodal: bool\n    embedding_dimensions: int\n    file_processors: dict[str, FileProcessor]\n    embedding_service: OpenAIEmbeddings | None\nsettings: GlobalSettings | None = None\ndef configure_global_settings():",
        "detail": "app.functions.text_processor.function_app",
        "documentation": {}
    },
    {
        "label": "AnyCitationMetric",
        "kind": 6,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "class AnyCitationMetric(BaseMetric):\n    METRIC_NAME = \"any_citation\"\n    @classmethod\n    def evaluator_fn(cls, **kwargs):\n        def any_citation(*, response, **kwargs):\n            if response is None:\n                logger.warning(\"Received response of None, can't compute any_citation metric. Setting to -1.\")\n                return {cls.METRIC_NAME: -1}\n            return {cls.METRIC_NAME: bool(CITATION_REGEX.search(response))}\n        return any_citation",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "CitationsMatchedMetric",
        "kind": 6,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "class CitationsMatchedMetric(BaseMetric):\n    METRIC_NAME = \"citations_matched\"\n    @classmethod\n    def evaluator_fn(cls, **kwargs):\n        def citations_matched(*, response, ground_truth, **kwargs):\n            if response is None:\n                logger.warning(\"Received response of None, can't compute citation_match metric. Setting to -1.\")\n                return {cls.METRIC_NAME: -1}\n            # Extract full citation tokens from ground truth and response\n            truth_citations = set(CITATION_REGEX.findall(ground_truth or \"\"))",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "get_openai_config",
        "kind": 2,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "def get_openai_config():\n    azure_endpoint = f\"https://{os.getenv('AZURE_OPENAI_SERVICE')}.openai.azure.com\"\n    azure_deployment = os.environ[\"AZURE_OPENAI_EVAL_DEPLOYMENT\"]\n    openai_config = {\"azure_endpoint\": azure_endpoint, \"azure_deployment\": azure_deployment}\n    # azure-ai-evaluate will call DefaultAzureCredential behind the scenes,\n    # so we must be logged in to Azure CLI with the correct tenant\n    return openai_config\ndef get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "get_azure_credential",
        "kind": 2,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "def get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential with tenant_id %s\", AZURE_TENANT_ID)\n        azure_credential = AzureDeveloperCliCredential(tenant_id=AZURE_TENANT_ID, process_timeout=60)\n    else:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential for home tenant\")\n        azure_credential = AzureDeveloperCliCredential(process_timeout=60)\n    return azure_credential\nif __name__ == \"__main__\":",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "logger = logging.getLogger(\"ragapp\")\n# Regex pattern to match citations of the forms:\n# [Document Name.pdf#page=7]\n# [Document Name.pdf#page=4(figure4_1.png)]\n# and supports multiple document extensions such as:\n#  pdf, html/htm, doc/docx, ppt/pptx, xls/xlsx, csv, txt, json,\n#  images: jpg/jpeg, png, bmp (listed as BPM in doc), tiff/tif, heif/heiff\n# Optional components:\n#   #page=\\d+           -> page anchor (primarily for paged docs like PDFs)\n#   ( ... )              -> figure/image or sub-resource reference (e.g., (figure4_1.png))",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "CITATION_REGEX",
        "kind": 5,
        "importPath": "evals.evaluate",
        "description": "evals.evaluate",
        "peekOfCode": "CITATION_REGEX = re.compile(\n    r\"\\[[^\\]]+?\\.(?:pdf|html?|docx?|pptx?|xlsx?|csv|txt|json|jpe?g|png|bmp|tiff?|heiff?|heif)(?:#page=\\d+)?(?:\\([^()\\]]+\\))?\\]\",\n    re.IGNORECASE,\n)\nclass AnyCitationMetric(BaseMetric):\n    METRIC_NAME = \"any_citation\"\n    @classmethod\n    def evaluator_fn(cls, **kwargs):\n        def any_citation(*, response, **kwargs):\n            if response is None:",
        "detail": "evals.evaluate",
        "documentation": {}
    },
    {
        "label": "get_azure_credential",
        "kind": 2,
        "importPath": "evals.generate_ground_truth",
        "description": "evals.generate_ground_truth",
        "peekOfCode": "def get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential with tenant_id %s\", AZURE_TENANT_ID)\n        azure_credential = AzureDeveloperCliCredential(tenant_id=AZURE_TENANT_ID, process_timeout=60)\n    else:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential for home tenant\")\n        azure_credential = AzureDeveloperCliCredential(process_timeout=60)\n    return azure_credential\ndef get_search_documents(azure_credential, num_search_documents=None) -> str:",
        "detail": "evals.generate_ground_truth",
        "documentation": {}
    },
    {
        "label": "get_search_documents",
        "kind": 2,
        "importPath": "evals.generate_ground_truth",
        "description": "evals.generate_ground_truth",
        "peekOfCode": "def get_search_documents(azure_credential, num_search_documents=None) -> str:\n    search_client = SearchClient(\n        endpoint=f\"https://{os.getenv('AZURE_SEARCH_SERVICE')}.search.windows.net\",\n        index_name=os.getenv(\"AZURE_SEARCH_INDEX\"),\n        credential=azure_credential,\n    )\n    all_documents = []\n    if num_search_documents is None:\n        logger.info(\"Fetching all document chunks from Azure AI Search\")\n        num_search_documents = 100000",
        "detail": "evals.generate_ground_truth",
        "documentation": {}
    },
    {
        "label": "generate_ground_truth_ragas",
        "kind": 2,
        "importPath": "evals.generate_ground_truth",
        "description": "evals.generate_ground_truth",
        "peekOfCode": "def generate_ground_truth_ragas(num_questions=200, num_search_documents=None, kg_file=None):\n    azure_credential = get_azure_credential()\n    azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\") or \"2024-06-01\"\n    azure_endpoint = f\"https://{os.getenv('AZURE_OPENAI_SERVICE')}.openai.azure.com\"\n    azure_ad_token_provider = get_bearer_token_provider(\n        azure_credential, \"https://cognitiveservices.azure.com/.default\"\n    )\n    generator_llm = LangchainLLMWrapper(\n        AzureChatOpenAI(\n            openai_api_version=azure_openai_api_version,",
        "detail": "evals.generate_ground_truth",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "evals.generate_ground_truth",
        "description": "evals.generate_ground_truth",
        "peekOfCode": "logger = logging.getLogger(\"ragapp\")\nroot_dir = pathlib.Path(__file__).parent\ndef get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential with tenant_id %s\", AZURE_TENANT_ID)\n        azure_credential = AzureDeveloperCliCredential(tenant_id=AZURE_TENANT_ID, process_timeout=60)\n    else:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential for home tenant\")\n        azure_credential = AzureDeveloperCliCredential(process_timeout=60)",
        "detail": "evals.generate_ground_truth",
        "documentation": {}
    },
    {
        "label": "root_dir",
        "kind": 5,
        "importPath": "evals.generate_ground_truth",
        "description": "evals.generate_ground_truth",
        "peekOfCode": "root_dir = pathlib.Path(__file__).parent\ndef get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential with tenant_id %s\", AZURE_TENANT_ID)\n        azure_credential = AzureDeveloperCliCredential(tenant_id=AZURE_TENANT_ID, process_timeout=60)\n    else:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential for home tenant\")\n        azure_credential = AzureDeveloperCliCredential(process_timeout=60)\n    return azure_credential",
        "detail": "evals.generate_ground_truth",
        "documentation": {}
    },
    {
        "label": "HarmSeverityLevel",
        "kind": 6,
        "importPath": "evals.safety_evaluation",
        "description": "evals.safety_evaluation",
        "peekOfCode": "class HarmSeverityLevel(Enum):\n    \"\"\"Harm severity levels reported by the Azure AI Evaluator service.\n    These constants have been copied from the azure-ai-evaluation package,\n    where they're currently in a private module.\n    \"\"\"\n    VeryLow = \"Very low\"\n    Low = \"Low\"\n    Medium = \"Medium\"\n    High = \"High\"\ndef get_azure_credential():",
        "detail": "evals.safety_evaluation",
        "documentation": {}
    },
    {
        "label": "get_azure_credential",
        "kind": 2,
        "importPath": "evals.safety_evaluation",
        "description": "evals.safety_evaluation",
        "peekOfCode": "def get_azure_credential():\n    AZURE_TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n    if AZURE_TENANT_ID:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential with tenant_id %s\", AZURE_TENANT_ID)\n        azure_credential = AzureDeveloperCliCredential(tenant_id=AZURE_TENANT_ID, process_timeout=60)\n    else:\n        logger.info(\"Setting up Azure credential using AzureDeveloperCliCredential for home tenant\")\n        azure_credential = AzureDeveloperCliCredential(process_timeout=60)\n    return azure_credential\nasync def callback(",
        "detail": "evals.safety_evaluation",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "evals.safety_evaluation",
        "description": "evals.safety_evaluation",
        "peekOfCode": "logger = logging.getLogger(\"ragapp\")\nroot_dir = pathlib.Path(__file__).parent\nclass HarmSeverityLevel(Enum):\n    \"\"\"Harm severity levels reported by the Azure AI Evaluator service.\n    These constants have been copied from the azure-ai-evaluation package,\n    where they're currently in a private module.\n    \"\"\"\n    VeryLow = \"Very low\"\n    Low = \"Low\"\n    Medium = \"Medium\"",
        "detail": "evals.safety_evaluation",
        "documentation": {}
    },
    {
        "label": "root_dir",
        "kind": 5,
        "importPath": "evals.safety_evaluation",
        "description": "evals.safety_evaluation",
        "peekOfCode": "root_dir = pathlib.Path(__file__).parent\nclass HarmSeverityLevel(Enum):\n    \"\"\"Harm severity levels reported by the Azure AI Evaluator service.\n    These constants have been copied from the azure-ai-evaluation package,\n    where they're currently in a private module.\n    \"\"\"\n    VeryLow = \"Very low\"\n    Low = \"Low\"\n    Medium = \"Medium\"\n    High = \"High\"",
        "detail": "evals.safety_evaluation",
        "documentation": {}
    },
    {
        "label": "AdlsGen2Setup",
        "kind": 6,
        "importPath": "scripts.adlsgen2setup",
        "description": "scripts.adlsgen2setup",
        "peekOfCode": "class AdlsGen2Setup:\n    \"\"\"\n    Sets up a Data Lake Storage Gen 2 account with sample data and access control\n    \"\"\"\n    def __init__(\n        self,\n        data_directory: str,\n        storage_account_name: str,\n        filesystem_name: str,\n        security_enabled_groups: bool,",
        "detail": "scripts.adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "scripts.adlsgen2setup",
        "description": "scripts.adlsgen2setup",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass AdlsGen2Setup:\n    \"\"\"\n    Sets up a Data Lake Storage Gen 2 account with sample data and access control\n    \"\"\"\n    def __init__(\n        self,\n        data_directory: str,\n        storage_account_name: str,\n        filesystem_name: str,",
        "detail": "scripts.adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "test_authentication_enabled",
        "kind": 2,
        "importPath": "scripts.auth_common",
        "description": "scripts.auth_common",
        "peekOfCode": "def test_authentication_enabled():\n    use_authentication = os.getenv(\"AZURE_USE_AUTHENTICATION\", \"\").lower() == \"true\"\n    enforce_access_control = os.getenv(\"AZURE_ENFORCE_ACCESS_CONTROL\", \"\").lower() == \"true\"\n    if enforce_access_control and not use_authentication:\n        print(\"AZURE_ENFORCE_ACCESS_CONTROL is true, but AZURE_USE_AUTHENTICATION is false. Stopping...\")\n        return False\n    if not use_authentication:\n        return False\n    return True",
        "detail": "scripts.auth_common",
        "documentation": {}
    },
    {
        "label": "GrantDefinition",
        "kind": 6,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "class GrantDefinition:\n    principal_id: str\n    resource_app_id: str\n    scopes: list[str]\n    target_label: str\n    def scope_string(self) -> str:\n        return \" \".join(self.scopes)\n# Required for the server app to work correctly\n# See https://learn.microsoft.com/graph/api/oauth2permissiongrant-post for more information\nasync def grant_application_admin_consent(graph_client: GraphServiceClient, client_app_id: str, server_app_id: str):",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "update_azd_env",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def update_azd_env(name, val):\n    subprocess.run(f'azd env set {name} \"{val}\"', shell=True)\ndef random_app_identifier():\n    rand = random.Random()\n    rand.seed(datetime.datetime.now().timestamp())\n    return rand.randint(1000, 100000)\ndef server_app_initial(identifier: int) -> Application:\n    return Application(\n        display_name=f\"Azure Search OpenAI Chat Server App {identifier}\",\n        sign_in_audience=\"AzureADMyOrg\",",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "random_app_identifier",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def random_app_identifier():\n    rand = random.Random()\n    rand.seed(datetime.datetime.now().timestamp())\n    return rand.randint(1000, 100000)\ndef server_app_initial(identifier: int) -> Application:\n    return Application(\n        display_name=f\"Azure Search OpenAI Chat Server App {identifier}\",\n        sign_in_audience=\"AzureADMyOrg\",\n    )\ndef server_app_permission_setup(server_app_id: str) -> Application:",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "server_app_initial",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def server_app_initial(identifier: int) -> Application:\n    return Application(\n        display_name=f\"Azure Search OpenAI Chat Server App {identifier}\",\n        sign_in_audience=\"AzureADMyOrg\",\n    )\ndef server_app_permission_setup(server_app_id: str) -> Application:\n    return Application(\n        api=ApiApplication(\n            known_client_applications=[],\n            oauth2_permission_scopes=[",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "server_app_permission_setup",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def server_app_permission_setup(server_app_id: str) -> Application:\n    return Application(\n        api=ApiApplication(\n            known_client_applications=[],\n            oauth2_permission_scopes=[\n                PermissionScope(\n                    id=uuid.UUID(\"{7b207263-0c4a-4127-a6fe-38ea8c8cd1a7}\"),\n                    admin_consent_display_name=\"Access Azure Search OpenAI Chat API\",\n                    admin_consent_description=\"Allows the app to access Azure Search OpenAI Chat API as the signed-in user.\",\n                    user_consent_display_name=\"Access Azure Search OpenAI Chat API\",",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "client_app",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def client_app(server_app_id: str, server_app: Application, identifier: int) -> Application:\n    if server_app.api is None:\n        raise ValueError(\"Server app does not have an API\")\n    if server_app.api.oauth2_permission_scopes is None or len(server_app.api.oauth2_permission_scopes) == 0:\n        raise ValueError(\"Server app does not have any permission scopes\")\n    return Application(\n        display_name=f\"Azure Search OpenAI Chat Client App {identifier}\",\n        sign_in_audience=\"AzureADMyOrg\",\n        web=WebApplication(\n            redirect_uris=[\"http://localhost:50505/.auth/login/aad/callback\"],",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "server_app_known_client_application",
        "kind": 2,
        "importPath": "scripts.auth_init",
        "description": "scripts.auth_init",
        "peekOfCode": "def server_app_known_client_application(client_app_id: str) -> Application:\n    return Application(\n        api=ApiApplication(\n            known_client_applications=[uuid.UUID(f\"{client_app_id}\")],\n        )\n    )\n@dataclass\nclass GrantDefinition:\n    principal_id: str\n    resource_app_id: str",
        "detail": "scripts.auth_init",
        "documentation": {}
    },
    {
        "label": "copy_tree",
        "kind": 2,
        "importPath": "scripts.copy_prepdocslib",
        "description": "scripts.copy_prepdocslib",
        "peekOfCode": "def copy_tree(src: Path, dest: Path) -> None:\n    if dest.exists():\n        shutil.rmtree(dest)\n    shutil.copytree(src, dest)\ndef main() -> None:\n    repo_root = Path(__file__).resolve().parent.parent\n    prep_source = repo_root / \"app\" / \"backend\" / \"prepdocslib\"\n    if not prep_source.exists():\n        raise RuntimeError(f\"Source prepdocslib directory not found: {prep_source}\")\n    backend_requirements = repo_root / \"app\" / \"backend\" / \"requirements.txt\"",
        "detail": "scripts.copy_prepdocslib",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.copy_prepdocslib",
        "description": "scripts.copy_prepdocslib",
        "peekOfCode": "def main() -> None:\n    repo_root = Path(__file__).resolve().parent.parent\n    prep_source = repo_root / \"app\" / \"backend\" / \"prepdocslib\"\n    if not prep_source.exists():\n        raise RuntimeError(f\"Source prepdocslib directory not found: {prep_source}\")\n    backend_requirements = repo_root / \"app\" / \"backend\" / \"requirements.txt\"\n    if not backend_requirements.exists():\n        raise RuntimeError(f\"Backend requirements file not found: {backend_requirements}\")\n    targets = [\n        repo_root / \"app\" / \"functions\" / \"document_extractor\" / \"prepdocslib\",",
        "detail": "scripts.copy_prepdocslib",
        "documentation": {}
    },
    {
        "label": "CosmosDBMigrator",
        "kind": 6,
        "importPath": "scripts.cosmosdb_migration",
        "description": "scripts.cosmosdb_migration",
        "peekOfCode": "class CosmosDBMigrator:\n    \"\"\"\n    Migrator class for CosmosDB data migration.\n    \"\"\"\n    def __init__(self, cosmos_account, database_name, credential=None):\n        \"\"\"\n        Initialize the migrator with CosmosDB account and database.\n        Args:\n            cosmos_account: CosmosDB account name\n            database_name: Database name",
        "detail": "scripts.cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "load_azd_env",
        "kind": 2,
        "importPath": "scripts.load_azd_env",
        "description": "scripts.load_azd_env",
        "peekOfCode": "def load_azd_env():\n    \"\"\"Get path to current azd env file and load file using python-dotenv\"\"\"\n    result = subprocess.run(\"azd env list -o json\", shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise Exception(\"Error loading azd env\")\n    env_json = json.loads(result.stdout)\n    env_file_path = None\n    for entry in env_json:\n        if entry[\"IsDefault\"]:\n            env_file_path = entry[\"DotEnvPath\"]",
        "detail": "scripts.load_azd_env",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "scripts.load_azd_env",
        "description": "scripts.load_azd_env",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\ndef load_azd_env():\n    \"\"\"Get path to current azd env file and load file using python-dotenv\"\"\"\n    result = subprocess.run(\"azd env list -o json\", shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise Exception(\"Error loading azd env\")\n    env_json = json.loads(result.stdout)\n    env_file_path = None\n    for entry in env_json:\n        if entry[\"IsDefault\"]:",
        "detail": "scripts.load_azd_env",
        "documentation": {}
    },
    {
        "label": "ManageAcl",
        "kind": 6,
        "importPath": "scripts.manageacl",
        "description": "scripts.manageacl",
        "peekOfCode": "class ManageAcl:\n    \"\"\"\n    Manually enable document level access control on a search index and manually set access control values using the [manageacl.ps1](./scripts/manageacl.ps1) script.\n    \"\"\"\n    def __init__(\n        self,\n        service_name: str,\n        index_name: str,\n        url: str,\n        acl_action: str,",
        "detail": "scripts.manageacl",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "scripts.manageacl",
        "description": "scripts.manageacl",
        "peekOfCode": "logger = logging.getLogger(\"scripts\")\nclass ManageAcl:\n    \"\"\"\n    Manually enable document level access control on a search index and manually set access control values using the [manageacl.ps1](./scripts/manageacl.ps1) script.\n    \"\"\"\n    def __init__(\n        self,\n        service_name: str,\n        index_name: str,\n        url: str,",
        "detail": "scripts.manageacl",
        "documentation": {}
    },
    {
        "label": "create_mock_retrieve",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def create_mock_retrieve(response_type=\"default\"):\n    \"\"\"Create a mock_retrieve function that returns different response types.\n    Supported response_type values:\n      - \"default\": single reference response\n      - \"sorting\": multiple refs to test ordering / interleaving\n      - \"top_limit\": many refs to test early breaking via top limit\n    \"\"\"\n    async def mock_retrieve_parameterized(self, *args, **kwargs):\n        retrieval_request = kwargs.get(\"retrieval_request\")\n        assert retrieval_request is not None",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_azurehttp_calls",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_azurehttp_calls(monkeypatch):\n    def mock_post(*args, **kwargs):\n        if kwargs.get(\"url\").endswith(\"computervision/retrieval:vectorizeText\"):\n            return mock_vision_response()\n        elif kwargs.get(\"url\").endswith(\"computervision/retrieval:vectorizeImage\"):\n            return mock_vision_response()\n        else:\n            raise Exception(\"Unexpected URL for mock call to ClientSession.post()\")\n    monkeypatch.setattr(aiohttp.ClientSession, \"post\", mock_post)\n@pytest.fixture",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_speech_success",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_speech_success(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_success)\n@pytest.fixture\ndef mock_speech_cancelled(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_cancelled)\n@pytest.fixture\ndef mock_speech_failed(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_failed)\n@pytest.fixture\ndef mock_openai_embedding(monkeypatch):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_speech_cancelled",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_speech_cancelled(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_cancelled)\n@pytest.fixture\ndef mock_speech_failed(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_failed)\n@pytest.fixture\ndef mock_openai_embedding(monkeypatch):\n    async def mock_acreate(*args, **kwargs):\n        return CreateEmbeddingResponse(\n            object=\"list\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_speech_failed",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_speech_failed(monkeypatch):\n    monkeypatch.setattr(azure.cognitiveservices.speech.SpeechSynthesizer, \"speak_text_async\", mock_speak_text_failed)\n@pytest.fixture\ndef mock_openai_embedding(monkeypatch):\n    async def mock_acreate(*args, **kwargs):\n        return CreateEmbeddingResponse(\n            object=\"list\",\n            data=[\n                Embedding(\n                    embedding=[",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_openai_embedding",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_openai_embedding(monkeypatch):\n    async def mock_acreate(*args, **kwargs):\n        return CreateEmbeddingResponse(\n            object=\"list\",\n            data=[\n                Embedding(\n                    embedding=[\n                        0.0023064255,\n                        -0.009327292,\n                        -0.0028842222,",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_openai_chatcompletion",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_openai_chatcompletion(monkeypatch):\n    class AsyncChatCompletionIterator:\n        def __init__(self, answer: str, reasoning: bool, usage: dict[str, Any]):\n            chunk_id = \"test-id\"\n            model = \"gpt-4.1-mini\" if not reasoning else \"o3-mini\"\n            self.responses = [\n                {\"object\": \"chat.completion.chunk\", \"choices\": [], \"id\": chunk_id, \"model\": model, \"created\": 1},\n                {\n                    \"object\": \"chat.completion.chunk\",\n                    \"choices\": [{\"delta\": {\"role\": \"assistant\"}, \"index\": 0, \"finish_reason\": None}],",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_acs_search",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_acs_search(monkeypatch):\n    monkeypatch.setattr(SearchClient, \"search\", mock_search)\n    async def mock_get_index(*args, **kwargs):\n        return MockSearchIndex\n    monkeypatch.setattr(SearchIndexClient, \"get_index\", mock_get_index)\n@pytest.fixture\ndef mock_acs_agent(monkeypatch):\n    monkeypatch.setattr(KnowledgeAgentRetrievalClient, \"retrieve\", create_mock_retrieve())\n    async def mock_get_agent(*args, **kwargs):\n        return MockAgent",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_acs_agent",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_acs_agent(monkeypatch):\n    monkeypatch.setattr(KnowledgeAgentRetrievalClient, \"retrieve\", create_mock_retrieve())\n    async def mock_get_agent(*args, **kwargs):\n        return MockAgent\n    monkeypatch.setattr(SearchIndexClient, \"get_agent\", mock_get_agent)\n@pytest.fixture\ndef mock_acs_search_filter(monkeypatch):\n    monkeypatch.setattr(SearchClient, \"search\", mock_search)\n    async def mock_get_index(*args, **kwargs):\n        return MockSearchIndex",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_acs_search_filter",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_acs_search_filter(monkeypatch):\n    monkeypatch.setattr(SearchClient, \"search\", mock_search)\n    async def mock_get_index(*args, **kwargs):\n        return MockSearchIndex\n    monkeypatch.setattr(SearchIndexClient, \"get_index\", mock_get_index)\n@pytest.fixture\ndef mock_blob_container_client(monkeypatch):\n    monkeypatch.setattr(ContainerClient, \"get_blob_client\", lambda *args, **kwargs: MockBlobClient())\n@pytest.fixture\ndef mock_blob_container_client_exists(monkeypatch):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_blob_container_client",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_blob_container_client(monkeypatch):\n    monkeypatch.setattr(ContainerClient, \"get_blob_client\", lambda *args, **kwargs: MockBlobClient())\n@pytest.fixture\ndef mock_blob_container_client_exists(monkeypatch):\n    async def mock_exists(*args, **kwargs):\n        return True\n    monkeypatch.setattr(\"azure.storage.blob.aio.ContainerClient.exists\", mock_exists)\n@pytest.fixture\ndef mock_blob_container_client_does_not_exist(monkeypatch):\n    async def mock_exists(*args, **kwargs):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_blob_container_client_exists",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_blob_container_client_exists(monkeypatch):\n    async def mock_exists(*args, **kwargs):\n        return True\n    monkeypatch.setattr(\"azure.storage.blob.aio.ContainerClient.exists\", mock_exists)\n@pytest.fixture\ndef mock_blob_container_client_does_not_exist(monkeypatch):\n    async def mock_exists(*args, **kwargs):\n        return False\n    monkeypatch.setattr(\"azure.storage.blob.aio.ContainerClient.exists\", mock_exists)\nenvs = [",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_blob_container_client_does_not_exist",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_blob_container_client_does_not_exist(monkeypatch):\n    async def mock_exists(*args, **kwargs):\n        return False\n    monkeypatch.setattr(\"azure.storage.blob.aio.ContainerClient.exists\", mock_exists)\nenvs = [\n    {\n        \"OPENAI_HOST\": \"openai\",\n        \"OPENAI_API_KEY\": \"secretkey\",\n        \"OPENAI_ORGANIZATION\": \"organization\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_IMAGESTORAGE_CONTAINER\", \"test-image-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"ENABLE_LANGUAGE_PICKER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_INPUT_BROWSER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_OUTPUT_AZURE\", \"true\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_reasoning_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_reasoning_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"ENABLE_LANGUAGE_PICKER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_INPUT_BROWSER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_OUTPUT_AZURE\", \"true\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_agent_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_agent_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"ENABLE_LANGUAGE_PICKER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_INPUT_BROWSER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_OUTPUT_AZURE\", \"true\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_agent_auth_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_agent_auth_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"ENABLE_LANGUAGE_PICKER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_INPUT_BROWSER\", \"true\")\n        monkeypatch.setenv(\"USE_SPEECH_OUTPUT_AZURE\", \"true\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_vision_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_vision_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_IMAGESTORAGE_CONTAINER\", \"test-image-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")\n        monkeypatch.setenv(\"AZURE_SEARCH_SERVICE\", \"test-search-service\")\n        monkeypatch.setenv(\"AZURE_OPENAI_CHATGPT_MODEL\", \"gpt-4.1-mini\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_vision_auth_env",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_vision_auth_env(monkeypatch, request):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_IMAGESTORAGE_CONTAINER\", \"test-image-container\")\n        monkeypatch.setenv(\"AZURE_STORAGE_RESOURCE_GROUP\", \"test-storage-rg\")\n        monkeypatch.setenv(\"AZURE_SUBSCRIPTION_ID\", \"test-storage-subid\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")\n        monkeypatch.setenv(\"AZURE_SEARCH_SERVICE\", \"test-search-service\")\n        monkeypatch.setenv(\"AZURE_OPENAI_CHATGPT_MODEL\", \"gpt-4.1-mini\")",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_validate_token_success",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_validate_token_success(monkeypatch):\n    async def mock_validate_access_token(self, token):\n        pass\n    monkeypatch.setattr(core.authentication.AuthenticationHelper, \"validate_access_token\", mock_validate_access_token)\n@pytest.fixture\ndef mock_confidential_client_success(monkeypatch):\n    def mock_acquire_token_on_behalf_of(self, *args, **kwargs):\n        assert kwargs.get(\"user_assertion\") is not None\n        scopes = kwargs.get(\"scopes\")\n        assert scopes == [AuthenticationHelper.scope]",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_confidential_client_success",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_confidential_client_success(monkeypatch):\n    def mock_acquire_token_on_behalf_of(self, *args, **kwargs):\n        assert kwargs.get(\"user_assertion\") is not None\n        scopes = kwargs.get(\"scopes\")\n        assert scopes == [AuthenticationHelper.scope]\n        return {\"access_token\": \"MockToken\", \"id_token_claims\": {\"oid\": \"OID_X\"}}\n    monkeypatch.setattr(\n        msal.ConfidentialClientApplication, \"acquire_token_on_behalf_of\", mock_acquire_token_on_behalf_of\n    )\n    def mock_init(self, *args, **kwargs):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_confidential_client_unauthorized",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_confidential_client_unauthorized(monkeypatch):\n    def mock_acquire_token_on_behalf_of(self, *args, **kwargs):\n        assert kwargs.get(\"user_assertion\") is not None\n        scopes = kwargs.get(\"scopes\")\n        assert scopes == [AuthenticationHelper.scope]\n        return {\"error\": \"unauthorized\"}\n    monkeypatch.setattr(\n        msal.ConfidentialClientApplication, \"acquire_token_on_behalf_of\", mock_acquire_token_on_behalf_of\n    )\n    def mock_init(self, *args, **kwargs):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_data_lake_service_client",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_data_lake_service_client(monkeypatch):\n    def mock_init(self, *args, **kwargs):\n        pass\n    async def mock_aenter(self, *args, **kwargs):\n        return self\n    async def mock_aexit(self, *args, **kwargs):\n        return self\n    def mock_get_file_system_client(self, *args, **kwargs):\n        return azure.storage.filedatalake.FileSystemClient(account_url=None, file_system_name=None, credential=None)\n    def mock_init_service_client_aio(self, *args, **kwargs):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "mock_user_directory_client",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def mock_user_directory_client(monkeypatch):\n    monkeypatch.setattr(\n        azure.storage.filedatalake.aio.FileSystemClient,\n        \"get_directory_client\",\n        lambda *args, **kwargs: MockDirectoryClient(),\n    )\n@pytest.fixture\ndef chat_approach():\n    return ChatReadRetrieveReadApproach(\n        search_client=SearchClient(endpoint=\"\", index_name=\"\", credential=AzureKeyCredential(\"\")),",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "chat_approach",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def chat_approach():\n    return ChatReadRetrieveReadApproach(\n        search_client=SearchClient(endpoint=\"\", index_name=\"\", credential=AzureKeyCredential(\"\")),\n        search_index_name=None,\n        agent_model=None,\n        agent_deployment=None,\n        agent_client=None,\n        openai_client=None,\n        chatgpt_model=\"gpt-4.1-mini\",\n        chatgpt_deployment=\"chat\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "MockSearchIndex",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "MockSearchIndex = SearchIndex(\n    name=\"test\",\n    fields=[\n        SearchField(name=\"oids\", type=\"Collection(Edm.String)\"),\n        SearchField(name=\"groups\", type=\"Collection(Edm.String)\"),\n    ],\n)\nMockAgent = KnowledgeAgent(\n    name=\"test\",\n    models=[],",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "MockAgent",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "MockAgent = KnowledgeAgent(\n    name=\"test\",\n    models=[],\n    knowledge_sources=[\n        SearchIndexKnowledgeSource(\n            name=\"test\",\n            description=\"The default index for searching\",\n            search_index_parameters=SearchIndexKnowledgeSourceParameters(\n                search_index_name=\"test\", include_reference_source_data=True\n            ),",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "envs = [\n    {\n        \"OPENAI_HOST\": \"openai\",\n        \"OPENAI_API_KEY\": \"secretkey\",\n        \"OPENAI_ORGANIZATION\": \"organization\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",\n        \"AZURE_OPENAI_EMB_DIMENSIONS\": \"3072\",\n    },\n    {\n        \"OPENAI_HOST\": \"azure\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "vision_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "vision_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"test-chatgpt\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",\n        \"AZURE_OPENAI_EMB_DIMENSIONS\": \"3072\",\n        \"USE_MULTIMODAL\": \"true\",\n        \"AZURE_VISION_ENDPOINT\": \"https://testvision.cognitiveservices.azure.com/\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "vision_auth_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "vision_auth_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"test-chatgpt\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",\n        \"AZURE_OPENAI_EMB_DIMENSIONS\": \"3072\",\n        \"USE_MULTIMODAL\": \"true\",\n        \"AZURE_USE_AUTHENTICATION\": \"true\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "auth_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "auth_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"test-chatgpt\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",\n        \"AZURE_OPENAI_EMB_DIMENSIONS\": \"3072\",\n        \"AZURE_USE_AUTHENTICATION\": \"true\",\n        \"AZURE_ENFORCE_ACCESS_CONTROL\": \"true\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "auth_public_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "auth_public_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"test-chatgpt\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_EMB_MODEL_NAME\": \"text-embedding-3-large\",\n        \"AZURE_OPENAI_EMB_DIMENSIONS\": \"3072\",\n        \"AZURE_USE_AUTHENTICATION\": \"true\",\n        \"AZURE_ENFORCE_ACCESS_CONTROL\": \"true\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "reasoning_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "reasoning_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_MODEL\": \"o3-mini\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"o3-mini\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n    },\n    {\n        \"OPENAI_HOST\": \"azure\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "agent_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "agent_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_MODEL\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_SEARCHAGENT_MODEL\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_SEARCHAGENT_DEPLOYMENT\": \"gpt-4.1-mini\",\n        \"USE_AGENTIC_RETRIEVAL\": \"true\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "agent_auth_envs",
        "kind": 5,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "agent_auth_envs = [\n    {\n        \"OPENAI_HOST\": \"azure\",\n        \"AZURE_OPENAI_SERVICE\": \"test-openai-service\",\n        \"AZURE_OPENAI_CHATGPT_MODEL\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_CHATGPT_DEPLOYMENT\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_EMB_DEPLOYMENT\": \"test-ada\",\n        \"AZURE_OPENAI_SEARCHAGENT_MODEL\": \"gpt-4.1-mini\",\n        \"AZURE_OPENAI_SEARCHAGENT_DEPLOYMENT\": \"gpt-4.1-mini\",\n        \"USE_AGENTIC_RETRIEVAL\": \"true\",",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "wait_for_server_ready",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def wait_for_server_ready(url: str, timeout: float = 10.0, check_interval: float = 0.5) -> bool:\n    \"\"\"Make requests to provided url until it responds without error.\"\"\"\n    conn_error = None\n    for _ in range(int(timeout / check_interval)):\n        try:\n            requests.get(url)\n        except requests.ConnectionError as exc:\n            time.sleep(check_interval)\n            conn_error = str(exc)\n        else:",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "free_port",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def free_port() -> int:\n    \"\"\"Returns a free port for the test server to bind.\"\"\"\n    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:\n        s.bind((\"\", 0))\n        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        return s.getsockname()[1]\ndef run_server(port: int):\n    with mock.patch.dict(\n        os.environ,\n        {",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "run_server",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def run_server(port: int):\n    with mock.patch.dict(\n        os.environ,\n        {\n            \"AZURE_STORAGE_ACCOUNT\": \"test-storage-account\",\n            \"AZURE_STORAGE_CONTAINER\": \"test-storage-container\",\n            \"AZURE_STORAGE_RESOURCE_GROUP\": \"test-storage-rg\",\n            \"AZURE_SUBSCRIPTION_ID\": \"test-storage-subid\",\n            \"ENABLE_LANGUAGE_PICKER\": \"false\",\n            \"USE_SPEECH_INPUT_BROWSER\": \"false\",",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "live_server_url",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def live_server_url(mock_env, mock_acs_search, free_port: int) -> Generator[str, None, None]:\n    proc = Process(target=run_server, args=(free_port,), daemon=True)\n    proc.start()\n    url = f\"http://localhost:{free_port}/\"\n    wait_for_server_ready(url, timeout=10.0, check_interval=0.5)\n    yield url\n    proc.kill()\n@pytest.fixture(params=[(480, 800), (600, 1024), (768, 1024), (992, 1024), (1024, 768)])\ndef sized_page(page: Page, request):\n    size = request.param",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "sized_page",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def sized_page(page: Page, request):\n    size = request.param\n    page.set_viewport_size({\"width\": size[0], \"height\": size[1]})\n    yield page\ndef test_home(page: Page, live_server_url: str):\n    page.goto(live_server_url)\n    expect(page).to_have_title(\"Azure OpenAI + AI Search\")\ndef test_chat(sized_page: Page, live_server_url: str):\n    page = sized_page\n    # Set up a mock route to the /chat endpoint with streaming results",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_home",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_home(page: Page, live_server_url: str):\n    page.goto(live_server_url)\n    expect(page).to_have_title(\"Azure OpenAI + AI Search\")\ndef test_chat(sized_page: Page, live_server_url: str):\n    page = sized_page\n    # Set up a mock route to the /chat endpoint with streaming results\n    def handle(route: Route):\n        try:\n            post_data = route.request.post_data_json\n            # Assert that session_state is specified (None initially)",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat(sized_page: Page, live_server_url: str):\n    page = sized_page\n    # Set up a mock route to the /chat endpoint with streaming results\n    def handle(route: Route):\n        try:\n            post_data = route.request.post_data_json\n            # Assert that session_state is specified (None initially)\n            if \"session_state\" in post_data:\n                assert post_data[\"session_state\"] is None\n            overrides = post_data[\"context\"][\"overrides\"]",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat_customization",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat_customization(page: Page, live_server_url: str):\n    # Set up a mock route to the /chat endpoint\n    def handle(route: Route):\n        try:\n            post_data = route.request.post_data_json\n            if post_data and \"context\" in post_data and \"overrides\" in post_data[\"context\"]:\n                overrides = post_data[\"context\"][\"overrides\"]\n                assert overrides[\"temperature\"] == 0.5\n                assert overrides[\"seed\"] == 123\n                assert overrides[\"minimum_search_score\"] == 0.5",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat_customization_multimodal",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat_customization_multimodal(page: Page, live_server_url: str):\n    # Set up a mock route to the /chat endpoint\n    def handle_chat(route: Route):\n        try:\n            post_data = route.request.post_data_json\n            if post_data and \"context\" in post_data and \"overrides\" in post_data[\"context\"]:\n                overrides = post_data[\"context\"][\"overrides\"]\n                # After our UI changes we expect:\n                # - send_text_sources to be False (we unchecked Texts)\n                # - send_image_sources to be True (we left Images checked)",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat_nonstreaming",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat_nonstreaming(page: Page, live_server_url: str):\n    # Set up a mock route to the /chat_stream endpoint\n    def handle(route: Route):\n        # Read the JSON from our snapshot results and return as the response\n        f = open(\"tests/snapshots/test_app/test_chat_text/client0/result.json\")\n        json = f.read()\n        f.close()\n        route.fulfill(body=json, status=200)\n    page.route(\"*/**/chat\", handle)\n    # Check initial page state",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat_followup_streaming",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat_followup_streaming(page: Page, live_server_url: str):\n    # Set up a mock route to the /chat_stream endpoint\n    def handle(route: Route):\n        try:\n            post_data = route.request.post_data_json\n            if post_data and \"context\" in post_data and \"overrides\" in post_data[\"context\"]:\n                overrides = post_data[\"context\"][\"overrides\"]\n                assert overrides[\"suggest_followup_questions\"] is True\n        except Exception as e:\n            print(f\"Error in test_chat_followup_streaming handler: {e}\")",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_chat_followup_nonstreaming",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_chat_followup_nonstreaming(page: Page, live_server_url: str):\n    # Set up a mock route to the /chat_stream endpoint\n    def handle(route: Route):\n        # Read the JSON from our snapshot results and return as the response\n        f = open(\"tests/snapshots/test_app/test_chat_followup/client0/result.json\")\n        json = f.read()\n        f.close()\n        route.fulfill(body=json, status=200)\n    page.route(\"*/**/chat\", handle)\n    # Check initial page state",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_ask",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_ask(sized_page: Page, live_server_url: str):\n    page = sized_page\n    # Set up a mock route to the /ask endpoint\n    def handle(route: Route):\n        # Assert that session_state is specified in the request (None for now)\n        try:\n            post_data = route.request.post_data_json\n            if post_data and \"session_state\" in post_data:\n                session_state = post_data[\"session_state\"]\n                assert session_state is None",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_upload_hidden",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_upload_hidden(page: Page, live_server_url: str):\n    def handle_auth_setup(route: Route):\n        with open(\"tests/snapshots/test_authenticationhelper/test_auth_setup/result.json\") as f:\n            auth_setup = json.load(f)\n            route.fulfill(body=json.dumps(auth_setup), status=200)\n    page.route(\"*/**/auth_setup\", handle_auth_setup)\n    def handle_config(route: Route):\n        route.fulfill(\n            body=json.dumps(\n                {",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "test_upload_disabled",
        "kind": 2,
        "importPath": "tests.e2e",
        "description": "tests.e2e",
        "peekOfCode": "def test_upload_disabled(page: Page, live_server_url: str):\n    def handle_auth_setup(route: Route):\n        with open(\"tests/snapshots/test_authenticationhelper/test_auth_setup/result.json\") as f:\n            auth_setup = json.load(f)\n            route.fulfill(body=json.dumps(auth_setup), status=200)\n    page.route(\"*/**/auth_setup\", handle_auth_setup)\n    def handle_config(route: Route):\n        route.fulfill(\n            body=json.dumps(\n                {",
        "detail": "tests.e2e",
        "documentation": {}
    },
    {
        "label": "MockAzureCredential",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAzureCredential(AsyncTokenCredential):\n    async def get_token(self, *scopes, **kwargs):  # accept claims, enable_cae, etc.\n        # Return a simple mock token structure with required attributes\n        return MockToken(\"mock-token\", 9999999999, \"mock-token\")\nclass MockAzureCredentialExpired(AsyncTokenCredential):\n    def __init__(self):\n        self.access_number = 0\n    async def get_token(self, *scopes, **kwargs):\n        self.access_number += 1\n        if self.access_number == 1:",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAzureCredentialExpired",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAzureCredentialExpired(AsyncTokenCredential):\n    def __init__(self):\n        self.access_number = 0\n    async def get_token(self, *scopes, **kwargs):\n        self.access_number += 1\n        if self.access_number == 1:\n            return MockToken(\"\", 0, \"\")\n        else:\n            return MockToken(\"\", 9999999999, \"\")\nclass MockBlobClient:",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockBlobClient",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockBlobClient:\n    async def download_blob(self):\n        return MockBlob()\nclass MockBlob:\n    def __init__(self):\n        self.properties = BlobProperties(\n            name=\"Financial Market Analysis Report 2023-7.png\", content_settings={\"content_type\": \"image/png\"}\n        )\n    async def readall(self):\n        return TEST_PNG_BYTES",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockBlob",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockBlob:\n    def __init__(self):\n        self.properties = BlobProperties(\n            name=\"Financial Market Analysis Report 2023-7.png\", content_settings={\"content_type\": \"image/png\"}\n        )\n    async def readall(self):\n        return TEST_PNG_BYTES\n    async def readinto(self, buffer: BytesIO):\n        buffer.write(b\"test\")\nclass MockAiohttpClientResponse404(aiohttp.ClientResponse):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAiohttpClientResponse404",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAiohttpClientResponse404(aiohttp.ClientResponse):\n    def __init__(self, url, body_bytes, headers=None):\n        self._body = body_bytes\n        self._headers = headers\n        self._cache = {}\n        self.status = 404\n        self.reason = \"Not Found\"\n        self._url = url\nclass MockAiohttpClientResponse(aiohttp.ClientResponse):\n    def __init__(self, url, body_bytes, headers=None):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAiohttpClientResponse",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAiohttpClientResponse(aiohttp.ClientResponse):\n    def __init__(self, url, body_bytes, headers=None):\n        self._body = body_bytes\n        self._headers = headers\n        self._cache = {}\n        self.status = 200\n        self.reason = \"OK\"\n        self._url = url\nclass MockTransport(AsyncHttpTransport):\n    async def send(self, request: HttpRequest, **kwargs) -> AioHttpTransportResponse:",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockTransport",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockTransport(AsyncHttpTransport):\n    async def send(self, request: HttpRequest, **kwargs) -> AioHttpTransportResponse:\n        return AioHttpTransportResponse(\n            request,\n            MockAiohttpClientResponse(\n                request.url,\n                TEST_PNG_BYTES,\n                {\n                    \"Content-Type\": \"application/octet-stream\",\n                    \"Content-Range\": \"bytes 0-27/28\",",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAsyncPageIterator",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAsyncPageIterator:\n    def __init__(self, data):\n        self.data = data\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if not self.data:\n            raise StopAsyncIteration\n        return self.data.pop(0)  # This should be a list of dictionaries.\nclass MockCaption:",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockCaption",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockCaption:\n    def __init__(self, text, highlights=None, additional_properties=None):\n        self.text = text\n        self.highlights = highlights or []\n        self.additional_properties = additional_properties or {}\nclass MockAsyncSearchResultsIterator:\n    def __init__(self, search_text, vector_queries: Optional[list[VectorQuery]]):\n        if search_text == \"westbrae nursery logo\" and (\n            vector_queries and any([vector.fields == \"images/embedding\" for vector in vector_queries])\n        ):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAsyncSearchResultsIterator",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAsyncSearchResultsIterator:\n    def __init__(self, search_text, vector_queries: Optional[list[VectorQuery]]):\n        if search_text == \"westbrae nursery logo\" and (\n            vector_queries and any([vector.fields == \"images/embedding\" for vector in vector_queries])\n        ):\n            self.data = [\n                [\n                    {\n                        \"id\": \"file-westbrae_jun28_pdf-77657374627261655F6A756E32382E7064667B276F696473273A205B2766653437353262612D623565652D343531632D623065312D393332316664663365353962275D7D-page-0\",\n                        \"content\": '<figure><figcaption>1.1 <br>The image displays the Gmail logo. It consists of a stylized letter \"M\" with four colors: red, blue, green, and yellow. To the right of the \"M\" is the word \"Gmail\" written in gray text. The design is modern and clean. The colors used are characteristic of Google\\'s branding.</figcaption></figure>\\n\\n\\nPamela Fox <pamela.fox@gmail.com>\\n\\nReceipt / Tax invoice (#2-108442)\\n\\nWestbrae Nursery <no-reply@email.lightspeedhq.com>\\nReply-To: jeff@westbrae-nursery.com\\nTo: pamela.fox@gmail.com\\n\\nSat, Jun 28, 2025 at 1:21 PM\\n\\n\\n<figure><figcaption>1.2 <br>The image shows the logo of Westbrae Nursery. The logo features three daffodil flowers on the left side. The text \"Westbrae\" is positioned to the right of the flowers. Below \"Westbrae\" is the word \"Nursery.\" The design is simple and rendered in black and white.</figcaption></figure>\\n\\n\\nAn Employee-Owned Co-op\\n1272 Gilman St, Berkeley, CA 94706\\n510-526-5517\\n\\nMain Outlet\\n\\nReceipt / Tax Invoice #2-108442 28 Jun 2025 1:21pm\\n\\n\\n<figure><table><tr><td>1 Gopher Baskets</td><td>@ $7.',",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockResponse",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockResponse:\n    def __init__(self, status, text=None, headers=None):\n        self._text = text or \"\"\n        self.status = status\n        self.headers = headers or {}\n    async def __aexit__(self, exc_type, exc, tb):\n        pass\n    async def __aenter__(self):\n        return self\n    async def text(self):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockEmbeddingsClient",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockEmbeddingsClient:\n    def __init__(self, create_embedding_response: openai.types.CreateEmbeddingResponse):\n        self.create_embedding_response = create_embedding_response\n    async def create(self, *args, **kwargs) -> openai.types.CreateEmbeddingResponse:\n        return self.create_embedding_response\nclass MockClient:\n    def __init__(self, embeddings_client):\n        self.embeddings = embeddings_client\ndef mock_vision_response():\n    return MockResponse(",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockClient",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockClient:\n    def __init__(self, embeddings_client):\n        self.embeddings = embeddings_client\ndef mock_vision_response():\n    return MockResponse(\n        status=200,\n        text=json.dumps(\n            {\n                \"vector\": [\n                    0.011925711,",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAudio",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAudio:\n    def __init__(self, audio_data):\n        self.audio_data = audio_data\n        self.reason = ResultReason.SynthesizingAudioCompleted\n    def read(self):\n        return self.audio_data\nclass MockSpeechSynthesisCancellationDetails:\n    def __init__(self):\n        self.reason = \"Canceled\"\n        self.error_details = \"The synthesis was canceled.\"",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockSpeechSynthesisCancellationDetails",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockSpeechSynthesisCancellationDetails:\n    def __init__(self):\n        self.reason = \"Canceled\"\n        self.error_details = \"The synthesis was canceled.\"\nclass MockAudioCancelled:\n    def __init__(self, audio_data):\n        self.audio_data = audio_data\n        self.reason = ResultReason.Canceled\n        self.cancellation_details = MockSpeechSynthesisCancellationDetails()\n    def read(self):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAudioCancelled",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAudioCancelled:\n    def __init__(self, audio_data):\n        self.audio_data = audio_data\n        self.reason = ResultReason.Canceled\n        self.cancellation_details = MockSpeechSynthesisCancellationDetails()\n    def read(self):\n        return self.audio_data\nclass MockAudioFailure:\n    def __init__(self, audio_data):\n        self.audio_data = audio_data",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockAudioFailure",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockAudioFailure:\n    def __init__(self, audio_data):\n        self.audio_data = audio_data\n        self.reason = ResultReason.NoMatch\n    def read(self):\n        return self.audio_data\nclass MockSynthesisResult:\n    def __init__(self, result):\n        self.__result = result\n    def get(self):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockSynthesisResult",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockSynthesisResult:\n    def __init__(self, result):\n        self.__result = result\n    def get(self):\n        return self.__result\n# Mock DirectoryClient used in blobmanager.py:AdlsBlobManager\nclass MockDirectoryClient:\n    async def get_directory_properties(self):\n        # Return dummy properties to indicate directory exists\n        return {\"name\": \"test-directory\"}",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockDirectoryClient",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockDirectoryClient:\n    async def get_directory_properties(self):\n        # Return dummy properties to indicate directory exists\n        return {\"name\": \"test-directory\"}\n    async def get_access_control(self):\n        # Return a dictionary with the owner matching the auth_client's user_oid\n        return {\"owner\": \"OID_X\"}  # This should match the user_oid in auth_client\n    def get_file_client(self, filename):\n        # Return a file client for the given filename\n        return MockFileClient(filename)",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockFileClient",
        "kind": 6,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "class MockFileClient:\n    def __init__(self, path_name):\n        self.path_name = path_name\n    async def download_file(self):\n        return MockBlob()\ndef mock_speak_text_success(self, text):\n    return MockSynthesisResult(MockAudio(\"mock_audio_data\"))\ndef mock_speak_text_cancelled(self, text):\n    return MockSynthesisResult(MockAudioCancelled(\"mock_audio_data\"))\ndef mock_speak_text_failed(self, text):",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_vision_response",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_vision_response():\n    return MockResponse(\n        status=200,\n        text=json.dumps(\n            {\n                \"vector\": [\n                    0.011925711,\n                    0.023533698,\n                    0.010133852,\n                    0.0063544377,",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_retrieval_response",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_retrieval_response():\n    return KnowledgeAgentRetrievalResponse(\n        response=[\n            KnowledgeAgentMessage(\n                role=\"assistant\",\n                content=[\n                    KnowledgeAgentMessageTextContent(\n                        text=r'[{\"ref_id\":0,\"title\":\"Benefit_Options-2.pdf\",\"content\":\"There is a whistleblower policy.\"}]'\n                    )\n                ],",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_retrieval_response_with_sorting",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_retrieval_response_with_sorting():\n    \"\"\"Mock response with multiple references for testing sorting\"\"\"\n    return KnowledgeAgentRetrievalResponse(\n        response=[\n            KnowledgeAgentMessage(\n                role=\"assistant\",\n                content=[KnowledgeAgentMessageTextContent(text=\"Test response\")],\n            )\n        ],\n        activity=[",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_retrieval_response_with_top_limit",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_retrieval_response_with_top_limit():\n    \"\"\"Mock response with many references to test top limit during document building\"\"\"\n    references = []\n    for i in range(15):  # More than any reasonable top limit\n        references.append(\n            KnowledgeAgentSearchIndexReference(\n                id=str(i),\n                activity_source=1,\n                doc_key=f\"doc{i}\",\n                source_data={\"id\": f\"doc{i}\", \"content\": f\"Content {i}\", \"sourcepage\": f\"page{i}.pdf\"},",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_speak_text_success",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_speak_text_success(self, text):\n    return MockSynthesisResult(MockAudio(\"mock_audio_data\"))\ndef mock_speak_text_cancelled(self, text):\n    return MockSynthesisResult(MockAudioCancelled(\"mock_audio_data\"))\ndef mock_speak_text_failed(self, text):\n    return MockSynthesisResult(MockAudioFailure(\"mock_audio_data\"))",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_speak_text_cancelled",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_speak_text_cancelled(self, text):\n    return MockSynthesisResult(MockAudioCancelled(\"mock_audio_data\"))\ndef mock_speak_text_failed(self, text):\n    return MockSynthesisResult(MockAudioFailure(\"mock_audio_data\"))",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_speak_text_failed",
        "kind": 2,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "def mock_speak_text_failed(self, text):\n    return MockSynthesisResult(MockAudioFailure(\"mock_audio_data\"))",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MOCK_EMBEDDING_DIMENSIONS",
        "kind": 5,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "MOCK_EMBEDDING_DIMENSIONS = 1536\nMOCK_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\nTEST_PNG_BYTES = (\n    b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\"\n    b\"\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\rIDATx\\xdac\\xfc\\xcf\\xf0\\xbf\\x1e\\x00\\x06\\x83\\x02\\x7f\\x94\\xad\"\n    b\"\\xd0\\xeb\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\"\n)\nMockToken = namedtuple(\"MockToken\", [\"token\", \"expires_on\", \"value\"])\nclass MockAzureCredential(AsyncTokenCredential):\n    async def get_token(self, *scopes, **kwargs):  # accept claims, enable_cae, etc.",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MOCK_EMBEDDING_MODEL_NAME",
        "kind": 5,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "MOCK_EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\nTEST_PNG_BYTES = (\n    b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\"\n    b\"\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\rIDATx\\xdac\\xfc\\xcf\\xf0\\xbf\\x1e\\x00\\x06\\x83\\x02\\x7f\\x94\\xad\"\n    b\"\\xd0\\xeb\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\"\n)\nMockToken = namedtuple(\"MockToken\", [\"token\", \"expires_on\", \"value\"])\nclass MockAzureCredential(AsyncTokenCredential):\n    async def get_token(self, *scopes, **kwargs):  # accept claims, enable_cae, etc.\n        # Return a simple mock token structure with required attributes",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "TEST_PNG_BYTES",
        "kind": 5,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "TEST_PNG_BYTES = (\n    b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x01\\x08\\x06\\x00\\x00\"\n    b\"\\x00\\x1f\\x15\\xc4\\x89\\x00\\x00\\x00\\rIDATx\\xdac\\xfc\\xcf\\xf0\\xbf\\x1e\\x00\\x06\\x83\\x02\\x7f\\x94\\xad\"\n    b\"\\xd0\\xeb\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82\"\n)\nMockToken = namedtuple(\"MockToken\", [\"token\", \"expires_on\", \"value\"])\nclass MockAzureCredential(AsyncTokenCredential):\n    async def get_token(self, *scopes, **kwargs):  # accept claims, enable_cae, etc.\n        # Return a simple mock token structure with required attributes\n        return MockToken(\"mock-token\", 9999999999, \"mock-token\")",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "MockToken",
        "kind": 5,
        "importPath": "tests.mocks",
        "description": "tests.mocks",
        "peekOfCode": "MockToken = namedtuple(\"MockToken\", [\"token\", \"expires_on\", \"value\"])\nclass MockAzureCredential(AsyncTokenCredential):\n    async def get_token(self, *scopes, **kwargs):  # accept claims, enable_cae, etc.\n        # Return a simple mock token structure with required attributes\n        return MockToken(\"mock-token\", 9999999999, \"mock-token\")\nclass MockAzureCredentialExpired(AsyncTokenCredential):\n    def __init__(self):\n        self.access_number = 0\n    async def get_token(self, *scopes, **kwargs):\n        self.access_number += 1",
        "detail": "tests.mocks",
        "documentation": {}
    },
    {
        "label": "mock_open",
        "kind": 2,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "def mock_open(monkeypatch):\n    class MockOpenedFile:\n        def __enter__(self, *args, **kwargs):\n            pass\n        def __exit__(self, *args, **kwargs):\n            return self\n    def mock_open(*args, **kwargs):\n        return MockOpenedFile()\n    monkeypatch.setattr(builtins, \"open\", mock_open)\n@pytest.fixture",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "mock_adlsgen2setup",
        "kind": 2,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "def mock_adlsgen2setup(monkeypatch):\n    def mock_adlsgen2setup_create_service_client(self, *args, **kwargs):\n        try:\n            return self.service_client\n        except AttributeError:\n            self.service_client = azure.storage.filedatalake.aio.DataLakeServiceClient()\n            return self.service_client\n    monkeypatch.setattr(AdlsGen2Setup, \"create_service_client\", mock_adlsgen2setup_create_service_client)\n@pytest.fixture\ndef mock_get_group_success(monkeypatch):",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "mock_get_group_success",
        "kind": 2,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "def mock_get_group_success(monkeypatch):\n    def mock_get(self, url, *args, **kwargs):\n        group_id = None\n        if \"GROUP_A\" in url:\n            group_id = \"GROUP_A_ID\"\n        elif \"GROUP_B\" in url:\n            group_id = \"GROUP_B_ID\"\n        elif \"GROUP_C\" in url:\n            group_id = \"GROUP_C_ID\"\n        else:",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "mock_get_group_missing",
        "kind": 2,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "def mock_get_group_missing(monkeypatch):\n    def mock_get(*args, **kwargs):\n        return MockResponse(\n            text=json.dumps({\"value\": []}),\n            status=200,\n        )\n    monkeypatch.setattr(aiohttp.ClientSession, \"get\", mock_get)\n@pytest.fixture\ndef mock_put_group(monkeypatch):\n    def mock_post(*args, **kwargs):",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "mock_put_group",
        "kind": 2,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "def mock_put_group(monkeypatch):\n    def mock_post(*args, **kwargs):\n        obj = kwargs.get(\"json\")\n        assert obj\n        assert \"displayName\" in obj\n        assert obj.get(\"groupTypes\") == [\"Unified\"]\n        assert obj.get(\"securityEnabled\") is False\n        return MockResponse(\n            text=json.dumps({\"id\": obj[\"displayName\"] + \"_ID_CREATED\"}),\n            status=201,",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "valid_data_access_control_format",
        "kind": 5,
        "importPath": "tests.test_adlsgen2setup",
        "description": "tests.test_adlsgen2setup",
        "peekOfCode": "valid_data_access_control_format = {\n    \"files\": {\n        \"a.txt\": {\"directory\": \"d1\"},\n        \"b.txt\": {\"directory\": \"d2\"},\n        \"c.txt\": {\"directory\": \"d1\"},\n    },\n    \"directories\": {\n        \"d1\": {\"groups\": [\"GROUP_A\"]},\n        \"d2\": {\"groups\": [\"GROUP_A\", \"GROUP_B\"]},\n        \"/\": {\"groups\": [\"GROUP_C\"]},",
        "detail": "tests.test_adlsgen2setup",
        "documentation": {}
    },
    {
        "label": "fake_response",
        "kind": 2,
        "importPath": "tests.test_app",
        "description": "tests.test_app",
        "peekOfCode": "def fake_response(http_code):\n    return Response(http_code, request=Request(method=\"get\", url=\"https://foo.bar/\"))\n# See https://learn.microsoft.com/azure/ai-services/openai/concepts/content-filter\nfiltered_response = BadRequestError(\n    message=\"The response was filtered\",\n    body={\n        \"message\": \"The response was filtered\",\n        \"type\": None,\n        \"param\": \"prompt\",\n        \"code\": \"content_filter\",",
        "detail": "tests.test_app",
        "documentation": {}
    },
    {
        "label": "messages_contains_text",
        "kind": 2,
        "importPath": "tests.test_app",
        "description": "tests.test_app",
        "peekOfCode": "def messages_contains_text(messages, text):\n    for message in messages:\n        if text in message[\"content\"]:\n            return True\n    return False\n@pytest.mark.asyncio\nasync def test_missing_env_vars():\n    with mock.patch.dict(os.environ, clear=True):\n        quart_app = app.create_app()\n        with pytest.raises(quart.testing.app.LifespanError, match=\"Error during startup 'AZURE_STORAGE_ACCOUNT'\"):",
        "detail": "tests.test_app",
        "documentation": {}
    },
    {
        "label": "filtered_response",
        "kind": 5,
        "importPath": "tests.test_app",
        "description": "tests.test_app",
        "peekOfCode": "filtered_response = BadRequestError(\n    message=\"The response was filtered\",\n    body={\n        \"message\": \"The response was filtered\",\n        \"type\": None,\n        \"param\": \"prompt\",\n        \"code\": \"content_filter\",\n        \"status\": 400,\n    },\n    response=Response(",
        "detail": "tests.test_app",
        "documentation": {}
    },
    {
        "label": "contextlength_response",
        "kind": 5,
        "importPath": "tests.test_app",
        "description": "tests.test_app",
        "peekOfCode": "contextlength_response = BadRequestError(\n    message=\"This model's maximum context length is 4096 tokens. However, your messages resulted in 5069 tokens. Please reduce the length of the messages.\",\n    body={\n        \"message\": \"This model's maximum context length is 4096 tokens. However, your messages resulted in 5069 tokens. Please reduce the length of the messages.\",\n        \"code\": \"context_length_exceeded\",\n        \"status\": 400,\n    },\n    response=Response(400, request=Request(method=\"get\", url=\"https://foo.bar/\"), json={\"error\": {\"code\": \"429\"}}),\n)\ndef messages_contains_text(messages, text):",
        "detail": "tests.test_app",
        "documentation": {}
    },
    {
        "label": "minimal_env",
        "kind": 2,
        "importPath": "tests.test_app_config",
        "description": "tests.test_app_config",
        "peekOfCode": "def minimal_env(monkeypatch):\n    with mock.patch.dict(os.environ, clear=True):\n        monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"test-storage-account\")\n        monkeypatch.setenv(\"AZURE_STORAGE_CONTAINER\", \"test-storage-container\")\n        monkeypatch.setenv(\"AZURE_SEARCH_INDEX\", \"test-search-index\")\n        monkeypatch.setenv(\"AZURE_SEARCH_SERVICE\", \"test-search-service\")\n        monkeypatch.setenv(\"AZURE_OPENAI_SERVICE\", \"test-openai-service\")\n        monkeypatch.setenv(\"AZURE_OPENAI_CHATGPT_MODEL\", \"gpt-4.1-mini\")\n        monkeypatch.setenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"test-chat-deployment\")\n        monkeypatch.setenv(\"AZURE_OPENAI_EMB_MODEL_NAME\", \"text-embedding-3-large\")",
        "detail": "tests.test_app_config",
        "documentation": {}
    },
    {
        "label": "test_app_enables_azure_monitor_when_connection_string_set",
        "kind": 2,
        "importPath": "tests.test_app_config",
        "description": "tests.test_app_config",
        "peekOfCode": "def test_app_enables_azure_monitor_when_connection_string_set(monkeypatch):\n    mock_connection_string = \"InstrumentationKey=12345678-1234-1234-1234-123456789012\"\n    monkeypatch.setenv(\"APPLICATIONINSIGHTS_CONNECTION_STRING\", mock_connection_string)\n    app.create_app()",
        "detail": "tests.test_app_config",
        "documentation": {}
    },
    {
        "label": "create_authentication_helper",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def create_authentication_helper(\n    enforce_access_control: bool = False,\n    enable_unauthenticated_access: bool = False,\n):\n    return AuthenticationHelper(\n        search_index=MockSearchIndex,\n        use_authentication=True,\n        server_app_id=\"SERVER_APP\",\n        server_app_secret=\"SERVER_SECRET\",\n        client_app_id=\"CLIENT_APP\",",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "create_search_client",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def create_search_client():\n    return SearchClient(endpoint=\"\", index_name=\"\", credential=AzureKeyCredential(\"\"))\ndef create_mock_jwt(kid=\"mock_kid\", oid=\"OID_X\"):\n    # Create a payload with necessary claims\n    payload = {\n        \"iss\": \"https://login.microsoftonline.com/TENANT_ID/v2.0\",\n        \"sub\": \"AaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaA\",\n        \"aud\": \"SERVER_APP\",\n        \"exp\": int((datetime.now(timezone.utc) + timedelta(hours=1)).timestamp()),\n        \"iat\": int(datetime.now(timezone.utc).timestamp()),",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "create_mock_jwt",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def create_mock_jwt(kid=\"mock_kid\", oid=\"OID_X\"):\n    # Create a payload with necessary claims\n    payload = {\n        \"iss\": \"https://login.microsoftonline.com/TENANT_ID/v2.0\",\n        \"sub\": \"AaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaA\",\n        \"aud\": \"SERVER_APP\",\n        \"exp\": int((datetime.now(timezone.utc) + timedelta(hours=1)).timestamp()),\n        \"iat\": int(datetime.now(timezone.utc).timestamp()),\n        \"nbf\": int(datetime.now(timezone.utc).timestamp()),\n        \"name\": \"John Doe\",",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "test_auth_setup",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def test_auth_setup(mock_confidential_client_success, mock_validate_token_success, snapshot):\n    helper = create_authentication_helper()\n    result = helper.get_auth_setup_for_client()\n    snapshot.assert_match(json.dumps(result, indent=4), \"result.json\")\ndef test_auth_setup_required_access_control(mock_confidential_client_success, mock_validate_token_success, snapshot):\n    helper = create_authentication_helper(enforce_access_control=True)\n    result = helper.get_auth_setup_for_client()\n    snapshot.assert_match(json.dumps(result, indent=4), \"result.json\")\ndef test_auth_setup_required_access_control_and_unauthenticated_access(\n    mock_confidential_client_success, mock_validate_token_success, snapshot",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "test_auth_setup_required_access_control",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def test_auth_setup_required_access_control(mock_confidential_client_success, mock_validate_token_success, snapshot):\n    helper = create_authentication_helper(enforce_access_control=True)\n    result = helper.get_auth_setup_for_client()\n    snapshot.assert_match(json.dumps(result, indent=4), \"result.json\")\ndef test_auth_setup_required_access_control_and_unauthenticated_access(\n    mock_confidential_client_success, mock_validate_token_success, snapshot\n):\n    helper = create_authentication_helper(enforce_access_control=True, enable_unauthenticated_access=True)\n    result = helper.get_auth_setup_for_client()\n    snapshot.assert_match(json.dumps(result, indent=4), \"result.json\")",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "test_auth_setup_required_access_control_and_unauthenticated_access",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def test_auth_setup_required_access_control_and_unauthenticated_access(\n    mock_confidential_client_success, mock_validate_token_success, snapshot\n):\n    helper = create_authentication_helper(enforce_access_control=True, enable_unauthenticated_access=True)\n    result = helper.get_auth_setup_for_client()\n    snapshot.assert_match(json.dumps(result, indent=4), \"result.json\")\ndef test_get_auth_token(mock_confidential_client_success, mock_validate_token_success):\n    with pytest.raises(AuthError) as exc_info:\n        AuthenticationHelper.get_token_auth_header({})\n    assert exc_info.value.status_code == 401",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "test_get_auth_token",
        "kind": 2,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "def test_get_auth_token(mock_confidential_client_success, mock_validate_token_success):\n    with pytest.raises(AuthError) as exc_info:\n        AuthenticationHelper.get_token_auth_header({})\n    assert exc_info.value.status_code == 401\n    with pytest.raises(AuthError) as exc_info:\n        AuthenticationHelper.get_token_auth_header({\"Authorization\": \". .\"})\n    assert exc_info.value.status_code == 401\n    with pytest.raises(AuthError) as exc_info:\n        AuthenticationHelper.get_token_auth_header({\"Authorization\": \"invalid\"})\n    assert exc_info.value.status_code == 401",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "MockSearchIndex",
        "kind": 5,
        "importPath": "tests.test_authenticationhelper",
        "description": "tests.test_authenticationhelper",
        "peekOfCode": "MockSearchIndex = SearchIndex(\n    name=\"test\",\n    fields=[\n        SearchField(name=\"oids\", type=\"Collection(Edm.String)\"),\n        SearchField(name=\"groups\", type=\"Collection(Edm.String)\"),\n    ],\n)\ndef create_authentication_helper(\n    enforce_access_control: bool = False,\n    enable_unauthenticated_access: bool = False,",
        "detail": "tests.test_authenticationhelper",
        "documentation": {}
    },
    {
        "label": "FakeRequestBuilder",
        "kind": 6,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "class FakeRequestBuilder:\n    def __init__(self, result):\n        self._result = result\n    async def get(self):\n        return self._result\nclass FakeOAuthGrant:\n    def __init__(self):\n        self.responses: list[SimpleNamespace] = []\n        self.raise_on_post: Optional[APIError] = None\n        self.posted = []",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "FakeOAuthGrant",
        "kind": 6,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "class FakeOAuthGrant:\n    def __init__(self):\n        self.responses: list[SimpleNamespace] = []\n        self.raise_on_post: Optional[APIError] = None\n        self.posted = []\n        self.post_attempts = 0\n    def configure(self, responses, raise_on_post=None):\n        self.responses = list(responses)\n        self.raise_on_post = raise_on_post\n        self.posted = []",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "graph_client",
        "kind": 2,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "def graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"\n    client = GraphServiceClient(credentials=MockAzureCredential(), scopes=[\"https://graph.microsoft.com/.default\"])\n    calls = {\n        \"applications.post\": [],\n        \"applications.patch\": [],\n        \"applications.add_password.post\": [],\n        \"service_principals.post\": [],",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "test_client_app_validation_errors",
        "kind": 2,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "def test_client_app_validation_errors():\n    # Server app without api\n    server_app = server_app_initial(1)\n    server_app.api = None\n    with pytest.raises(ValueError):\n        client_app(\"server_app_id\", server_app, 2)\n    # Server app with empty scopes\n    # attach empty api\n    server_app_permission = server_app_permission_setup(\"server_app\")\n    server_app_permission.api.oauth2_permission_scopes = []",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "test_client_app_success",
        "kind": 2,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "def test_client_app_success():\n    server_app_permission = server_app_permission_setup(\"server_app\")\n    c_app = client_app(\"server_app\", server_app_permission, 123)\n    assert c_app.web is not None\n    assert c_app.spa is not None\n    assert c_app.required_resource_access is not None\n    assert len(c_app.required_resource_access) >= 1\ndef test_server_app_permission_setup():\n    # simulate after creation we know app id\n    app_with_permissions = server_app_permission_setup(\"server_app_id\")",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "test_server_app_permission_setup",
        "kind": 2,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "def test_server_app_permission_setup():\n    # simulate after creation we know app id\n    app_with_permissions = server_app_permission_setup(\"server_app_id\")\n    assert app_with_permissions.identifier_uris == [\"api://server_app_id\"]\n    assert app_with_permissions.required_resource_access is not None\n    assert len(app_with_permissions.required_resource_access) == 2\n@pytest.mark.asyncio\nasync def test_grant_application_admin_consent_creates_grants(graph_client):\n    graph = graph_client\n    oauth_grants = graph._test_oauth_grants",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "MOCK_OBJECT_ID",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "MOCK_OBJECT_ID = \"OBJ123\"\nMOCK_APP_ID = \"APP123\"\nMOCK_SECRET = \"SECRET_VALUE\"\nEXISTING_MOCK_OBJECT_ID = \"OBJ999\"\nMOCK_CLIENT_APP_ID = \"client-app\"\nMOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "MOCK_APP_ID",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "MOCK_APP_ID = \"APP123\"\nMOCK_SECRET = \"SECRET_VALUE\"\nEXISTING_MOCK_OBJECT_ID = \"OBJ999\"\nMOCK_CLIENT_APP_ID = \"client-app\"\nMOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "MOCK_SECRET",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "MOCK_SECRET = \"SECRET_VALUE\"\nEXISTING_MOCK_OBJECT_ID = \"OBJ999\"\nMOCK_CLIENT_APP_ID = \"client-app\"\nMOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"\n    client = GraphServiceClient(credentials=MockAzureCredential(), scopes=[\"https://graph.microsoft.com/.default\"])",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "EXISTING_MOCK_OBJECT_ID",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "EXISTING_MOCK_OBJECT_ID = \"OBJ999\"\nMOCK_CLIENT_APP_ID = \"client-app\"\nMOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"\n    client = GraphServiceClient(credentials=MockAzureCredential(), scopes=[\"https://graph.microsoft.com/.default\"])\n    calls = {",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "MOCK_CLIENT_APP_ID",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "MOCK_CLIENT_APP_ID = \"client-app\"\nMOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"\n    client = GraphServiceClient(credentials=MockAzureCredential(), scopes=[\"https://graph.microsoft.com/.default\"])\n    calls = {\n        \"applications.post\": [],",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "MOCK_SERVER_APP_ID",
        "kind": 5,
        "importPath": "tests.test_auth_init",
        "description": "tests.test_auth_init",
        "peekOfCode": "MOCK_SERVER_APP_ID = \"server-app\"\n@pytest.fixture\ndef graph_client(monkeypatch):\n    \"\"\"GraphServiceClient whose network layer is intercepted to avoid real HTTP calls.\n    We exercise real request builders while intercepting the adapter's send_async.\n    \"\"\"\n    client = GraphServiceClient(credentials=MockAzureCredential(), scopes=[\"https://graph.microsoft.com/.default\"])\n    calls = {\n        \"applications.post\": [],\n        \"applications.patch\": [],",
        "detail": "tests.test_auth_init",
        "documentation": {}
    },
    {
        "label": "blob_manager",
        "kind": 2,
        "importPath": "tests.test_blob_manager",
        "description": "tests.test_blob_manager",
        "peekOfCode": "def blob_manager():\n    return BlobManager(\n        endpoint=f\"https://{os.environ['AZURE_STORAGE_ACCOUNT']}.blob.core.windows.net\",\n        credential=MockAzureCredential(),\n        container=os.environ[\"AZURE_STORAGE_CONTAINER\"],\n        account=os.environ[\"AZURE_STORAGE_ACCOUNT\"],\n        resource_group=os.environ[\"AZURE_STORAGE_RESOURCE_GROUP\"],\n        subscription_id=os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n    )\n@pytest.fixture",
        "detail": "tests.test_blob_manager",
        "documentation": {}
    },
    {
        "label": "adls_blob_manager",
        "kind": 2,
        "importPath": "tests.test_blob_manager",
        "description": "tests.test_blob_manager",
        "peekOfCode": "def adls_blob_manager(monkeypatch):\n    return AdlsBlobManager(\n        endpoint=\"https://test-storage-account.dfs.core.windows.net\",\n        container=\"test-storage-container\",\n        credential=MockAzureCredential(),\n    )\n@pytest.mark.asyncio\n@pytest.mark.skipif(sys.version_info.minor < 10, reason=\"requires Python 3.10 or higher (due to NamedTemporaryFile)\")\nasync def test_upload_and_remove(monkeypatch, mock_env, mock_blob_container_client_exists, blob_manager):\n    with NamedTemporaryFile(suffix=\".pdf\") as temp_file:",
        "detail": "tests.test_blob_manager",
        "documentation": {}
    },
    {
        "label": "test_get_managed_identity_connection_string",
        "kind": 2,
        "importPath": "tests.test_blob_manager",
        "description": "tests.test_blob_manager",
        "peekOfCode": "def test_get_managed_identity_connection_string(mock_env, blob_manager):\n    assert (\n        blob_manager.get_managedidentity_connectionstring()\n        == \"ResourceId=/subscriptions/test-storage-subid/resourceGroups/test-storage-rg/providers/Microsoft.Storage/storageAccounts/test-storage-account;\"\n    )\ndef test_sourcepage_from_file_page():\n    assert BlobManager.sourcepage_from_file_page(\"test.pdf\", 0) == \"test.pdf#page=1\"\n    assert BlobManager.sourcepage_from_file_page(\"test.html\", 0) == \"test.html\"\ndef test_blob_name_from_file_name():\n    assert BlobManager.blob_name_from_file_name(\"tmp/test.pdf\") == \"test.pdf\"",
        "detail": "tests.test_blob_manager",
        "documentation": {}
    },
    {
        "label": "test_sourcepage_from_file_page",
        "kind": 2,
        "importPath": "tests.test_blob_manager",
        "description": "tests.test_blob_manager",
        "peekOfCode": "def test_sourcepage_from_file_page():\n    assert BlobManager.sourcepage_from_file_page(\"test.pdf\", 0) == \"test.pdf#page=1\"\n    assert BlobManager.sourcepage_from_file_page(\"test.html\", 0) == \"test.html\"\ndef test_blob_name_from_file_name():\n    assert BlobManager.blob_name_from_file_name(\"tmp/test.pdf\") == \"test.pdf\"\n    assert BlobManager.blob_name_from_file_name(\"tmp/test.html\") == \"test.html\"\n@pytest.mark.asyncio\nasync def test_download_blob(monkeypatch, mock_env, mock_blob_container_client_exists, blob_manager):\n    # Mock the download_blob method\n    test_content = b\"test content bytes\"",
        "detail": "tests.test_blob_manager",
        "documentation": {}
    },
    {
        "label": "test_blob_name_from_file_name",
        "kind": 2,
        "importPath": "tests.test_blob_manager",
        "description": "tests.test_blob_manager",
        "peekOfCode": "def test_blob_name_from_file_name():\n    assert BlobManager.blob_name_from_file_name(\"tmp/test.pdf\") == \"test.pdf\"\n    assert BlobManager.blob_name_from_file_name(\"tmp/test.html\") == \"test.html\"\n@pytest.mark.asyncio\nasync def test_download_blob(monkeypatch, mock_env, mock_blob_container_client_exists, blob_manager):\n    # Mock the download_blob method\n    test_content = b\"test content bytes\"\n    class MockDownloadResponse:\n        def __init__(self):\n            # Create properties with content_settings",
        "detail": "tests.test_blob_manager",
        "documentation": {}
    },
    {
        "label": "test_get_search_query",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_get_search_query(chat_approach):\n    payload = \"\"\"\n    {\n\t\"id\": \"chatcmpl-81JkxYqYppUkPtOAia40gki2vJ9QM\",\n\t\"object\": \"chat.completion\",\n\t\"created\": 1695324963,\n\t\"model\": \"gpt-4.1-mini\",\n\t\"prompt_filter_results\": [\n\t\t{\n\t\t\t\"prompt_index\": 0,",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "test_get_search_query_returns_default",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_get_search_query_returns_default(chat_approach):\n    payload = '{\"id\":\"chatcmpl-81JkxYqYppUkPtOAia40gki2vJ9QM\",\"object\":\"chat.completion\",\"created\":1695324963,\"model\":\"gpt-4.1-mini\",\"prompt_filter_results\":[{\"prompt_index\":0,\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}}}],\"choices\":[{\"index\":0,\"finish_reason\":\"function_call\",\"message\":{\"content\":\"\",\"role\":\"assistant\"},\"content_filter_results\":{}}],\"usage\":{\"completion_tokens\":19,\"prompt_tokens\":425,\"total_tokens\":444}}'\n    default_query = \"hello\"\n    chatcompletions = ChatCompletion.model_validate(json.loads(payload), strict=False)\n    query = chat_approach.get_search_query(chatcompletions, default_query)\n    assert query == default_query\ndef test_extract_followup_questions(chat_approach):\n    content = \"Here is answer to your question.<<What is the dress code?>>\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"Here is answer to your question.\"",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "test_extract_followup_questions",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_extract_followup_questions(chat_approach):\n    content = \"Here is answer to your question.<<What is the dress code?>>\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"Here is answer to your question.\"\n    assert followup_questions == [\"What is the dress code?\"]\ndef test_extract_followup_questions_three(chat_approach):\n    content = \"\"\"Here is answer to your question.\n<<What are some examples of successful product launches they should have experience with?>>\n<<Are there any specific technical skills or certifications required for the role?>>\n<<Is there a preference for candidates with experience in a specific industry or sector?>>\"\"\"",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "test_extract_followup_questions_three",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_extract_followup_questions_three(chat_approach):\n    content = \"\"\"Here is answer to your question.\n<<What are some examples of successful product launches they should have experience with?>>\n<<Are there any specific technical skills or certifications required for the role?>>\n<<Is there a preference for candidates with experience in a specific industry or sector?>>\"\"\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"Here is answer to your question.\\n\\n\"\n    assert followup_questions == [\n        \"What are some examples of successful product launches they should have experience with?\",\n        \"Are there any specific technical skills or certifications required for the role?\",",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "test_extract_followup_questions_no_followup",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_extract_followup_questions_no_followup(chat_approach):\n    content = \"Here is answer to your question.\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"Here is answer to your question.\"\n    assert followup_questions == []\ndef test_extract_followup_questions_no_pre_content(chat_approach):\n    content = \"<<What is the dress code?>>\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"\"\n    assert followup_questions == [\"What is the dress code?\"]",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "test_extract_followup_questions_no_pre_content",
        "kind": 2,
        "importPath": "tests.test_chatapproach",
        "description": "tests.test_chatapproach",
        "peekOfCode": "def test_extract_followup_questions_no_pre_content(chat_approach):\n    content = \"<<What is the dress code?>>\"\n    pre_content, followup_questions = chat_approach.extract_followup_questions(content)\n    assert pre_content == \"\"\n    assert followup_questions == [\"What is the dress code?\"]\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"minimum_search_score,minimum_reranker_score,expected_result_count\",\n    [\n        (0, 0, 1),",
        "detail": "tests.test_chatapproach",
        "documentation": {}
    },
    {
        "label": "MockCosmosDBResultsIterator",
        "kind": 6,
        "importPath": "tests.test_cosmosdb",
        "description": "tests.test_cosmosdb",
        "peekOfCode": "class MockCosmosDBResultsIterator:\n    def __init__(self, data=[]):\n        self.data = copy.deepcopy(data)\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if not self.data:\n            raise StopAsyncIteration\n        return MockAsyncPageIterator(self.data.pop(0))\n    async def get_count(self):",
        "detail": "tests.test_cosmosdb",
        "documentation": {}
    },
    {
        "label": "for_sessions_query",
        "kind": 5,
        "importPath": "tests.test_cosmosdb",
        "description": "tests.test_cosmosdb",
        "peekOfCode": "for_sessions_query = [\n    [\n        {\n            \"id\": \"123\",\n            \"session_id\": \"123\",\n            \"entra_oid\": \"OID_X\",\n            \"title\": \"This is a test message\",\n            \"timestamp\": 123456789,\n            \"type\": \"session\",\n        }",
        "detail": "tests.test_cosmosdb",
        "documentation": {}
    },
    {
        "label": "for_deletion_query",
        "kind": 5,
        "importPath": "tests.test_cosmosdb",
        "description": "tests.test_cosmosdb",
        "peekOfCode": "for_deletion_query = [\n    [\n        {\n            \"id\": \"123\",\n            \"session_id\": \"123\",\n            \"entra_oid\": \"OID_X\",\n            \"title\": \"This is a test message\",\n            \"timestamp\": 123456789,\n            \"type\": \"session\",\n        },",
        "detail": "tests.test_cosmosdb",
        "documentation": {}
    },
    {
        "label": "for_message_pairs_query",
        "kind": 5,
        "importPath": "tests.test_cosmosdb",
        "description": "tests.test_cosmosdb",
        "peekOfCode": "for_message_pairs_query = [\n    [\n        {\n            \"id\": \"123-0\",\n            \"version\": \"cosmosdb-v2\",\n            \"session_id\": \"123\",\n            \"entra_oid\": \"OID_X\",\n            \"type\": \"message_pair\",\n            \"question\": \"What does a Product Manager do?\",\n            \"response\": {",
        "detail": "tests.test_cosmosdb",
        "documentation": {}
    },
    {
        "label": "MockAsyncPageIterator",
        "kind": 6,
        "importPath": "tests.test_cosmosdb_migration",
        "description": "tests.test_cosmosdb_migration",
        "peekOfCode": "class MockAsyncPageIterator:\n    \"\"\"Helper class to mock an async page from CosmosDB\"\"\"\n    def __init__(self, items):\n        self.items = items\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if not self.items:\n            raise StopAsyncIteration\n        return self.items.pop(0)",
        "detail": "tests.test_cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "MockCosmosDBResultsIterator",
        "kind": 6,
        "importPath": "tests.test_cosmosdb_migration",
        "description": "tests.test_cosmosdb_migration",
        "peekOfCode": "class MockCosmosDBResultsIterator:\n    \"\"\"Helper class to mock a paginated query result from CosmosDB\"\"\"\n    def __init__(self, data=[]):\n        self.data = data\n        self.continuation_token = None\n    def by_page(self, continuation_token=None):\n        \"\"\"Return a paged iterator\"\"\"\n        self.continuation_token = \"next_token\" if not continuation_token else continuation_token + \"_next\"\n        # Return an async iterator that contains pages\n        return MockPagesAsyncIterator(self.data)",
        "detail": "tests.test_cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "MockPagesAsyncIterator",
        "kind": 6,
        "importPath": "tests.test_cosmosdb_migration",
        "description": "tests.test_cosmosdb_migration",
        "peekOfCode": "class MockPagesAsyncIterator:\n    \"\"\"Helper class to mock an iterator of pages\"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.continuation_token = \"next_token\"\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if not self.data:\n            raise StopAsyncIteration",
        "detail": "tests.test_cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "TEST_OLD_ITEM",
        "kind": 5,
        "importPath": "tests.test_cosmosdb_migration",
        "description": "tests.test_cosmosdb_migration",
        "peekOfCode": "TEST_OLD_ITEM = {\n    \"id\": \"123\",\n    \"entra_oid\": \"OID_X\",\n    \"title\": \"This is a test message\",\n    \"timestamp\": 123456789,\n    \"answers\": [\n        [\n            \"What does a Product Manager do?\",\n            {\n                \"delta\": {\"role\": \"assistant\"},",
        "detail": "tests.test_cosmosdb_migration",
        "documentation": {}
    },
    {
        "label": "ChunkStub",
        "kind": 6,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "class ChunkStub:\n    page_num: int\n    text: str\n    images: list[Any] = field(default_factory=list)\n@dataclass\nclass SectionStub:\n    chunk: ChunkStub\ndef build_request(payload: dict[str, Any]) -> func.HttpRequest:\n    \"\"\"Construct an HttpRequest carrying the provided payload.\"\"\"\n    body = json.dumps(payload).encode(\"utf-8\")",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "SectionStub",
        "kind": 6,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "class SectionStub:\n    chunk: ChunkStub\ndef build_request(payload: dict[str, Any]) -> func.HttpRequest:\n    \"\"\"Construct an HttpRequest carrying the provided payload.\"\"\"\n    body = json.dumps(payload).encode(\"utf-8\")\n    return func.HttpRequest(\n        method=\"POST\",\n        url=\"http://localhost/api\",\n        headers={},\n        params={},",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "build_request",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def build_request(payload: dict[str, Any]) -> func.HttpRequest:\n    \"\"\"Construct an HttpRequest carrying the provided payload.\"\"\"\n    body = json.dumps(payload).encode(\"utf-8\")\n    return func.HttpRequest(\n        method=\"POST\",\n        url=\"http://localhost/api\",\n        headers={},\n        params={},\n        body=body,\n    )",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "build_raw_request",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def build_raw_request(body: bytes) -> func.HttpRequest:\n    \"\"\"Construct an HttpRequest with a raw (non-JSON) payload.\"\"\"\n    return func.HttpRequest(\n        method=\"POST\",\n        url=\"http://localhost/api\",\n        headers={},\n        params={},\n        body=body,\n    )\n@pytest.mark.asyncio",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_document_extractor_missing_file_data",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_document_extractor_missing_file_data() -> None:\n    with pytest.raises(ValueError):\n        document_extractor.get_document_stream_filedata({\"file_data\": {}})\ndef test_document_extractor_managed_identity_reload(monkeypatch: pytest.MonkeyPatch) -> None:\n    monkeypatch.setenv(\"AZURE_CLIENT_ID\", \"client-123\")\n    document_extractor.configure_global_settings()\n    assert isinstance(document_extractor.settings.azure_credential, document_extractor.ManagedIdentityCredential)\n    monkeypatch.delenv(\"AZURE_CLIENT_ID\", raising=False)\n    document_extractor.configure_global_settings()\n@pytest.mark.asyncio",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_document_extractor_managed_identity_reload",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_document_extractor_managed_identity_reload(monkeypatch: pytest.MonkeyPatch) -> None:\n    monkeypatch.setenv(\"AZURE_CLIENT_ID\", \"client-123\")\n    document_extractor.configure_global_settings()\n    assert isinstance(document_extractor.settings.azure_credential, document_extractor.ManagedIdentityCredential)\n    monkeypatch.delenv(\"AZURE_CLIENT_ID\", raising=False)\n    document_extractor.configure_global_settings()\n@pytest.mark.asyncio\nasync def test_figure_processor_returns_enriched_metadata(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"Figure processor enriches images with URL and description.\"\"\"\n    async def fake_process_page_image(*, image, document_filename: str, **kwargs: Any):",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_figure_processor_initialisation_with_env",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_figure_processor_initialisation_with_env(monkeypatch: pytest.MonkeyPatch) -> None:\n    monkeypatch.setenv(\"AZURE_CLIENT_ID\", \"client-456\")\n    monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"acct\")\n    monkeypatch.setenv(\"AZURE_IMAGESTORAGE_CONTAINER\", \"images\")\n    monkeypatch.setenv(\"USE_MULTIMODAL\", \"true\")\n    monkeypatch.setenv(\"AZURE_OPENAI_SERVICE\", \"svc\")\n    monkeypatch.setenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"deploy\")\n    monkeypatch.setenv(\"AZURE_VISION_ENDPOINT\", \"https://vision\")\n    call_state: dict[str, Any] = {}\n    class StubCredential:",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_figure_processor_warns_when_openai_incomplete",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_figure_processor_warns_when_openai_incomplete(monkeypatch: pytest.MonkeyPatch, caplog) -> None:\n    \"\"\"Figure processor is created with warning when USE_MULTIMODAL is true but OpenAI config is incomplete.\"\"\"\n    monkeypatch.setenv(\"USE_MULTIMODAL\", \"true\")\n    monkeypatch.setenv(\"AZURE_STORAGE_ACCOUNT\", \"acct\")\n    monkeypatch.setenv(\"AZURE_IMAGESTORAGE_CONTAINER\", \"images\")\n    # OpenAI config missing, so figure_processor will be created but won't work properly\n    figure_processor.configure_global_settings()\n    # A FigureProcessor object is created even with incomplete config\n    assert figure_processor.settings.figure_processor is not None\n    assert \"USE_MULTIMODAL is true but Azure OpenAI configuration incomplete\" in caplog.text",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_document_extractor_module_init_key_error",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_document_extractor_module_init_key_error(\n    monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture\n) -> None:\n    \"\"\"Reload module without pytest env to trigger init warning path.\"\"\"\n    import importlib\n    from unittest import mock\n    saved_env = os.environ.get(\"PYTEST_CURRENT_TEST\")\n    monkeypatch.delenv(\"PYTEST_CURRENT_TEST\", raising=False)\n    caplog.set_level(\"WARNING\")\n    with mock.patch(\"azure.identity.aio.ManagedIdentityCredential\", lambda *_, **__: object()), mock.patch(",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_text_processor_configure_logs_when_embedding_config_missing",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_text_processor_configure_logs_when_embedding_config_missing(\n    monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture\n) -> None:\n    monkeypatch.setenv(\"USE_VECTORS\", \"true\")\n    monkeypatch.setattr(text_processor, \"ManagedIdentityCredential\", lambda *args, **kwargs: object())\n    monkeypatch.setattr(text_processor, \"build_file_processors\", lambda **kwargs: {\".pdf\": object()})\n    text_processor.settings = None\n    with caplog.at_level(logging.WARNING):\n        text_processor.configure_global_settings()\n    assert \"embedding configuration incomplete\" in caplog.text",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_text_processor_module_init_logs_warning",
        "kind": 2,
        "importPath": "tests.test_function_apps",
        "description": "tests.test_function_apps",
        "peekOfCode": "def test_text_processor_module_init_logs_warning(\n    monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture\n) -> None:\n    import importlib\n    from unittest import mock\n    saved_env = os.environ.get(\"PYTEST_CURRENT_TEST\")\n    monkeypatch.delenv(\"PYTEST_CURRENT_TEST\", raising=False)\n    class StubCredential:\n        def __init__(self, *args, **kwargs) -> None:\n            pass",
        "detail": "tests.test_function_apps",
        "documentation": {}
    },
    {
        "label": "test_file_filename",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_file_filename():\n    empty = io.BytesIO()\n    empty.name = \"test/foo.pdf\"\n    assert File(empty).filename() == \"foo.pdf\"\ndef test_file_file_extension():\n    empty = io.BytesIO()\n    empty.name = \"test/foo.pdf\"\n    assert File(empty).file_extension() == \".pdf\"\ndef test_file_contextmanager():\n    empty = io.BytesIO()",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "test_file_file_extension",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_file_file_extension():\n    empty = io.BytesIO()\n    empty.name = \"test/foo.pdf\"\n    assert File(empty).file_extension() == \".pdf\"\ndef test_file_contextmanager():\n    empty = io.BytesIO()\n    empty.name = \"test/foo.pdf\"\n    f = File(empty)\n    assert f.content.read() == b\"\"\n    f.close()",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "test_file_contextmanager",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_file_contextmanager():\n    empty = io.BytesIO()\n    empty.name = \"test/foo.pdf\"\n    f = File(empty)\n    assert f.content.read() == b\"\"\n    f.close()\n    assert empty.closed\ndef test_file_filename_to_id():\n    empty = io.BytesIO()\n    empty.name = \"foo.pdf\"",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "test_file_filename_to_id",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_file_filename_to_id():\n    empty = io.BytesIO()\n    empty.name = \"foo.pdf\"\n    # test ascii filename\n    assert File(empty).filename_to_id() == \"file-foo_pdf-666F6F2E706466\"\n    # test filename containing unicode\n    empty.name = \"foo\\u00a9.txt\"\n    assert File(empty).filename_to_id() == \"file-foo__txt-666F6FC2A92E747874\"\n    # test filenaming starting with unicode\n    empty.name = \".pdf\"",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "test_file_filename_to_id_acls",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_file_filename_to_id_acls():\n    empty = io.BytesIO()\n    empty.name = \"foo.pdf\"\n    filename_id = File(empty).filename_to_id()\n    filename_id2 = File(empty, acls={\"oids\": [\"A-USER-ID\"]}).filename_to_id()\n    filename_id3 = File(empty, acls={\"groups\": [\"A-GROUP-ID\"]}).filename_to_id()\n    filename_id4 = File(empty, acls={\"oids\": [\"A-USER-ID\"], \"groups\": [\"A-GROUP-ID\"]}).filename_to_id()\n    # Assert that all filenames are unique\n    assert len(set([filename_id, filename_id2, filename_id3, filename_id4])) == 4\n@pytest.mark.asyncio",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "test_locallistfilestrategy_checkmd5",
        "kind": 2,
        "importPath": "tests.test_listfilestrategy",
        "description": "tests.test_listfilestrategy",
        "peekOfCode": "def test_locallistfilestrategy_checkmd5():\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        with open(os.path.join(tmpdirname, \"test.pdf\"), \"w\") as pdf_file:\n            pdf_file.write(\"test\")\n            f1_hash = hashlib.md5(b\"test\").hexdigest()\n        with open(os.path.join(tmpdirname, \"test.pdf.md5\"), \"w\", encoding=\"utf-8\") as md5_file:\n            md5_file.write(f1_hash)\n        local_list_strategy = LocalListFileStrategy(path_pattern=f\"{tmpdirname}/*\")\n        assert local_list_strategy.check_md5(md5_file.name) is True\n        assert local_list_strategy.check_md5(pdf_file.name) is True",
        "detail": "tests.test_listfilestrategy",
        "documentation": {}
    },
    {
        "label": "AsyncSearchResultsIterator",
        "kind": 6,
        "importPath": "tests.test_manageacl",
        "description": "tests.test_manageacl",
        "peekOfCode": "class AsyncSearchResultsIterator:\n    def __init__(self, results):\n        self.results = results\n        self.num = len(results)\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        self.num -= 1\n        if self.num >= 0:\n            return self.results[self.num]",
        "detail": "tests.test_manageacl",
        "documentation": {}
    },
    {
        "label": "AsyncPageIterator",
        "kind": 6,
        "importPath": "tests.test_manageacl",
        "description": "tests.test_manageacl",
        "peekOfCode": "class AsyncPageIterator:\n    def __init__(self, pages):\n        self.pages = pages\n        self.index = 0\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if self.index < len(self.pages):\n            page = self.pages[self.index]\n            self.index += 1",
        "detail": "tests.test_manageacl",
        "documentation": {}
    },
    {
        "label": "AsyncPageContent",
        "kind": 6,
        "importPath": "tests.test_manageacl",
        "description": "tests.test_manageacl",
        "peekOfCode": "class AsyncPageContent:\n    def __init__(self, items):\n        self.items = items\n        self.index = 0\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if self.index < len(self.items):\n            item = self.items[self.index]\n            self.index += 1",
        "detail": "tests.test_manageacl",
        "documentation": {}
    },
    {
        "label": "validate_index",
        "kind": 2,
        "importPath": "tests.test_manageacl",
        "description": "tests.test_manageacl",
        "peekOfCode": "def validate_index(index):\n    assert len(index.fields) == 3\n    oids_field = None\n    groups_field = None\n    storageurl_field = None\n    for field in index.fields:\n        if field.name == \"oids\":\n            assert not oids_field\n            oids_field = field\n        elif field.name == \"groups\":",
        "detail": "tests.test_manageacl",
        "documentation": {}
    },
    {
        "label": "MockAsyncOpenAI",
        "kind": 6,
        "importPath": "tests.test_mediadescriber",
        "description": "tests.test_mediadescriber",
        "peekOfCode": "class MockAsyncOpenAI:\n    def __init__(self, test_response):\n        self.chat = type(\"MockChat\", (), {})()\n        self.chat.completions = MockChatCompletions(test_response)\nclass MockChatCompletions:\n    def __init__(self, test_response):\n        self.test_response = test_response\n        self.create_calls = []\n    async def create(self, *args, **kwargs):\n        self.create_calls.append(kwargs)",
        "detail": "tests.test_mediadescriber",
        "documentation": {}
    },
    {
        "label": "MockChatCompletions",
        "kind": 6,
        "importPath": "tests.test_mediadescriber",
        "description": "tests.test_mediadescriber",
        "peekOfCode": "class MockChatCompletions:\n    def __init__(self, test_response):\n        self.test_response = test_response\n        self.create_calls = []\n    async def create(self, *args, **kwargs):\n        self.create_calls.append(kwargs)\n        return self.test_response\n@pytest.mark.asyncio\n@pytest.mark.parametrize(\n    \"model, deployment, expected_model_param\",",
        "detail": "tests.test_mediadescriber",
        "documentation": {}
    },
    {
        "label": "sample_image",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def sample_image():\n    \"\"\"Fixture for a sample ImageOnPage object used across multiple tests.\"\"\"\n    return ImageOnPage(\n        bytes=b\"fake\",\n        bbox=(0, 0, 100, 100),\n        page_num=1,\n        figure_id=\"fig_1\",\n        placeholder='<figure id=\"fig_1\"></figure>',\n        filename=\"test.png\",\n    )",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "assert_image_equal",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def assert_image_equal(image1, image2):\n    assert image1.size == image2.size\n    assert image1.mode == image2.mode\n    # Based on https://stackoverflow.com/a/55251080/1347623\n    diff = ImageChops.difference(image1, image2).histogram()\n    sq = (value * (i % 256) ** 2 for i, value in enumerate(diff))\n    rms = math.sqrt(sum(sq) / float(image1.size[0] * image1.size[1]))\n    assert rms < 90\ndef test_crop_image_from_pdf_page():\n    doc = pymupdf.open(TEST_DATA_DIR / \"Financial Market Analysis Report 2023.pdf\", filetype=\"pdf\")",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_crop_image_from_pdf_page",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_crop_image_from_pdf_page():\n    doc = pymupdf.open(TEST_DATA_DIR / \"Financial Market Analysis Report 2023.pdf\", filetype=\"pdf\")\n    page_number = 2\n    bounding_box = (1.4703, 2.8371, 5.5381, 6.6022)  # Coordinates in inches\n    cropped_image_bytes, bbox_pixels = DocumentAnalysisParser.crop_image_from_pdf_page(doc, page_number, bounding_box)\n    # Verify the output is not empty\n    assert cropped_image_bytes is not None\n    assert len(cropped_image_bytes) > 0\n    assert bbox_pixels is not None\n    assert len(bbox_pixels) == 4",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_table_to_html",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_table_to_html():\n    table = DocumentTable(\n        row_count=2,\n        column_count=2,\n        cells=[\n            DocumentTableCell(row_index=0, column_index=0, content=\"Header 1\", kind=\"columnHeader\"),\n            DocumentTableCell(row_index=0, column_index=1, content=\"Header 2\", kind=\"columnHeader\"),\n            DocumentTableCell(row_index=1, column_index=0, content=\"Cell 1\"),\n            DocumentTableCell(row_index=1, column_index=1, content=\"Cell 2\"),\n        ],",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_table_to_html_with_spans",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_table_to_html_with_spans():\n    table = DocumentTable(\n        row_count=2,\n        column_count=2,\n        cells=[\n            DocumentTableCell(row_index=0, column_index=0, content=\"Header 1\", kind=\"columnHeader\", column_span=2),\n            DocumentTableCell(row_index=1, column_index=0, content=\"Cell 1\", row_span=2),\n            DocumentTableCell(row_index=1, column_index=1, content=\"Cell 2\"),\n        ],\n    )",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_image_on_page_from_skill_payload_without_bytes",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_image_on_page_from_skill_payload_without_bytes():\n    \"\"\"Test ImageOnPage.from_skill_payload when bytes_base64 is not provided.\"\"\"\n    payload = {\n        \"filename\": \"test.png\",\n        \"figure_id\": \"fig_1\",\n        \"page_num\": \"1\",\n        \"bbox\": [0, 0, 100, 100],\n        \"document_file_name\": \"test.pdf\",\n    }\n    image, doc_filename = ImageOnPage.from_skill_payload(payload)",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_image_on_page_from_skill_payload_invalid_page_num",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_image_on_page_from_skill_payload_invalid_page_num():\n    \"\"\"Test ImageOnPage.from_skill_payload with invalid page_num.\"\"\"\n    payload = {\n        \"filename\": \"test.png\",\n        \"figure_id\": \"fig_1\",\n        \"page_num\": \"invalid\",\n        \"bbox\": [0, 0, 100, 100],\n    }\n    image, _ = ImageOnPage.from_skill_payload(payload)\n    assert image.page_num == 0",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "test_image_on_page_from_skill_payload_invalid_bbox",
        "kind": 2,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "def test_image_on_page_from_skill_payload_invalid_bbox():\n    \"\"\"Test ImageOnPage.from_skill_payload with invalid bbox.\"\"\"\n    payload = {\n        \"filename\": \"test.png\",\n        \"figure_id\": \"fig_1\",\n        \"page_num\": 1,\n        \"bbox\": [0, 0, 100],  # Only 3 elements\n    }\n    image, _ = ImageOnPage.from_skill_payload(payload)\n    assert image.bbox == (0, 0, 0, 0)",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "TEST_DATA_DIR",
        "kind": 5,
        "importPath": "tests.test_pdfparser",
        "description": "tests.test_pdfparser",
        "peekOfCode": "TEST_DATA_DIR = pathlib.Path(__file__).parent / \"test-data\"\n@pytest.fixture\ndef sample_image():\n    \"\"\"Fixture for a sample ImageOnPage object used across multiple tests.\"\"\"\n    return ImageOnPage(\n        bytes=b\"fake\",\n        bbox=(0, 0, 100, 100),\n        page_num=1,\n        figure_id=\"fig_1\",\n        placeholder='<figure id=\"fig_1\"></figure>',",
        "detail": "tests.test_pdfparser",
        "documentation": {}
    },
    {
        "label": "MockEmbeddingsClient",
        "kind": 6,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "class MockEmbeddingsClient:\n    def __init__(self, create_embedding_response: openai.types.CreateEmbeddingResponse):\n        self.create_embedding_response = create_embedding_response\n    async def create(self, *args, **kwargs) -> openai.types.CreateEmbeddingResponse:\n        return self.create_embedding_response\nclass MockClient:\n    def __init__(self, embeddings_client):\n        self.embeddings = embeddings_client\n@pytest.mark.asyncio\nasync def test_compute_embedding_success():",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "MockClient",
        "kind": 6,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "class MockClient:\n    def __init__(self, embeddings_client):\n        self.embeddings = embeddings_client\n@pytest.mark.asyncio\nasync def test_compute_embedding_success():\n    response = openai.types.CreateEmbeddingResponse(\n        object=\"list\",\n        data=[\n            openai.types.Embedding(\n                embedding=[",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "RateLimitMockEmbeddingsClient",
        "kind": 6,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "class RateLimitMockEmbeddingsClient:\n    async def create(self, *args, **kwargs) -> openai.types.CreateEmbeddingResponse:\n        raise openai.RateLimitError(\n            message=\"Rate limited on the OpenAI embeddings API\", response=fake_response(409), body=None\n        )\nasync def create_rate_limit_client(*args, **kwargs):\n    return MockClient(embeddings_client=RateLimitMockEmbeddingsClient())\n@pytest.mark.asyncio\nasync def test_compute_embedding_ratelimiterror_batch(monkeypatch, caplog):\n    with caplog.at_level(logging.INFO):",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "AuthenticationErrorMockEmbeddingsClient",
        "kind": 6,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "class AuthenticationErrorMockEmbeddingsClient:\n    async def create(self, *args, **kwargs) -> openai.types.CreateEmbeddingResponse:\n        raise openai.AuthenticationError(message=\"Bad things happened.\", response=fake_response(403), body=None)\n@pytest.mark.asyncio\nasync def test_compute_embedding_autherror(monkeypatch):\n    monkeypatch.setattr(\n        \"prepdocslib.embeddings.wait_random_exponential\",\n        lambda *args, **kwargs: tenacity.wait_fixed(0),\n    )\n    with pytest.raises(openai.AuthenticationError):",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "fake_response",
        "kind": 2,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "def fake_response(http_code):\n    return Response(http_code, request=Request(method=\"get\", url=\"https://foo.bar/\"))\nclass RateLimitMockEmbeddingsClient:\n    async def create(self, *args, **kwargs) -> openai.types.CreateEmbeddingResponse:\n        raise openai.RateLimitError(\n            message=\"Rate limited on the OpenAI embeddings API\", response=fake_response(409), body=None\n        )\nasync def create_rate_limit_client(*args, **kwargs):\n    return MockClient(embeddings_client=RateLimitMockEmbeddingsClient())\n@pytest.mark.asyncio",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "test_setup_list_file_strategy_uses_datalake_key",
        "kind": 2,
        "importPath": "tests.test_prepdocs",
        "description": "tests.test_prepdocs",
        "peekOfCode": "def test_setup_list_file_strategy_uses_datalake_key(monkeypatch: pytest.MonkeyPatch) -> None:\n    captured: dict[str, object] = {}\n    class StubAdlsStrategy:\n        def __init__(\n            self,\n            *,\n            data_lake_storage_account: str,\n            data_lake_filesystem: str,\n            data_lake_path: str,\n            credential: object,",
        "detail": "tests.test_prepdocs",
        "documentation": {}
    },
    {
        "label": "test_sentencetextsplitter_split_empty_pages",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentencetextsplitter_split_empty_pages():\n    t = SentenceTextSplitter()\n    assert list(t.split_pages([])) == []\ndef test_sentencetextsplitter_split_small_pages():\n    t = SentenceTextSplitter()\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text=\"Not a large page\")]))\n    assert len(chunks) == 1\n    assert chunks[0].page_num == 0\n    assert chunks[0].text == \"Not a large page\"\n@pytest.mark.asyncio",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentencetextsplitter_split_small_pages",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentencetextsplitter_split_small_pages():\n    t = SentenceTextSplitter()\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text=\"Not a large page\")]))\n    assert len(chunks) == 1\n    assert chunks[0].page_num == 0\n    assert chunks[0].text == \"Not a large page\"\n@pytest.mark.asyncio\nasync def test_sentencetextsplitter_list_parse_and_split(tmp_path, snapshot):\n    text_splitter = SentenceTextSplitter()\n    pdf_parser = LocalPdfParser()",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_simpletextsplitter_split_empty_pages",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_simpletextsplitter_split_empty_pages():\n    t = SimpleTextSplitter()\n    assert list(t.split_pages([])) == []\ndef test_simpletextsplitter_split_small_pages():\n    t = SimpleTextSplitter()\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text='{\"test\": \"Not a large page\"}')]))\n    assert len(chunks) == 1\n    assert chunks[0].page_num == 0\n    assert chunks[0].text == '{\"test\": \"Not a large page\"}'\ndef test_sentencetextsplitter_split_pages():",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_simpletextsplitter_split_small_pages",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_simpletextsplitter_split_small_pages():\n    t = SimpleTextSplitter()\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text='{\"test\": \"Not a large page\"}')]))\n    assert len(chunks) == 1\n    assert chunks[0].page_num == 0\n    assert chunks[0].text == '{\"test\": \"Not a large page\"}'\ndef test_sentencetextsplitter_split_pages():\n    max_object_length = 10\n    t = SimpleTextSplitter(max_object_length=max_object_length)\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text='{\"test\": \"Not a large page\"}')]))",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentencetextsplitter_split_pages",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentencetextsplitter_split_pages():\n    max_object_length = 10\n    t = SimpleTextSplitter(max_object_length=max_object_length)\n    chunks = list(t.split_pages(pages=[Page(page_num=0, offset=0, text='{\"test\": \"Not a large page\"}')]))\n    assert len(chunks) == 3\n    assert chunks[0].page_num == 0\n    assert chunks[0].text == '{\"test\": \"'\n    assert len(chunks[0].text) <= max_object_length\n    assert chunks[1].page_num == 1\n    assert chunks[1].text == \"Not a larg\"",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "pytest_generate_tests",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def pytest_generate_tests(metafunc):\n    \"\"\"Parametrize the test_doc fixture with all the pdf files in the test-data directory.\"\"\"\n    if \"test_doc\" in metafunc.fixturenames:\n        metafunc.parametrize(\"test_doc\", [pdf for pdf in Path(\"tests\", \"test-data\").glob(\"*.pdf\")])\n@pytest.mark.asyncio\nasync def test_sentencetextsplitter_multilang(test_doc, tmp_path):\n    text_splitter = SentenceTextSplitter()\n    bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\n    pdf_parser = LocalPdfParser()\n    shutil.copy(str(test_doc.absolute()), tmp_path)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_split_tables",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_split_tables():\n    t = SentenceTextSplitter()\n    test_text_without_table = \"\"\"Contoso Electronics is a leader in the aerospace industry, providing advanced electronic\ncomponents for both commercial and military aircraft. We specialize in creating cutting-\nedge systems that are both reliable and efficient. Our mission is to provide the highest\nquality aircraft components to our customers, while maintaining a commitment to safety\nand excellence. We are proud to have built a strong reputation in the aerospace industry\nand strive to continually improve our products and services. Our experienced team of\nengineers and technicians are dedicated to providing the best products and services to our\ncustomers. With our commitment to excellence, we are sure to remain a leader in the",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_pages_with_figures",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_pages_with_figures(snapshot, file_name):\n    # open up the serialized pages from pages_with_figures.json\n    file_path = Path(__file__).parent / \"test-data\" / file_name\n    with open(file_path) as f:\n        pages_dicts = json.load(f)\n    pages = [\n        Page(page_num=page_dict[\"page_num\"], offset=page_dict[\"offset\"], text=page_dict[\"text\"])\n        for page_dict in pages_dicts\n    ]\n    # call split_pages on the pages",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_large_figure_not_split",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_large_figure_not_split():\n    # Construct an intentionally large figure (repeated table rows) that would exceed token limits if split naively\n    repeated_rows = \"\".join([f\"<tr><td>{i}</td><td>Data {i}</td></tr>\" for i in range(200)])\n    large_figure = f\"<figure><figcaption><table>{repeated_rows}</table></figcaption></figure>\"\n    surrounding_text = \"Intro paragraph before figure. \" + large_figure + \" Conclusion after figure.\" * 2\n    pages = [Page(page_num=0, offset=0, text=surrounding_text)]\n    t = SentenceTextSplitter(max_tokens_per_section=50)  # Force a low token threshold\n    chunks = list(t.split_pages(pages=pages))\n    # Assert at least one chunk contains the entire figure block intact\n    figure_chunks = [chunk for chunk in chunks if \"<figure\" in chunk.text and \"</figure>\" in chunk.text]",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_figure_at_start_emitted",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_figure_at_start_emitted():\n    \"\"\"Figure at very start of page should be emitted (regression test for missing emission bug).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=50)\n    fig = \"<figure><img src='x.png'/><figcaption>Cap</figcaption></figure>\"\n    pages = [Page(page_num=0, offset=0, text=fig + \" Following text sentence one. Another sentence.\")]\n    chunks = list(splitter.split_pages(pages))\n    assert chunks, \"No chunks produced\"\n    assert any(\"<figure\" in c.text and \"</figure>\" in c.text for c in chunks), \"Figure not emitted as atomic chunk\"\n    for c in chunks:\n        if \"<figure\" in c.text:",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_unbalanced_figure_treated_as_text",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_unbalanced_figure_treated_as_text():\n    \"\"\"Unbalanced <figure> markup should be treated as plain text and still be split safely.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    # Missing closing </figure>\n    txt = \"Intro \" + \"<figure><img/></figcaption \" + \" morewords\" * 30\n    pages = [Page(page_num=0, offset=0, text=txt)]\n    chunks = list(splitter.split_pages(pages))\n    assert chunks\n    # At least one chunk contains the raw (broken) markup\n    assert any(\"<figure\" in c.text for c in chunks)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_oversize_single_sentence_recursion",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_oversize_single_sentence_recursion():\n    \"\"\"A single oversized sentence (no punctuation) should be recursively split by token logic.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=50)\n    # Use SINGLE_TOKEN_CHAR repetition to exceed token limit: 120 chars -> 120 tokens > 50\n    long_run = SINGLE_TOKEN_CHAR * 120\n    page = Page(page_num=0, offset=0, text=long_run + \".\")\n    chunks = list(splitter.split_pages([page]))\n    assert len(chunks) > 1, \"Expected recursive splitting for oversized sentence\"\n    bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\n    assert all(len(bpe.encode(c.text)) <= splitter.max_tokens_per_section for c in chunks)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentence_boundary_fallback_half_split",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentence_boundary_fallback_half_split():\n    \"\"\"Exercise fallback path when no sentence ending near midpoint causes half/overlap split.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=60)\n    text = \"Start\" + (\" word\" * 180) + \".\"  # Only final punctuation\n    page = Page(page_num=0, offset=0, text=text)\n    chunks = list(splitter.split_pages([page]))\n    assert len(chunks) >= 2, \"Expected multiple chunks from fallback split\"\ndef test_cross_page_merge_mid_sentence():\n    \"\"\"Verify cross-page merge combines mid-sentence break when within limits.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=200)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_merge_mid_sentence",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_merge_mid_sentence():\n    \"\"\"Verify cross-page merge combines mid-sentence break when within limits.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=200)\n    page1 = Page(page_num=0, offset=0, text=\"This is a sentence intentionally broken across pages without completion\")\n    page2 = Page(page_num=1, offset=0, text=\"and continues on the next page with more content.\")\n    chunks = list(splitter.split_pages([page1, page2]))\n    # Ensure there exists a chunk containing both segments (merged) with a space boundary inserted\n    merged = any(\"completion and continues\" in c.text or \"completionand continues\" in c.text for c in chunks)\n    assert merged, f\"Cross-page merge did not occur. Chunks: {[c.text for c in chunks]}\"\ndef test_normalization_trims_leading_space_overflow():",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_normalization_trims_leading_space_overflow",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_normalization_trims_leading_space_overflow():\n    \"\"\"Chunk slightly over char limit due to leading spaces should be normalized (trimmed).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=400)\n    splitter.max_section_length = 50  # tighten char limit for test\n    base = \"A\" * 50\n    overflow = \" \" * 4 + \"tail.\"  # push over 1.2 * max ( = 60 ) by a small margin\n    page = Page(page_num=0, offset=0, text=base + overflow)\n    chunks = list(splitter.split_pages([page]))\n    assert chunks\n    max_chars = int(splitter.max_section_length * 1.2)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_split_page_by_max_tokens_merges_heading_with_figure",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_split_page_by_max_tokens_merges_heading_with_figure():\n    \"\"\"Direct helper invocation should keep heading attached to following figure in same chunk.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=30)\n    heading = \"Heading before figure. \"\n    rows = \"\".join(f\"<tr><td>{i}</td></tr>\" for i in range(40))\n    figure = f\"<figure><table>{rows}</table></figure>\"\n    joined = heading + figure + \" trailing text.\"\n    chunks = list(splitter.split_page_by_max_tokens(0, joined))\n    assert any(c.text.startswith(heading) and \"<figure\" in c.text for c in chunks), \"Heading and figure not merged\"\ndef test_recursive_split_uses_sentence_boundary():",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_recursive_split_uses_sentence_boundary",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_recursive_split_uses_sentence_boundary():\n    \"\"\"Ensure recursive split picks a nearby sentence boundary when available (split_position > 0 path).\"\"\"\n    # Force very small token limit so recursion occurs even for moderate text length\n    splitter = SentenceTextSplitter(max_tokens_per_section=20)\n    # Create two sentences; first ends with period near middle.\n    left = (\"word \" * 15).strip() + \".\"  # ~15 words\n    right = (\"next \" * 14).strip() + \".\"\n    text = left + right\n    chunks = list(splitter.split_page_by_max_tokens(0, text))\n    assert len(chunks) >= 2, f\"Expected recursive split, got 1 chunk: {chunks[0].text}\"",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_merge_fragment_shift_no_sentence_end",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_merge_fragment_shift_no_sentence_end():\n    \"\"\"Cross-page merge failing due to size triggers trailing fragment carry-forward when previous chunk has no sentence ending.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    splitter.max_section_length = 120\n    # Previous page produces one chunk without punctuation so last_end = -1 (fragment_start=0).\n    page1 = Page(page_num=0, offset=0, text=\"word \" * 30)  # ~150 chars, will be emitted as one chunk\n    # Next page starts with lowercase continuation; combined would exceed token limit so merge fails.\n    page2 = Page(page_num=1, offset=0, text=\"continuation \" * 5 + \"end.\")\n    chunks = list(splitter.split_pages([page1, page2]))\n    # Ensure we did NOT merge whole (would have uppercase W then lowercase c joined) but did shift some fragment",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_merge_fragment_shift_with_sentence_end_and_shortening",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_merge_fragment_shift_with_sentence_end_and_shortening():\n    \"\"\"Cross-page merge trailing fragment carry-forward path where a fragment contains an internal sentence boundary allowing shortening.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=60)\n    splitter.max_section_length = 120\n    # Previous chunk ends mid-sentence but contains an earlier full stop to anchor retained portion\n    prev_text = (\n        \"Intro sentence. \"  # full sentence to retain\n        \"Second part that is quite long and will be partially moved and maybe trimmed due to limits \"\n        \"with extra words\"\n    )",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_merge_fragment_shift_hard_trim",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_merge_fragment_shift_hard_trim():\n    \"\"\"Exercise hard trim branch where fragment must be aggressively shortened (token loop).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    splitter.max_section_length = 100\n    # Use repeated single-token char run to create a large fragment (260 tokens) with minimal punctuation.\n    fragment_run_len = 260\n    fragment_run = SINGLE_TOKEN_CHAR * fragment_run_len\n    prev_text = \"Start. \" + fragment_run\n    page1 = Page(page_num=0, offset=0, text=prev_text)\n    # Next page small continuation",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_figure_merge_both_branches",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_figure_merge_both_branches():\n    \"\"\"Ensure figure merge handles preceding text and consecutive figures.\n    This test exercises split_pages with a single Page containing both\n    branches: (1) a figure following existing text, (2) a second consecutive figure,\n    then trailing text.\n    \"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=100)\n    page_text = (\n        \"Heading before.\"  # preceding text (current non-empty before first figure)\n        + \"<figure><img src='a.png'/></figure>\"  # first figure attaches to text and flushes",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentence_boundary_right_side",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentence_boundary_right_side():\n    \"\"\"Trigger sentence boundary discovery on the right side of midpoint (alternate branch).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    # Construct long text with no punctuation until slightly after midpoint, then a period.\n    left = (\"word \" * 120).strip()  # long left without punctuation\n    # Insert single period after some extra words just to the right of mid point\n    right = (\"cont \" * 10) + \"End.\" + (\" tail \" * 20)\n    text = left + \" \" + right\n    chunks = list(splitter.split_page_by_max_tokens(0, text))\n    assert len(chunks) > 1, f\"Expected recursion, got 1 chunk length={len(chunks[0].text)}\"",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentence_boundary_left_side",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentence_boundary_left_side():\n    \"\"\"Trigger sentence boundary on the left side of midpoint (left branch hit first).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    # Create text where a period appears before middle and no period until far right.\n    left_sentence = (\"alpha \" * 25).strip() + \".\"  # this period should be chosen\n    # Long tail without punctuation until very end ensures search finds left first.\n    tail = \" beta\" * 120 + \".\"  # final period far to the right\n    text = left_sentence + tail\n    chunks = list(splitter.split_page_by_max_tokens(0, text))\n    assert len(chunks) > 1",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_sentence_boundary_left_midpoint_exact",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_sentence_boundary_left_midpoint_exact():\n    \"\"\"Exact midpoint has a period so the midpoint search loop selects the left boundary immediately.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=20)\n    # Create symmetric text with period exactly at midpoint index.\n    left = \"A\" * 100\n    right = \"B\" * 100\n    text = left + \".\" + right  # length 201; midpoint index = 100 -> '.'\n    chunks = list(splitter.split_page_by_max_tokens(0, text))\n    assert len(chunks) >= 2\n    assert chunks[0].text.endswith(\".\"), \"First chunk should end with midpoint period\"",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_recursive_split_prefers_word_break_over_overlap",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_recursive_split_prefers_word_break_over_overlap():\n    \"\"\"Punctuation-free text with spaces should split at a word break (space) rather than arbitrary midpoint overlap duplication.\"\"\"\n    # Use deterministic single-token chars to guarantee token overflow.\n    splitter = SentenceTextSplitter(max_tokens_per_section=20)  # Force very low token limit\n    # Create 60 single-token words separated by spaces (approx 120+ tokens including spaces -> >20)\n    word = SINGLE_TOKEN_CHAR * 3  # 3 tokens per word\n    words = [word for _ in range(25)]  # 75 tokens (plus spaces) >> 20 limit\n    text = \" \".join(words)\n    page = Page(page_num=0, offset=0, text=text)\n    chunks = list(splitter.split_pages([page]))",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_recursive_split_overlap_fallback_when_no_word_breaks",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_recursive_split_overlap_fallback_when_no_word_breaks():\n    \"\"\"Long contiguous text without sentence endings or word breaks should fall back to midpoint overlap strategy.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=30)\n    # Use a contiguous run of the single-token char (no spaces / punctuation) to exceed limit.\n    contiguous = SINGLE_TOKEN_CHAR * 120  # 120 tokens > 30 limit, no word breaks or sentence endings\n    page = Page(page_num=0, offset=0, text=contiguous)\n    chunks = list(splitter.split_pages([page]))\n    assert len(chunks) > 1, \"Expected recursion via overlap fallback\"\n    # Detect some overlap duplication at boundaries (heuristic)\n    found_overlap = False",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_fragment_shift_token_limit_fits_false",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_fragment_shift_token_limit_fits_false():\n    \"\"\"Trigger trailing fragment carry-forward where fits() fails solely due to token limit (not char length) and trimming loop runs.\"\"\"\n    # Configure large char allowance so only token constraint matters.\n    splitter = SentenceTextSplitter(max_tokens_per_section=50)\n    splitter.max_section_length = 5000  # very high to avoid char-based fits() failure\n    # Build fragment via single-token char repetition (120 tokens) beyond the 50-token limit.\n    fragment = SINGLE_TOKEN_CHAR * 120  # no terminating punctuation\n    prev_text = \"Intro sentence.\" + fragment  # last sentence end ensures fragment_start > 0\n    page1 = Page(page_num=0, offset=0, text=prev_text)\n    # Next page starts lowercase to trigger merge attempt; small first_new keeps emphasis on fragment tokens.",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_fragment_shift_token_limit_single_token_char",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_fragment_shift_token_limit_single_token_char():\n    \"\"\"Deterministically force token overflow using the single-token pressure char.\n    Repeats exceed the token limit while keeping 1:1 char/token mapping for simpler assertions.\n    \"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=80)\n    splitter.max_section_length = 5000  # ensure only token constraint matters\n    pressure_char = SINGLE_TOKEN_CHAR  # now single-token char\n    bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\n    assert len(bpe.encode(pressure_char)) == 1\n    fragment = pressure_char * 400  # 400 tokens > 80 token limit",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_safe_concat_html_tag_boundary",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_safe_concat_html_tag_boundary():\n    \"\"\"Cross-page merge where previous ends with '>' ensures no extra space inserted.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=80)\n    page1 = Page(page_num=0, offset=0, text=\"<b>Bold tag close></b>\")\n    # Force text so that merge conditions apply (lowercase start, not sentence end)\n    page2 = Page(page_num=1, offset=0, text=\"continues here without leading space.\")\n    chunks = list(splitter.split_pages([page1, page2]))\n    merged = next((c for c in chunks if \"</b>continues\" in c.text or \"</b> continues\" in c.text), None)\n    assert merged is not None, f\"Expected merged chunk, got: {[c.text for c in chunks]}\"\n    # Ensure we did not insert a space because preceding char was '>'",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_normalization_trims_trailing_space_overflow",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_normalization_trims_trailing_space_overflow():\n    \"\"\"Chunk barely over limit with trailing space/newline should have trailing whitespace stripped by normalization.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=400)\n    splitter.max_section_length = 30\n    max_chars = int(splitter.max_section_length * 1.2)  # 36\n    # Build a chunk that will exceed max_chars by <=3 after normalization attempt and ends with space/newline\n    # Construct a page with a single long sentence forcing one chunk slightly over limit, ending with whitespace.\n    # Use no sentence-ending punctuation early so accumulation doesn't flush.\n    # Build base so total length including one trailing space is max_chars+2 (within +3 window)\n    core = \"C\" * (max_chars + 1)",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_fragment_shortening_path",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_fragment_shortening_path():\n    \"\"\"Exercise trailing fragment carry-forward after a complete sentence; ensures part of trailing fragment is moved and retained sentence stays.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=55)\n    splitter.max_section_length = 120\n    # Previous ends with two sentences, second incomplete to encourage trailing fragment carry-forward\n    prev = \"Complete sentence one. Asecondpartthatshouldbeshortened because it is long\"\n    page1 = Page(page_num=0, offset=0, text=prev)\n    nxt = \"continues here with lowercase start.\"  # triggers merge attempt (lowercase)\n    page2 = Page(page_num=1, offset=0, text=nxt)\n    chunks = list(splitter.split_pages([page1, page2]))",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_cross_page_fragment_hard_trim_iterative",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_cross_page_fragment_hard_trim_iterative():\n    \"\"\"Hard trim path where fragment must be iteratively token-trimmed (loop executes).\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=30)\n    splitter.max_section_length = 80\n    fragment_iter_len = 210  # 420 tokens\n    prev = \"Intro. \" + (SINGLE_TOKEN_CHAR * fragment_iter_len)\n    page1 = Page(page_num=0, offset=0, text=prev)\n    page2 = Page(page_num=1, offset=0, text=\"continuation lower start\")\n    chunks = list(splitter.split_pages([page1, page2]))\n    # Some trimmed fragment should appear but much shorter than original",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_intra_page_semantic_overlap_applied",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_intra_page_semantic_overlap_applied():\n    \"\"\"When multiple chunks arise on the SAME page, the second should begin with duplicated\n    semantic overlap (~10% tail of prior), unless figure or heading prevents it.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=40)\n    splitter.max_section_length = 200  # keep char constraint loose\n    # Build text long enough to force at least two chunks via token limit using many short sentences\n    base_sentence = \"alpha beta gamma delta epsilon zeta eta theta iota kappa lambda. \"\n    text = base_sentence * 6  # repeated => should exceed token cap for one chunk\n    page = Page(page_num=0, offset=0, text=text)\n    chunks = list(splitter.split_pages([page]))",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_no_overlap_after_figure_previous",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_no_overlap_after_figure_previous():\n    \"\"\"If previous chunk contains a figure, semantic overlap should not duplicate its suffix.\"\"\"\n    splitter = SentenceTextSplitter(max_tokens_per_section=60)\n    # Compose page with an early figure chunk; then long continuation forcing another chunk.\n    fig = \"<figure><img src='a.png'/><figcaption>Caption text here</figcaption></figure>\"\n    continuation = \" continuing text that will form another chunk because we repeat it.\"\n    text = fig + continuation * 10\n    page = Page(page_num=0, offset=0, text=text)\n    chunks = list(splitter.split_pages([page]))\n    # Locate figure chunk",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "test_append_overlap_preserves_next_chunk_start",
        "kind": 2,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "def test_append_overlap_preserves_next_chunk_start():\n    \"\"\"Ensure the semantic overlap append to the previous chunk instead of\n    prepending to the next, so each chunk starts at a clean sentence\n    boundary.\n    We build text with short sentences forcing multiple chunks due to a low\n    token limit. We then assert:\n    - First and second chunks both start with a capital letter / beginning of a sentence.\n    - Some prefix of the second chunk's starting text is appended to the tail of\n      the first chunk (overlap duplication) without altering the second chunk's\n      own start.",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "SINGLE_TOKEN_CHAR",
        "kind": 5,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "SINGLE_TOKEN_CHAR = \"\"  # 1 token under cl100k_base\n_bpe_for_guard = tiktoken.encoding_for_model(ENCODING_MODEL)\nassert len(_bpe_for_guard.encode(SINGLE_TOKEN_CHAR)) == 1, (\n    f\"Invariant changed: {SINGLE_TOKEN_CHAR!r} no longer encodes to 1 token under {ENCODING_MODEL}; \"\n    \"adjust tests to a different stable single-token char.\"\n)\ndef test_sentencetextsplitter_split_empty_pages():\n    t = SentenceTextSplitter()\n    assert list(t.split_pages([])) == []\ndef test_sentencetextsplitter_split_small_pages():",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "_bpe_for_guard",
        "kind": 5,
        "importPath": "tests.test_prepdocslib_textsplitter",
        "description": "tests.test_prepdocslib_textsplitter",
        "peekOfCode": "_bpe_for_guard = tiktoken.encoding_for_model(ENCODING_MODEL)\nassert len(_bpe_for_guard.encode(SINGLE_TOKEN_CHAR)) == 1, (\n    f\"Invariant changed: {SINGLE_TOKEN_CHAR!r} no longer encodes to 1 token under {ENCODING_MODEL}; \"\n    \"adjust tests to a different stable single-token char.\"\n)\ndef test_sentencetextsplitter_split_empty_pages():\n    t = SentenceTextSplitter()\n    assert list(t.split_pages([])) == []\ndef test_sentencetextsplitter_split_small_pages():\n    t = SentenceTextSplitter()",
        "detail": "tests.test_prepdocslib_textsplitter",
        "documentation": {}
    },
    {
        "label": "AsyncSearchResultsIterator",
        "kind": 6,
        "importPath": "tests.test_searchmanager",
        "description": "tests.test_searchmanager",
        "peekOfCode": "class AsyncSearchResultsIterator:\n    def __init__(self, results):\n        self.results = results\n    def __aiter__(self):\n        return self\n    async def __anext__(self):\n        if len(self.results) == 0:\n            raise StopAsyncIteration\n        return self.results.pop()\n    async def get_count(self):",
        "detail": "tests.test_searchmanager",
        "documentation": {}
    },
    {
        "label": "search_info",
        "kind": 2,
        "importPath": "tests.test_searchmanager",
        "description": "tests.test_searchmanager",
        "peekOfCode": "def search_info():\n    return SearchInfo(\n        endpoint=\"https://testsearchclient.blob.core.windows.net\",\n        credential=AzureKeyCredential(\"test\"),\n        index_name=\"test\",\n    )\n@pytest.mark.asyncio\nasync def test_create_index_doesnt_exist_yet(monkeypatch, search_info):\n    indexes = []\n    async def mock_create_index(self, index):",
        "detail": "tests.test_searchmanager",
        "documentation": {}
    },
    {
        "label": "test_sentence_text_splitter_initializes_overlap_correctly",
        "kind": 2,
        "importPath": "tests.test_sentencetextsplitter",
        "description": "tests.test_sentencetextsplitter",
        "peekOfCode": "def test_sentence_text_splitter_initializes_overlap_correctly(\n    actual_percentage: float, expected_section_overlap: float\n):\n    with patch(\"prepdocslib.textsplitter.DEFAULT_OVERLAP_PERCENT\", actual_percentage):\n        subject = SentenceTextSplitter(False)\n        assert subject.section_overlap == expected_section_overlap",
        "detail": "tests.test_sentencetextsplitter",
        "documentation": {}
    },
    {
        "label": "test_setup_blob_manager_respects_storage_key",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_blob_manager_respects_storage_key(monkeypatch: pytest.MonkeyPatch) -> None:\n    captured: dict[str, object] = {}\n    class StubBlobManager:\n        def __init__(\n            self,\n            *,\n            endpoint: str,\n            container: str,\n            account: str,\n            credential: object,",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_embeddings_service_populates_azure_metadata",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_embeddings_service_populates_azure_metadata() -> None:\n    embeddings = setup_embeddings_service(\n        open_ai_client=MockClient(\n            MockEmbeddingsClient(\n                openai.types.CreateEmbeddingResponse(\n                    object=\"list\",\n                    data=[],\n                    model=\"text-embedding-3-large\",\n                    usage=Usage(prompt_tokens=0, total_tokens=0),\n                )",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_embeddings_service_requires_endpoint_for_azure",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_embeddings_service_requires_endpoint_for_azure() -> None:\n    with pytest.raises(ValueError):\n        setup_embeddings_service(\n            open_ai_client=MockClient(\n                MockEmbeddingsClient(\n                    openai.types.CreateEmbeddingResponse(\n                        object=\"list\",\n                        data=[],\n                        model=\"text-embedding-3-large\",\n                        usage=Usage(prompt_tokens=0, total_tokens=0),",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_embeddings_service_requires_deployment_for_azure",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_embeddings_service_requires_deployment_for_azure() -> None:\n    with pytest.raises(ValueError):\n        setup_embeddings_service(\n            open_ai_client=MockClient(\n                MockEmbeddingsClient(\n                    openai.types.CreateEmbeddingResponse(\n                        object=\"list\",\n                        data=[],\n                        model=\"text-embedding-3-large\",\n                        usage=Usage(prompt_tokens=0, total_tokens=0),",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_azure_constructs_endpoint_correctly",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_azure_constructs_endpoint_correctly(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"Test that setup_openai_client correctly constructs the Azure OpenAI endpoint URL from service name.\"\"\"\n    captured_base_url: list[str] = []\n    class StubAsyncOpenAI:\n        def __init__(self, *, base_url: str, api_key, **kwargs) -> None:\n            captured_base_url.append(base_url)\n    monkeypatch.setattr(\"prepdocslib.servicesetup.AsyncOpenAI\", StubAsyncOpenAI)\n    monkeypatch.setattr(\n        \"prepdocslib.servicesetup.get_bearer_token_provider\", lambda *args, **kwargs: lambda: \"fake_token\"\n    )",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_azure_custom_uses_custom_url",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_azure_custom_uses_custom_url(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"Test that setup_openai_client uses the custom URL for azure_custom host.\"\"\"\n    captured_base_url: list[str] = []\n    class StubAsyncOpenAI:\n        def __init__(self, *, base_url: str, api_key, **kwargs) -> None:\n            captured_base_url.append(base_url)\n    monkeypatch.setattr(\"prepdocslib.servicesetup.AsyncOpenAI\", StubAsyncOpenAI)\n    _, endpoint = setup_openai_client(\n        openai_host=OpenAIHost.AZURE_CUSTOM,\n        azure_credential=MockAzureCredential(),",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_azure_respects_api_key",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_azure_respects_api_key(monkeypatch: pytest.MonkeyPatch) -> None:\n    \"\"\"Test that setup_openai_client uses the API key override when provided.\"\"\"\n    captured_api_key: list[str] = []\n    class StubAsyncOpenAI:\n        def __init__(self, *, base_url: str, api_key: str, **kwargs) -> None:\n            captured_api_key.append(api_key)\n    monkeypatch.setattr(\"prepdocslib.servicesetup.AsyncOpenAI\", StubAsyncOpenAI)\n    setup_openai_client(\n        openai_host=OpenAIHost.AZURE,\n        azure_credential=MockAzureCredential(),",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_openai_requires_api_key",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_openai_requires_api_key() -> None:\n    \"\"\"Test that setup_openai_client raises ValueError when using OpenAI without API key.\"\"\"\n    with pytest.raises(ValueError, match=\"OpenAI key is required\"):\n        setup_openai_client(\n            openai_host=OpenAIHost.OPENAI,\n            azure_credential=MockAzureCredential(),\n            openai_api_key=None,\n        )\ndef test_setup_openai_client_azure_requires_service() -> None:\n    \"\"\"Test that setup_openai_client raises ValueError when using Azure without service name.\"\"\"",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_azure_requires_service",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_azure_requires_service() -> None:\n    \"\"\"Test that setup_openai_client raises ValueError when using Azure without service name.\"\"\"\n    with pytest.raises(ValueError, match=\"AZURE_OPENAI_SERVICE must be set\"):\n        setup_openai_client(\n            openai_host=OpenAIHost.AZURE,\n            azure_credential=MockAzureCredential(),\n            azure_openai_service=None,\n        )\ndef test_setup_openai_client_azure_custom_requires_url() -> None:\n    \"\"\"Test that setup_openai_client raises ValueError when using azure_custom without custom URL.\"\"\"",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_openai_client_azure_custom_requires_url",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_openai_client_azure_custom_requires_url() -> None:\n    \"\"\"Test that setup_openai_client raises ValueError when using azure_custom without custom URL.\"\"\"\n    with pytest.raises(ValueError, match=\"AZURE_OPENAI_CUSTOM_URL must be set\"):\n        setup_openai_client(\n            openai_host=OpenAIHost.AZURE_CUSTOM,\n            azure_credential=MockAzureCredential(),\n            azure_openai_custom_url=None,\n        )\ndef test_setup_search_info_agentic_retrieval_without_model():\n    \"\"\"Test that setup_search_info raises ValueError when using agentic retrieval without search agent model.\"\"\"",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_search_info_agentic_retrieval_without_model",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_search_info_agentic_retrieval_without_model():\n    \"\"\"Test that setup_search_info raises ValueError when using agentic retrieval without search agent model.\"\"\"\n    with pytest.raises(ValueError, match=\"SearchAgent model must be specified\"):\n        setup_search_info(\n            azure_credential=MockAzureCredential(),\n            search_service=\"mysearch\",\n            index_name=\"myindex\",\n            use_agentic_retrieval=True,\n            azure_openai_searchagent_model=None,\n        )",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_image_embeddings_multimodal_without_vision",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_image_embeddings_multimodal_without_vision():\n    \"\"\"Test that setup_image_embeddings_service raises ValueError when using multimodal without vision endpoint.\"\"\"\n    with pytest.raises(ValueError, match=\"Azure AI Vision endpoint must be provided\"):\n        setup_image_embeddings_service(\n            use_multimodal=True,\n            vision_endpoint=None,\n            azure_credential=MockAzureCredential(),\n        )\ndef test_setup_figure_processor_content_understanding():\n    \"\"\"Test that setup_figure_processor returns correct processor for content understanding.\"\"\"",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_setup_figure_processor_content_understanding",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_setup_figure_processor_content_understanding():\n    \"\"\"Test that setup_figure_processor returns correct processor for content understanding.\"\"\"\n    processor = setup_figure_processor(\n        use_multimodal=False,\n        use_content_understanding=True,\n        content_understanding_endpoint=\"https://example.com\",\n        credential=MockAzureCredential(),\n        openai_client=None,\n        openai_model=None,\n        openai_deployment=None,",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_build_file_processors_with_document_intelligence_key",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_build_file_processors_with_document_intelligence_key():\n    \"\"\"Test that build_file_processors uses key credential when provided.\"\"\"\n    file_processors = build_file_processors(\n        azure_credential=MockAzureCredential(),\n        document_intelligence_service=\"myservice\",\n        document_intelligence_key=\"my-key\",\n        use_local_pdf_parser=False,\n        use_local_html_parser=False,\n    )\n    assert \".pdf\" in file_processors",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_build_file_processors_text_files",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_build_file_processors_text_files():\n    \"\"\"Test that build_file_processors includes text file parsers.\"\"\"\n    file_processors = build_file_processors(\n        azure_credential=MockAzureCredential(),\n        document_intelligence_service=None,\n    )\n    assert \".txt\" in file_processors\n    assert isinstance(file_processors[\".txt\"].parser, TextParser)\n    assert \".md\" in file_processors\n    assert isinstance(file_processors[\".md\"].parser, TextParser)",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_build_file_processors_with_di_enables_office_formats",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_build_file_processors_with_di_enables_office_formats():\n    \"\"\"Test that build_file_processors includes Office formats when DI is available.\"\"\"\n    file_processors = build_file_processors(\n        azure_credential=MockAzureCredential(),\n        document_intelligence_service=\"myservice\",\n    )\n    assert \".docx\" in file_processors\n    assert \".pptx\" in file_processors\n    assert \".xlsx\" in file_processors\n    assert isinstance(file_processors[\".docx\"].parser, DocumentAnalysisParser)",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_build_file_processors_without_di_excludes_office_formats",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_build_file_processors_without_di_excludes_office_formats():\n    \"\"\"Test that build_file_processors excludes Office formats when DI is not available.\"\"\"\n    file_processors = build_file_processors(\n        azure_credential=MockAzureCredential(),\n        document_intelligence_service=None,\n    )\n    assert \".docx\" not in file_processors\n    assert \".pptx\" not in file_processors\n    assert \".xlsx\" not in file_processors\ndef test_clean_key_if_exists_handles_whitespace() -> None:",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_clean_key_if_exists_handles_whitespace",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_clean_key_if_exists_handles_whitespace() -> None:\n    assert clean_key_if_exists(\"  secret  \") == \"secret\"\n    assert clean_key_if_exists(\"   \") is None\n    assert clean_key_if_exists(None) is None\ndef test_build_file_processors_logs_when_no_parsers(\n    monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture\n) -> None:\n    caplog.set_level(\"WARNING\")\n    monkeypatch.setattr(\"prepdocslib.servicesetup.DocumentAnalysisParser\", lambda *args, **kwargs: None)\n    processors = build_file_processors(",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_build_file_processors_logs_when_no_parsers",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_build_file_processors_logs_when_no_parsers(\n    monkeypatch: pytest.MonkeyPatch, caplog: pytest.LogCaptureFixture\n) -> None:\n    caplog.set_level(\"WARNING\")\n    monkeypatch.setattr(\"prepdocslib.servicesetup.DocumentAnalysisParser\", lambda *args, **kwargs: None)\n    processors = build_file_processors(\n        azure_credential=MockAzureCredential(),\n        document_intelligence_service=\"service\",\n        use_local_pdf_parser=False,\n        use_local_html_parser=False,",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_select_processor_for_filename_raises_when_unknown",
        "kind": 2,
        "importPath": "tests.test_servicesetup",
        "description": "tests.test_servicesetup",
        "peekOfCode": "def test_select_processor_for_filename_raises_when_unknown() -> None:\n    with pytest.raises(ValueError, match=\"Unsupported file type: file.unsupported\"):\n        select_processor_for_filename(\"file.unsupported\", {\".txt\": FileProcessor(TextParser(), None)})",
        "detail": "tests.test_servicesetup",
        "documentation": {}
    },
    {
        "label": "test_combine_text_with_figures_no_description",
        "kind": 2,
        "importPath": "tests.test_textprocessor",
        "description": "tests.test_textprocessor",
        "peekOfCode": "def test_combine_text_with_figures_no_description():\n    \"\"\"Test combine_text_with_figures when image has no description.\"\"\"\n    image = ImageOnPage(\n        bytes=b\"fake\",\n        bbox=(0, 0, 100, 100),\n        filename=\"test.png\",\n        page_num=1,\n        figure_id=\"fig_1\",\n        placeholder=\"[PLACEHOLDER_fig_1]\",\n        description=None,",
        "detail": "tests.test_textprocessor",
        "documentation": {}
    },
    {
        "label": "test_combine_text_with_figures_placeholder_not_found",
        "kind": 2,
        "importPath": "tests.test_textprocessor",
        "description": "tests.test_textprocessor",
        "peekOfCode": "def test_combine_text_with_figures_placeholder_not_found(caplog):\n    \"\"\"Test combine_text_with_figures when placeholder is not in text.\"\"\"\n    import logging\n    image = ImageOnPage(\n        bytes=b\"fake\",\n        bbox=(0, 0, 100, 100),\n        filename=\"test.png\",\n        page_num=1,\n        figure_id=\"fig_1\",\n        placeholder=\"[PLACEHOLDER_fig_1]\",",
        "detail": "tests.test_textprocessor",
        "documentation": {}
    },
    {
        "label": "test_combine_text_with_figures_replaces_successfully",
        "kind": 2,
        "importPath": "tests.test_textprocessor",
        "description": "tests.test_textprocessor",
        "peekOfCode": "def test_combine_text_with_figures_replaces_successfully():\n    \"\"\"Test combine_text_with_figures successfully replaces placeholder.\"\"\"\n    image = ImageOnPage(\n        bytes=b\"fake\",\n        bbox=(0, 0, 100, 100),\n        filename=\"test.png\",\n        page_num=1,\n        figure_id=\"fig_1\",\n        title=\"Test Figure\",\n        placeholder=\"[PLACEHOLDER_fig_1]\",",
        "detail": "tests.test_textprocessor",
        "documentation": {}
    },
    {
        "label": "ChatUser",
        "kind": 6,
        "importPath": "locustfile",
        "description": "locustfile",
        "peekOfCode": "class ChatUser(HttpUser):\n    wait_time = between(5, 20)\n    @task\n    def ask_question(self):\n        self.client.get(\n            \"/\",\n            name=\"home\",\n        )\n        time.sleep(self.wait_time())\n        first_question = random.choice(",
        "detail": "locustfile",
        "documentation": {}
    }
]